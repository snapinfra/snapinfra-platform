{
  "timestamp": "2025-12-09T17:56:20.416Z",
  "project": {
    "id": "1dcff85a-610d-43ef-8b2d-0188eb85241d",
    "userId": "user_1765130484804_aph096zm6",
    "name": "Build Multitenant B2b",
    "description": "Build a multi-tenant B2B SaaS platform for supply chain visibility serving 1M+ daily shipments. Key features: real-time tracking, predictive alerts, multi-carrier integration, org hierarchies, analytics dashboard. Scale to 50 to 5K enterprise clients over 3 years across NA/EU/APAC regions and ensure SOC 2 Type II, ISO 27001, GDPR compliance.",
    "schema": [
      {
        "id": "table_1765301349092_0",
        "name": "organizations",
        "description": "",
        "fields": [
          {
            "id": "field_1765301349092_0",
            "name": "id",
            "type": "uuid",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349092_1",
            "name": "name",
            "type": "varchar",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349092_2",
            "name": "email",
            "type": "varchar",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349092_3",
            "name": "created_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349092_4",
            "name": "updated_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349092_5",
            "name": "deleted_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          }
        ],
        "relationships": [],
        "indexes": [
          {
            "name": "idx_organizations_email",
            "type": "unique",
            "fields": [
              "email"
            ]
          }
        ],
        "position": {
          "x": 172.68559501373986,
          "y": 243.42626855618903
        },
        "estimatedRows": 0
      },
      {
        "id": "table_1765301349092_1",
        "name": "organization_users",
        "description": "",
        "fields": [
          {
            "id": "field_1765301349093_0",
            "name": "id",
            "type": "uuid",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_1",
            "name": "organization_id",
            "type": "uuid",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_2",
            "name": "user_id",
            "type": "uuid",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_3",
            "name": "role",
            "type": "varchar",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_4",
            "name": "created_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_5",
            "name": "updated_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_6",
            "name": "deleted_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          }
        ],
        "relationships": [],
        "indexes": [
          {
            "name": "idx_organization_users_organization_id",
            "type": "btree",
            "fields": [
              "organization_id"
            ]
          },
          {
            "name": "idx_organization_users_user_id",
            "type": "btree",
            "fields": [
              "user_id"
            ]
          }
        ],
        "position": {
          "x": 366.0308776514239,
          "y": 425.00858931569684
        },
        "estimatedRows": 0
      },
      {
        "id": "table_1765301349093_2",
        "name": "users",
        "description": "",
        "fields": [
          {
            "id": "field_1765301349093_0",
            "name": "id",
            "type": "uuid",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_1",
            "name": "email",
            "type": "varchar",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_2",
            "name": "password",
            "type": "varchar",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_3",
            "name": "created_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_4",
            "name": "updated_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_5",
            "name": "deleted_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          }
        ],
        "relationships": [],
        "indexes": [
          {
            "name": "idx_users_email",
            "type": "unique",
            "fields": [
              "email"
            ]
          }
        ],
        "position": {
          "x": 498.7432728413861,
          "y": 345.7685326181079
        },
        "estimatedRows": 0
      },
      {
        "id": "table_1765301349093_3",
        "name": "shipments",
        "description": "",
        "fields": [
          {
            "id": "field_1765301349093_0",
            "name": "id",
            "type": "uuid",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_1",
            "name": "organization_id",
            "type": "uuid",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_2",
            "name": "carrier_id",
            "type": "uuid",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_3",
            "name": "tracking_number",
            "type": "varchar",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_4",
            "name": "created_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_5",
            "name": "updated_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_6",
            "name": "deleted_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          }
        ],
        "relationships": [],
        "indexes": [
          {
            "name": "idx_shipments_organization_id",
            "type": "btree",
            "fields": [
              "organization_id"
            ]
          },
          {
            "name": "idx_shipments_carrier_id",
            "type": "btree",
            "fields": [
              "carrier_id"
            ]
          },
          {
            "name": "idx_shipments_tracking_number",
            "type": "unique",
            "fields": [
              "tracking_number"
            ]
          }
        ],
        "position": {
          "x": 193.23403124283732,
          "y": 327.27161489146044
        },
        "estimatedRows": 0
      },
      {
        "id": "table_1765301349093_4",
        "name": "carriers",
        "description": "",
        "fields": [
          {
            "id": "field_1765301349093_0",
            "name": "id",
            "type": "uuid",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_1",
            "name": "name",
            "type": "varchar",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_2",
            "name": "api_key",
            "type": "varchar",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_3",
            "name": "created_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_4",
            "name": "updated_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_5",
            "name": "deleted_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          }
        ],
        "relationships": [],
        "indexes": [
          {
            "name": "idx_carriers_name",
            "type": "unique",
            "fields": [
              "name"
            ]
          }
        ],
        "position": {
          "x": 470.41455652776307,
          "y": 243.04228572338116
        },
        "estimatedRows": 0
      },
      {
        "id": "table_1765301349093_5",
        "name": "shipment_status",
        "description": "",
        "fields": [
          {
            "id": "field_1765301349093_0",
            "name": "id",
            "type": "uuid",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_1",
            "name": "shipment_id",
            "type": "uuid",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_2",
            "name": "status",
            "type": "varchar",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_3",
            "name": "created_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_4",
            "name": "updated_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_5",
            "name": "deleted_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          }
        ],
        "relationships": [],
        "indexes": [
          {
            "name": "idx_shipment_status_shipment_id",
            "type": "btree",
            "fields": [
              "shipment_id"
            ]
          }
        ],
        "position": {
          "x": 290.72021480203034,
          "y": 240.3741583849409
        },
        "estimatedRows": 0
      },
      {
        "id": "table_1765301349093_6",
        "name": "shipment_locations",
        "description": "",
        "fields": [
          {
            "id": "field_1765301349093_0",
            "name": "id",
            "type": "uuid",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_1",
            "name": "shipment_id",
            "type": "uuid",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_2",
            "name": "latitude",
            "type": "decimal",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_3",
            "name": "longitude",
            "type": "decimal",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_4",
            "name": "created_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_5",
            "name": "updated_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_6",
            "name": "deleted_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          }
        ],
        "relationships": [],
        "indexes": [
          {
            "name": "idx_shipment_locations_shipment_id",
            "type": "btree",
            "fields": [
              "shipment_id"
            ]
          }
        ],
        "position": {
          "x": 326.36574265101774,
          "y": 356.64660582095826
        },
        "estimatedRows": 0
      },
      {
        "id": "table_1765301349093_7",
        "name": "shipment_alerts",
        "description": "",
        "fields": [
          {
            "id": "field_1765301349093_0",
            "name": "id",
            "type": "uuid",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_1",
            "name": "shipment_id",
            "type": "uuid",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_2",
            "name": "alert_type",
            "type": "varchar",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_3",
            "name": "created_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_4",
            "name": "updated_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_5",
            "name": "deleted_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          }
        ],
        "relationships": [],
        "indexes": [
          {
            "name": "idx_shipment_alerts_shipment_id",
            "type": "btree",
            "fields": [
              "shipment_id"
            ]
          }
        ],
        "position": {
          "x": 192.5177603328841,
          "y": 489.63896746926065
        },
        "estimatedRows": 0
      },
      {
        "id": "table_1765301349093_8",
        "name": "settings",
        "description": "",
        "fields": [
          {
            "id": "field_1765301349093_0",
            "name": "id",
            "type": "uuid",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_1",
            "name": "organization_id",
            "type": "uuid",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_2",
            "name": "setting_key",
            "type": "varchar",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_3",
            "name": "setting_value",
            "type": "varchar",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_4",
            "name": "created_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_5",
            "name": "updated_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_6",
            "name": "deleted_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          }
        ],
        "relationships": [],
        "indexes": [
          {
            "name": "idx_settings_organization_id",
            "type": "btree",
            "fields": [
              "organization_id"
            ]
          }
        ],
        "position": {
          "x": 203.67102367330943,
          "y": 315.8250701972904
        },
        "estimatedRows": 0
      },
      {
        "id": "table_1765301349093_9",
        "name": "audit_logs",
        "description": "",
        "fields": [
          {
            "id": "field_1765301349093_0",
            "name": "id",
            "type": "uuid",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_1",
            "name": "organization_id",
            "type": "uuid",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_2",
            "name": "log_level",
            "type": "varchar",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_3",
            "name": "log_message",
            "type": "text",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_4",
            "name": "created_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_5",
            "name": "updated_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          },
          {
            "id": "field_1765301349093_6",
            "name": "deleted_at",
            "type": "timestamptz",
            "isPrimary": false,
            "isRequired": false,
            "isUnique": false,
            "isForeignKey": false,
            "description": "",
            "hasIndex": false
          }
        ],
        "relationships": [],
        "indexes": [
          {
            "name": "idx_audit_logs_organization_id",
            "type": "btree",
            "fields": [
              "organization_id"
            ]
          }
        ],
        "position": {
          "x": 338.0661160023659,
          "y": 115.83443141889238
        },
        "estimatedRows": 0
      }
    ],
    "specialParam": "uday",
    "diagrams": {
      "hld": {
        "id": "arch-1765301322151",
        "name": "Build Multitenant B2b System Architecture",
        "description": "Moderate architecture with 25 components",
        "nodes": [
          {
            "id": "cdn-1",
            "type": "cdn",
            "position": {
              "x": 100,
              "y": 100
            },
            "data": {
              "name": "Content Delivery Network",
              "description": "Distributes frontend assets",
              "color": "#0891B2",
              "metadata": {
                "layer": "Layer 0 (Client)",
                "layerIndex": 0
              },
              "aiExplanation": {
                "whyChosen": "\"Content Delivery Network\" provides essential cdn functionality for Build Multitenant B2b. It distributes frontend assets.",
                "howItFits": "This cdn integrates with other components to handle cdn responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard cdn best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "build-multitenant-b2b-frontend-1",
            "type": "frontend",
            "position": {
              "x": 100,
              "y": 300
            },
            "data": {
              "name": "Build Multitenant B2b Frontend",
              "description": "Handles client-side logic",
              "color": "#3B82F6",
              "metadata": {
                "layer": "Layer 0 (Client)",
                "layerIndex": 0
              },
              "aiExplanation": {
                "whyChosen": "\"Build Multitenant B2b Frontend\" provides essential frontend functionality for Build Multitenant B2b. It handles client-side logic.",
                "howItFits": "This frontend integrates with other components to handle frontend responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard frontend best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "mobile-1",
            "type": "mobile",
            "position": {
              "x": 100,
              "y": 500
            },
            "data": {
              "name": "Mobile Application",
              "description": "Provides mobile access to the application",
              "color": "#06B6D4",
              "metadata": {
                "layer": "Layer 0 (Client)",
                "layerIndex": 0
              },
              "aiExplanation": {
                "whyChosen": "\"Mobile Application\" provides essential mobile functionality for Build Multitenant B2b. It provides mobile access to the application.",
                "howItFits": "This mobile integrates with other components to handle mobile responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard mobile best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "load-balancer-1",
            "type": "load-balancer",
            "position": {
              "x": 500,
              "y": 100
            },
            "data": {
              "name": "Load Balancer",
              "description": "Routes traffic to services",
              "color": "#10B981",
              "metadata": {
                "layer": "Layer 1 (Gateway)",
                "layerIndex": 1
              },
              "aiExplanation": {
                "whyChosen": "\"Load Balancer\" provides essential load-balancer functionality for Build Multitenant B2b. It routes traffic to services.",
                "howItFits": "This load-balancer integrates with other components to handle load-balancer responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard load-balancer best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "api-gateway-1",
            "type": "api-gateway",
            "position": {
              "x": 500,
              "y": 300
            },
            "data": {
              "name": "API Gateway",
              "description": "Handles API requests and routing",
              "color": "#059669",
              "metadata": {
                "layer": "Layer 1 (Gateway)",
                "layerIndex": 1
              },
              "aiExplanation": {
                "whyChosen": "\"API Gateway\" provides essential api-gateway functionality for Build Multitenant B2b. It handles api requests and routing.",
                "howItFits": "This api-gateway integrates with other components to handle api-gateway responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's request routing.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard api-gateway best practices for configuration and deployment: configure rate limiting, implement authentication, enable logging."
              }
            }
          },
          {
            "id": "authentication-1",
            "type": "authentication",
            "position": {
              "x": 500,
              "y": 500
            },
            "data": {
              "name": "Authentication",
              "description": "Handles authentication operations",
              "color": "#F59E0B",
              "metadata": {
                "layer": "Layer 1 (Gateway)",
                "layerIndex": 1
              },
              "aiExplanation": {
                "whyChosen": "\"Authentication\" provides essential authentication functionality for Build Multitenant B2b. It handles authentication operations.",
                "howItFits": "This authentication integrates with other components to handle authentication responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard authentication best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "authentication-service-1",
            "type": "api-service",
            "position": {
              "x": 900,
              "y": 100
            },
            "data": {
              "name": "Authentication Service",
              "description": "Handles 2 POST endpoints for authentication management",
              "color": "#8B5CF6",
              "metadata": {
                "layer": "Layer 2 (Application)",
                "layerIndex": 2
              },
              "aiExplanation": {
                "whyChosen": "\"Authentication Service\" provides essential api-service functionality for Build Multitenant B2b. It handles 2 post endpoints for authentication management.",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "organizations-service-1",
            "type": "api-service",
            "position": {
              "x": 900,
              "y": 300
            },
            "data": {
              "name": "Organizations Service",
              "description": "Manages organizations table via 5 endpoints (GET, POST, PUT, DELETE)",
              "color": "#8B5CF6",
              "metadata": {
                "layer": "Layer 2 (Application)",
                "layerIndex": 2
              },
              "aiExplanation": {
                "whyChosen": "\"Organizations Service\" provides essential api-service functionality for Build Multitenant B2b. It manages organizations table via 5 endpoints (get, post, put, delete).",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "shipments-service-1",
            "type": "api-service",
            "position": {
              "x": 900,
              "y": 500
            },
            "data": {
              "name": "Shipments Service",
              "description": "Manages shipments table via 5 endpoints (GET, POST, PUT, DELETE)",
              "color": "#8B5CF6",
              "metadata": {
                "layer": "Layer 2 (Application)",
                "layerIndex": 2
              },
              "aiExplanation": {
                "whyChosen": "\"Shipments Service\" provides essential api-service functionality for Build Multitenant B2b. It manages shipments table via 5 endpoints (get, post, put, delete).",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "carriers-service-1",
            "type": "api-service",
            "position": {
              "x": 900,
              "y": 700
            },
            "data": {
              "name": "Carriers Service",
              "description": "Manages carriers table via 5 endpoints (GET, POST, PUT, DELETE)",
              "color": "#8B5CF6",
              "metadata": {
                "layer": "Layer 2 (Application)",
                "layerIndex": 2
              },
              "aiExplanation": {
                "whyChosen": "\"Carriers Service\" provides essential api-service functionality for Build Multitenant B2b. It manages carriers table via 5 endpoints (get, post, put, delete).",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "settings-service-1",
            "type": "api-service",
            "position": {
              "x": 900,
              "y": 900
            },
            "data": {
              "name": "Settings Service",
              "description": "Manages settings table via 5 endpoints (GET, POST, PUT, DELETE)",
              "color": "#8B5CF6",
              "metadata": {
                "layer": "Layer 2 (Application)",
                "layerIndex": 2
              },
              "aiExplanation": {
                "whyChosen": "\"Settings Service\" provides essential api-service functionality for Build Multitenant B2b. It manages settings table via 5 endpoints (get, post, put, delete).",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "cache-1",
            "type": "cache",
            "position": {
              "x": 900,
              "y": 1100
            },
            "data": {
              "name": "Cache",
              "description": "Improves performance by caching frequently accessed data",
              "color": "#DC2626",
              "metadata": {
                "layer": "Layer 2 (Application)",
                "layerIndex": 2
              },
              "aiExplanation": {
                "whyChosen": "\"Cache\" provides essential cache functionality for Build Multitenant B2b. It improves performance by caching frequently accessed data.",
                "howItFits": "This cache integrates with other components to handle cache responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's performance optimization.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Caching improves speed but requires cache invalidation strategy.",
                "bestPractices": "Follow standard cache best practices for configuration and deployment: set appropriate TTLs, implement cache warming, monitor hit rates."
              }
            }
          },
          {
            "id": "queue-1",
            "type": "queue",
            "position": {
              "x": 900,
              "y": 1300
            },
            "data": {
              "name": "Message Queue",
              "description": "Handles asynchronous tasks and messaging",
              "color": "#F97316",
              "metadata": {
                "layer": "Layer 2 (Application)",
                "layerIndex": 2
              },
              "aiExplanation": {
                "whyChosen": "\"Message Queue\" provides essential queue functionality for Build Multitenant B2b. It handles asynchronous tasks and messaging.",
                "howItFits": "This queue integrates with other components to handle queue responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard queue best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "database-1",
            "type": "database",
            "position": {
              "x": 1300,
              "y": 100
            },
            "data": {
              "name": "PostgreSQL Database",
              "description": "Stores data in the following tables: organizations, organization_users, users, shipments, carriers, shipment_status, shipment_locations, shipment_alerts, settings, audit_logs",
              "color": "#EF4444",
              "metadata": {
                "layer": "Layer 3 (Data)",
                "layerIndex": 3
              },
              "aiExplanation": {
                "whyChosen": "\"PostgreSQL Database\" provides essential database functionality for Build Multitenant B2b. It stores data in the following tables: organizations, organization_users, users, shipments, carriers, shipment_status, shipment_locations, shipment_alerts, settings, audit_logs.",
                "howItFits": "This database integrates with other components to handle database responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's data persistence.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Centralized data storage ensures consistency but may become a bottleneck.",
                "bestPractices": "Follow standard database best practices for configuration and deployment: optimize queries, implement backup strategies, use connection pooling."
              }
            }
          },
          {
            "id": "search-engine-1",
            "type": "search-engine",
            "position": {
              "x": 1300,
              "y": 300
            },
            "data": {
              "name": "Search Engine",
              "description": "Provides full-text search capabilities",
              "color": "#B45309",
              "metadata": {
                "layer": "Layer 3 (Data)",
                "layerIndex": 3
              },
              "aiExplanation": {
                "whyChosen": "\"Search Engine\" provides essential search-engine functionality for Build Multitenant B2b. It provides full-text search capabilities.",
                "howItFits": "This search-engine integrates with other components to handle search-engine responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard search-engine best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "storage-1",
            "type": "backup-storage",
            "position": {
              "x": 1300,
              "y": 500
            },
            "data": {
              "name": "Storage",
              "description": "Stores and retrieves files and assets",
              "color": "#4B5563",
              "metadata": {
                "layer": "Layer 3 (Data)",
                "layerIndex": 3
              },
              "aiExplanation": {
                "whyChosen": "\"Storage\" provides essential backup-storage functionality for Build Multitenant B2b. It stores and retrieves files and assets.",
                "howItFits": "This backup-storage integrates with other components to handle backup-storage responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard backup-storage best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "replica-1",
            "type": "database",
            "position": {
              "x": 1300,
              "y": 700
            },
            "data": {
              "name": "Database Replica",
              "description": "Provides a read-only replica of the primary database",
              "color": "#EF4444",
              "metadata": {
                "layer": "Layer 3 (Data)",
                "layerIndex": 3
              },
              "aiExplanation": {
                "whyChosen": "\"Database Replica\" provides essential database functionality for Build Multitenant B2b. It provides a read-only replica of the primary database.",
                "howItFits": "This database integrates with other components to handle database responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's data persistence.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Centralized data storage ensures consistency but may become a bottleneck.",
                "bestPractices": "Follow standard database best practices for configuration and deployment: optimize queries, implement backup strategies, use connection pooling."
              }
            }
          },
          {
            "id": "monitoring-1",
            "type": "monitoring",
            "position": {
              "x": 1700,
              "y": 100
            },
            "data": {
              "name": "Monitoring",
              "description": "Tracks system performance and health",
              "color": "#EA580C",
              "metadata": {
                "layer": "Layer 4 (Infrastructure)",
                "layerIndex": 4
              },
              "aiExplanation": {
                "whyChosen": "\"Monitoring\" provides essential monitoring functionality for Build Multitenant B2b. It tracks system performance and health.",
                "howItFits": "This monitoring integrates with other components to handle monitoring responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard monitoring best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "logging-1",
            "type": "logging",
            "position": {
              "x": 1700,
              "y": 300
            },
            "data": {
              "name": "Logging",
              "description": "Handles log collection and analysis",
              "color": "#CA8A04",
              "metadata": {
                "layer": "Layer 4 (Infrastructure)",
                "layerIndex": 4
              },
              "aiExplanation": {
                "whyChosen": "\"Logging\" provides essential logging functionality for Build Multitenant B2b. It handles log collection and analysis.",
                "howItFits": "This logging integrates with other components to handle logging responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard logging best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "notifications-1",
            "type": "notification-service",
            "position": {
              "x": 1700,
              "y": 500
            },
            "data": {
              "name": "Notifications",
              "description": "Sends notifications to users and administrators",
              "color": "#8B5CF6",
              "metadata": {
                "layer": "Layer 4 (Infrastructure)",
                "layerIndex": 4
              },
              "aiExplanation": {
                "whyChosen": "\"Notifications\" provides essential notification-service functionality for Build Multitenant B2b. It sends notifications to users and administrators.",
                "howItFits": "This notification-service integrates with other components to handle notification-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard notification-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "analytics-1",
            "type": "analytics",
            "position": {
              "x": 1700,
              "y": 700
            },
            "data": {
              "name": "Analytics",
              "description": "Provides insights into system usage and performance",
              "color": "#7C3AED",
              "metadata": {
                "layer": "Layer 4 (Infrastructure)",
                "layerIndex": 4
              },
              "aiExplanation": {
                "whyChosen": "\"Analytics\" provides essential analytics functionality for Build Multitenant B2b. It provides insights into system usage and performance.",
                "howItFits": "This analytics integrates with other components to handle analytics responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard analytics best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "ci-cd-1",
            "type": "ci-cd",
            "position": {
              "x": 2100,
              "y": 100
            },
            "data": {
              "name": "CI/CD Pipeline",
              "description": "Automates build, test, and deployment processes",
              "color": "#059669",
              "metadata": {
                "layer": "Layer 5 (DevOps)",
                "layerIndex": 5
              },
              "aiExplanation": {
                "whyChosen": "\"CI/CD Pipeline\" provides essential ci-cd functionality for Build Multitenant B2b. It automates build, test, and deployment processes.",
                "howItFits": "This ci-cd integrates with other components to handle ci-cd responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard ci-cd best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "secrets-manager-1",
            "type": "secrets-manager",
            "position": {
              "x": 2100,
              "y": 300
            },
            "data": {
              "name": "Secrets Manager",
              "description": "Stores and manages sensitive data",
              "color": "#374151",
              "metadata": {
                "layer": "Layer 5 (DevOps)",
                "layerIndex": 5
              },
              "aiExplanation": {
                "whyChosen": "\"Secrets Manager\" provides essential secrets-manager functionality for Build Multitenant B2b. It stores and manages sensitive data.",
                "howItFits": "This secrets-manager integrates with other components to handle secrets-manager responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard secrets-manager best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "backup-1",
            "type": "backup-storage",
            "position": {
              "x": 2100,
              "y": 500
            },
            "data": {
              "name": "Backup",
              "description": "Stores and retrieves backups of the system",
              "color": "#4B5563",
              "metadata": {
                "layer": "Layer 5 (DevOps)",
                "layerIndex": 5
              },
              "aiExplanation": {
                "whyChosen": "\"Backup\" provides essential backup-storage functionality for Build Multitenant B2b. It stores and retrieves backups of the system.",
                "howItFits": "This backup-storage integrates with other components to handle backup-storage responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard backup-storage best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "container-registry-1",
            "type": "container-registry",
            "position": {
              "x": 2100,
              "y": 700
            },
            "data": {
              "name": "Container Registry",
              "description": "Stores and manages container images",
              "color": "#6B7280",
              "metadata": {
                "layer": "Layer 5 (DevOps)",
                "layerIndex": 5
              },
              "aiExplanation": {
                "whyChosen": "\"Container Registry\" provides essential container-registry functionality for Build Multitenant B2b. It stores and manages container images.",
                "howItFits": "This container-registry integrates with other components to handle container-registry responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard container-registry best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          }
        ],
        "edges": [
          {
            "id": "edge-cdn-1-build-multitenant-b2b-frontend-1-0",
            "source": "cdn-1",
            "target": "build-multitenant-b2b-frontend-1",
            "type": "smoothstep",
            "label": "GET Frontend Assets",
            "data": {}
          },
          {
            "id": "edge-build-multitenant-b2b-frontend-1-load-balancer-1-1",
            "source": "build-multitenant-b2b-frontend-1",
            "target": "load-balancer-1",
            "type": "smoothstep",
            "label": "GET/POST/PATCH Frontend Requests",
            "data": {}
          },
          {
            "id": "edge-load-balancer-1-api-gateway-1-2",
            "source": "load-balancer-1",
            "target": "api-gateway-1",
            "type": "smoothstep",
            "label": "POST/GET API Requests",
            "data": {}
          },
          {
            "id": "edge-api-gateway-1-authentication-1-3",
            "source": "api-gateway-1",
            "target": "authentication-1",
            "type": "smoothstep",
            "label": "POST Authentication Data",
            "data": {}
          },
          {
            "id": "edge-api-gateway-1-authentication-service-1-4",
            "source": "api-gateway-1",
            "target": "authentication-service-1",
            "type": "smoothstep",
            "label": "POST Authentication Data",
            "data": {}
          },
          {
            "id": "edge-api-gateway-1-organizations-service-1-5",
            "source": "api-gateway-1",
            "target": "organizations-service-1",
            "type": "smoothstep",
            "label": "GET/POST Organizations Data",
            "data": {}
          },
          {
            "id": "edge-api-gateway-1-shipments-service-1-6",
            "source": "api-gateway-1",
            "target": "shipments-service-1",
            "type": "smoothstep",
            "label": "GET/POST Shipments Data",
            "data": {}
          },
          {
            "id": "edge-api-gateway-1-carriers-service-1-7",
            "source": "api-gateway-1",
            "target": "carriers-service-1",
            "type": "smoothstep",
            "label": "GET/POST Carriers Data",
            "data": {}
          },
          {
            "id": "edge-api-gateway-1-settings-service-1-8",
            "source": "api-gateway-1",
            "target": "settings-service-1",
            "type": "smoothstep",
            "label": "GET/POST Settings Data",
            "data": {}
          },
          {
            "id": "edge-organizations-service-1-database-1-9",
            "source": "organizations-service-1",
            "target": "database-1",
            "type": "smoothstep",
            "label": "GET/POST Organizations Table",
            "data": {}
          },
          {
            "id": "edge-shipments-service-1-database-1-10",
            "source": "shipments-service-1",
            "target": "database-1",
            "type": "smoothstep",
            "label": "GET/POST Shipments Table",
            "data": {}
          },
          {
            "id": "edge-carriers-service-1-database-1-11",
            "source": "carriers-service-1",
            "target": "database-1",
            "type": "smoothstep",
            "label": "GET/POST Carriers Table",
            "data": {}
          },
          {
            "id": "edge-settings-service-1-database-1-12",
            "source": "settings-service-1",
            "target": "database-1",
            "type": "smoothstep",
            "label": "GET/POST Settings Table",
            "data": {}
          },
          {
            "id": "edge-database-1-replica-1-13",
            "source": "database-1",
            "target": "replica-1",
            "type": "smoothstep",
            "label": "Replication Data",
            "data": {}
          },
          {
            "id": "edge-database-1-search-engine-1-14",
            "source": "database-1",
            "target": "search-engine-1",
            "type": "smoothstep",
            "label": "Search Indexing",
            "data": {}
          },
          {
            "id": "edge-ci-cd-1-container-registry-1-15",
            "source": "ci-cd-1",
            "target": "container-registry-1",
            "type": "smoothstep",
            "label": "Image Deployment",
            "data": {}
          },
          {
            "id": "edge-ci-cd-1-load-balancer-1-16",
            "source": "ci-cd-1",
            "target": "load-balancer-1",
            "type": "smoothstep",
            "label": "Deployment",
            "data": {}
          },
          {
            "id": "edge-secrets-manager-1-ci-cd-1-17",
            "source": "secrets-manager-1",
            "target": "ci-cd-1",
            "type": "smoothstep",
            "label": "Secrets Injection",
            "data": {}
          }
        ],
        "metadata": {
          "createdAt": "2025-12-09T17:28:42.151Z",
          "updatedAt": "2025-12-09T17:28:42.151Z",
          "version": "2.0.0",
          "aiGenerated": true,
          "complexity": "Moderate",
          "scalingStrategy": "Horizontal",
          "securityLevel": "Standard"
        }
      },
      "lld": {
        "id": "lld-1765301323176",
        "name": "Build Multitenant B2b - Low Level Design",
        "description": "Detailed component architecture with 26 implementation components",
        "nodes": [
          {
            "id": "user-controller",
            "type": "api-service",
            "position": {
              "x": 100,
              "y": 100
            },
            "data": {
              "name": "UserController",
              "description": "Handles user-related HTTP requests",
              "color": "#8B5CF6",
              "metadata": {
                "technology": "Express.js Controller",
                "layer": "Controllers Layer",
                "layerIndex": 0,
                "methods": [
                  "POST /api/v1/auth/login",
                  "POST /api/v1/auth/register",
                  "GET /api/v1/users",
                  "GET /api/v1/users/{user_id}",
                  "PUT /api/v1/users/{user_id}",
                  "DELETE /api/v1/users/{user_id}"
                ],
                "dependencies": [
                  "authentication-service",
                  "user-service",
                  "auth-middleware"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"UserController\" provides essential api-service functionality for Build Multitenant B2b. It handles user-related http requests.",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "organization-controller",
            "type": "api-service",
            "position": {
              "x": 100,
              "y": 280
            },
            "data": {
              "name": "OrganizationController",
              "description": "Handles organization-related HTTP requests",
              "color": "#8B5CF6",
              "metadata": {
                "technology": "Express.js Controller",
                "layer": "Controllers Layer",
                "layerIndex": 0,
                "methods": [
                  "GET /api/v1/organizations",
                  "GET /api/v1/organizations/{organization_id}",
                  "POST /api/v1/organizations",
                  "PUT /api/v1/organizations/{organization_id}",
                  "DELETE /api/v1/organizations/{organization_id}"
                ],
                "dependencies": [
                  "organization-service",
                  "auth-middleware"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"OrganizationController\" provides essential api-service functionality for Build Multitenant B2b. It handles organization-related http requests.",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "shipment-controller",
            "type": "api-service",
            "position": {
              "x": 100,
              "y": 460
            },
            "data": {
              "name": "ShipmentController",
              "description": "Handles shipment-related HTTP requests",
              "color": "#8B5CF6",
              "metadata": {
                "technology": "Express.js Controller",
                "layer": "Controllers Layer",
                "layerIndex": 0,
                "methods": [
                  "GET /api/v1/shipments",
                  "GET /api/v1/shipments/{shipment_id}",
                  "POST /api/v1/shipments",
                  "PUT /api/v1/shipments/{shipment_id}",
                  "DELETE /api/v1/shipments/{shipment_id}"
                ],
                "dependencies": [
                  "shipment-service",
                  "auth-middleware"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"ShipmentController\" provides essential api-service functionality for Build Multitenant B2b. It handles shipment-related http requests.",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "carrier-controller",
            "type": "api-service",
            "position": {
              "x": 100,
              "y": 640
            },
            "data": {
              "name": "CarrierController",
              "description": "Handles carrier-related HTTP requests",
              "color": "#8B5CF6",
              "metadata": {
                "technology": "Express.js Controller",
                "layer": "Controllers Layer",
                "layerIndex": 0,
                "methods": [
                  "GET /api/v1/carriers",
                  "GET /api/v1/carriers/{carrier_id}",
                  "POST /api/v1/carriers",
                  "PUT /api/v1/carriers/{carrier_id}",
                  "DELETE /api/v1/carriers/{carrier_id}"
                ],
                "dependencies": [
                  "carrier-service",
                  "auth-middleware"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"CarrierController\" provides essential api-service functionality for Build Multitenant B2b. It handles carrier-related http requests.",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "authentication-service",
            "type": "api-service",
            "position": {
              "x": 450,
              "y": 100
            },
            "data": {
              "name": "AuthenticationService",
              "description": "Handles user authentication",
              "color": "#8B5CF6",
              "metadata": {
                "technology": "TypeScript Class",
                "layer": "Services/Business Logic Layer",
                "layerIndex": 1,
                "methods": [
                  "login(email, password)",
                  "validateToken(token)",
                  "refreshToken(token)"
                ],
                "dependencies": [
                  "user-repository",
                  "token-repository"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"AuthenticationService\" provides essential api-service functionality for Build Multitenant B2b. It handles user authentication.",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "user-service",
            "type": "api-service",
            "position": {
              "x": 450,
              "y": 280
            },
            "data": {
              "name": "UserService",
              "description": "Handles user-related business logic",
              "color": "#8B5CF6",
              "metadata": {
                "technology": "TypeScript Class",
                "layer": "Services/Business Logic Layer",
                "layerIndex": 1,
                "methods": [
                  "createUser(dto)",
                  "updateUser(id, dto)",
                  "deleteUser(id)"
                ],
                "dependencies": [
                  "user-repository"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"UserService\" provides essential api-service functionality for Build Multitenant B2b. It handles user-related business logic.",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "organization-service",
            "type": "api-service",
            "position": {
              "x": 450,
              "y": 460
            },
            "data": {
              "name": "OrganizationService",
              "description": "Handles organization-related business logic",
              "color": "#8B5CF6",
              "metadata": {
                "technology": "TypeScript Class",
                "layer": "Services/Business Logic Layer",
                "layerIndex": 1,
                "methods": [
                  "createOrganization(dto)",
                  "updateOrganization(id, dto)",
                  "deleteOrganization(id)"
                ],
                "dependencies": [
                  "organization-repository"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"OrganizationService\" provides essential api-service functionality for Build Multitenant B2b. It handles organization-related business logic.",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "shipment-service",
            "type": "api-service",
            "position": {
              "x": 450,
              "y": 640
            },
            "data": {
              "name": "ShipmentService",
              "description": "Handles shipment-related business logic",
              "color": "#8B5CF6",
              "metadata": {
                "technology": "TypeScript Class",
                "layer": "Services/Business Logic Layer",
                "layerIndex": 1,
                "methods": [
                  "createShipment(dto)",
                  "updateShipment(id, dto)",
                  "deleteShipment(id)"
                ],
                "dependencies": [
                  "shipment-repository"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"ShipmentService\" provides essential api-service functionality for Build Multitenant B2b. It handles shipment-related business logic.",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "carrier-service",
            "type": "api-service",
            "position": {
              "x": 450,
              "y": 820
            },
            "data": {
              "name": "CarrierService",
              "description": "Handles carrier-related business logic",
              "color": "#8B5CF6",
              "metadata": {
                "technology": "TypeScript Class",
                "layer": "Services/Business Logic Layer",
                "layerIndex": 1,
                "methods": [
                  "createCarrier(dto)",
                  "updateCarrier(id, dto)",
                  "deleteCarrier(id)"
                ],
                "dependencies": [
                  "carrier-repository"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"CarrierService\" provides essential api-service functionality for Build Multitenant B2b. It handles carrier-related business logic.",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "user-repository",
            "type": "api-service",
            "position": {
              "x": 800,
              "y": 100
            },
            "data": {
              "name": "UserRepository",
              "description": "Handles user data access",
              "color": "#8B5CF6",
              "metadata": {
                "technology": "TypeORM Repository",
                "layer": "Repositories/Data Access Layer",
                "layerIndex": 2,
                "methods": [
                  "findById(id)",
                  "save(user)",
                  "update(id, user)",
                  "delete(id)"
                ],
                "dependencies": []
              },
              "aiExplanation": {
                "whyChosen": "\"UserRepository\" provides essential api-service functionality for Build Multitenant B2b. It handles user data access.",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "organization-repository",
            "type": "api-service",
            "position": {
              "x": 800,
              "y": 280
            },
            "data": {
              "name": "OrganizationRepository",
              "description": "Handles organization data access",
              "color": "#8B5CF6",
              "metadata": {
                "technology": "TypeORM Repository",
                "layer": "Repositories/Data Access Layer",
                "layerIndex": 2,
                "methods": [
                  "findById(id)",
                  "save(organization)",
                  "update(id, organization)",
                  "delete(id)"
                ],
                "dependencies": []
              },
              "aiExplanation": {
                "whyChosen": "\"OrganizationRepository\" provides essential api-service functionality for Build Multitenant B2b. It handles organization data access.",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "shipment-repository",
            "type": "api-service",
            "position": {
              "x": 800,
              "y": 460
            },
            "data": {
              "name": "ShipmentRepository",
              "description": "Handles shipment data access",
              "color": "#8B5CF6",
              "metadata": {
                "technology": "TypeORM Repository",
                "layer": "Repositories/Data Access Layer",
                "layerIndex": 2,
                "methods": [
                  "findById(id)",
                  "save(shipment)",
                  "update(id, shipment)",
                  "delete(id)"
                ],
                "dependencies": []
              },
              "aiExplanation": {
                "whyChosen": "\"ShipmentRepository\" provides essential api-service functionality for Build Multitenant B2b. It handles shipment data access.",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "carrier-repository",
            "type": "api-service",
            "position": {
              "x": 800,
              "y": 640
            },
            "data": {
              "name": "CarrierRepository",
              "description": "Handles carrier data access",
              "color": "#8B5CF6",
              "metadata": {
                "technology": "TypeORM Repository",
                "layer": "Repositories/Data Access Layer",
                "layerIndex": 2,
                "methods": [
                  "findById(id)",
                  "save(carrier)",
                  "update(id, carrier)",
                  "delete(id)"
                ],
                "dependencies": []
              },
              "aiExplanation": {
                "whyChosen": "\"CarrierRepository\" provides essential api-service functionality for Build Multitenant B2b. It handles carrier data access.",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "user-entity",
            "type": "database",
            "position": {
              "x": 1150,
              "y": 100
            },
            "data": {
              "name": "User",
              "description": "Represents a user",
              "color": "#EF4444",
              "metadata": {
                "technology": "TypeScript Interface",
                "layer": "Models/Entities Layer",
                "layerIndex": 3,
                "methods": [],
                "dependencies": []
              },
              "aiExplanation": {
                "whyChosen": "\"User\" provides essential database functionality for Build Multitenant B2b. It represents a user.",
                "howItFits": "This database integrates with other components to handle database responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's data persistence.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Centralized data storage ensures consistency but may become a bottleneck.",
                "bestPractices": "Follow standard database best practices for configuration and deployment: optimize queries, implement backup strategies, use connection pooling."
              }
            }
          },
          {
            "id": "organization-entity",
            "type": "database",
            "position": {
              "x": 1150,
              "y": 280
            },
            "data": {
              "name": "Organization",
              "description": "Represents an organization",
              "color": "#EF4444",
              "metadata": {
                "technology": "TypeScript Interface",
                "layer": "Models/Entities Layer",
                "layerIndex": 3,
                "methods": [],
                "dependencies": []
              },
              "aiExplanation": {
                "whyChosen": "\"Organization\" provides essential database functionality for Build Multitenant B2b. It represents an organization.",
                "howItFits": "This database integrates with other components to handle database responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's data persistence.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Centralized data storage ensures consistency but may become a bottleneck.",
                "bestPractices": "Follow standard database best practices for configuration and deployment: optimize queries, implement backup strategies, use connection pooling."
              }
            }
          },
          {
            "id": "shipment-entity",
            "type": "database",
            "position": {
              "x": 1150,
              "y": 460
            },
            "data": {
              "name": "Shipment",
              "description": "Represents a shipment",
              "color": "#EF4444",
              "metadata": {
                "technology": "TypeScript Interface",
                "layer": "Models/Entities Layer",
                "layerIndex": 3,
                "methods": [],
                "dependencies": []
              },
              "aiExplanation": {
                "whyChosen": "\"Shipment\" provides essential database functionality for Build Multitenant B2b. It represents a shipment.",
                "howItFits": "This database integrates with other components to handle database responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's data persistence.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Centralized data storage ensures consistency but may become a bottleneck.",
                "bestPractices": "Follow standard database best practices for configuration and deployment: optimize queries, implement backup strategies, use connection pooling."
              }
            }
          },
          {
            "id": "carrier-entity",
            "type": "database",
            "position": {
              "x": 1150,
              "y": 640
            },
            "data": {
              "name": "Carrier",
              "description": "Represents a carrier",
              "color": "#EF4444",
              "metadata": {
                "technology": "TypeScript Interface",
                "layer": "Models/Entities Layer",
                "layerIndex": 3,
                "methods": [],
                "dependencies": []
              },
              "aiExplanation": {
                "whyChosen": "\"Carrier\" provides essential database functionality for Build Multitenant B2b. It represents a carrier.",
                "howItFits": "This database integrates with other components to handle database responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's data persistence.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Centralized data storage ensures consistency but may become a bottleneck.",
                "bestPractices": "Follow standard database best practices for configuration and deployment: optimize queries, implement backup strategies, use connection pooling."
              }
            }
          },
          {
            "id": "auth-middleware",
            "type": "api-gateway",
            "position": {
              "x": 1500,
              "y": 100
            },
            "data": {
              "name": "AuthMiddleware",
              "description": "Handles authentication middleware",
              "color": "#059669",
              "metadata": {
                "technology": "Express.js Middleware",
                "layer": "Middleware & Utilities Layer",
                "layerIndex": 4,
                "methods": [
                  "validateToken(token)"
                ],
                "dependencies": []
              },
              "aiExplanation": {
                "whyChosen": "\"AuthMiddleware\" provides essential api-gateway functionality for Build Multitenant B2b. It handles authentication middleware.",
                "howItFits": "This api-gateway integrates with other components to handle api-gateway responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's request routing.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard api-gateway best practices for configuration and deployment: configure rate limiting, implement authentication, enable logging."
              }
            }
          },
          {
            "id": "error-handler",
            "type": "api-service",
            "position": {
              "x": 1500,
              "y": 280
            },
            "data": {
              "name": "ErrorHandler",
              "description": "Handles error handling",
              "color": "#8B5CF6",
              "metadata": {
                "technology": "TypeScript Class",
                "layer": "Middleware & Utilities Layer",
                "layerIndex": 4,
                "methods": [
                  "handleError(error)"
                ],
                "dependencies": []
              },
              "aiExplanation": {
                "whyChosen": "\"ErrorHandler\" provides essential api-service functionality for Build Multitenant B2b. It handles error handling.",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "logger-utility",
            "type": "api-service",
            "position": {
              "x": 1500,
              "y": 460
            },
            "data": {
              "name": "LoggerUtility",
              "description": "Handles logging",
              "color": "#8B5CF6",
              "metadata": {
                "technology": "TypeScript Class",
                "layer": "Middleware & Utilities Layer",
                "layerIndex": 4,
                "methods": [
                  "log(message)"
                ],
                "dependencies": []
              },
              "aiExplanation": {
                "whyChosen": "\"LoggerUtility\" provides essential api-service functionality for Build Multitenant B2b. It handles logging.",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "cache-helper",
            "type": "api-service",
            "position": {
              "x": 1500,
              "y": 640
            },
            "data": {
              "name": "CacheHelper",
              "description": "Handles caching",
              "color": "#8B5CF6",
              "metadata": {
                "technology": "TypeScript Class",
                "layer": "Middleware & Utilities Layer",
                "layerIndex": 4,
                "methods": [
                  "get(key)",
                  "set(key, value)"
                ],
                "dependencies": []
              },
              "aiExplanation": {
                "whyChosen": "\"CacheHelper\" provides essential api-service functionality for Build Multitenant B2b. It handles caching.",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "email-service-adapter",
            "type": "external-service",
            "position": {
              "x": 1850,
              "y": 100
            },
            "data": {
              "name": "EmailServiceAdapter",
              "description": "Handles email service integration",
              "color": "#6B7280",
              "metadata": {
                "technology": "TypeScript Class",
                "layer": "External Integrations Layer",
                "layerIndex": 5,
                "methods": [
                  "sendEmail(email, subject, body)"
                ],
                "dependencies": []
              },
              "aiExplanation": {
                "whyChosen": "\"EmailServiceAdapter\" provides essential external-service functionality for Build Multitenant B2b. It handles email service integration.",
                "howItFits": "This external-service integrates with other components to handle external-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard external-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "payment-gateway-integration",
            "type": "api-service",
            "position": {
              "x": 1850,
              "y": 280
            },
            "data": {
              "name": "PaymentGatewayIntegration",
              "description": "Handles payment gateway integration",
              "color": "#8B5CF6",
              "metadata": {
                "technology": "TypeScript Class",
                "layer": "External Integrations Layer",
                "layerIndex": 5,
                "methods": [
                  "processPayment(amount)"
                ],
                "dependencies": []
              },
              "aiExplanation": {
                "whyChosen": "\"PaymentGatewayIntegration\" provides essential api-service functionality for Build Multitenant B2b. It handles payment gateway integration.",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "database-connection",
            "type": "api-service",
            "position": {
              "x": 2200,
              "y": 100
            },
            "data": {
              "name": "DatabaseConnection",
              "description": "Handles database connection",
              "color": "#8B5CF6",
              "metadata": {
                "technology": "TypeORM Connection",
                "layer": "Infrastructure Layer",
                "layerIndex": 6,
                "methods": [
                  "connect()",
                  "disconnect()"
                ],
                "dependencies": []
              },
              "aiExplanation": {
                "whyChosen": "\"DatabaseConnection\" provides essential api-service functionality for Build Multitenant B2b. It handles database connection.",
                "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "cache-client",
            "type": "external-service",
            "position": {
              "x": 2200,
              "y": 280
            },
            "data": {
              "name": "CacheClient",
              "description": "Handles cache client",
              "color": "#6B7280",
              "metadata": {
                "technology": "TypeScript Class",
                "layer": "Infrastructure Layer",
                "layerIndex": 6,
                "methods": [
                  "get(key)",
                  "set(key, value)"
                ],
                "dependencies": []
              },
              "aiExplanation": {
                "whyChosen": "\"CacheClient\" provides essential external-service functionality for Build Multitenant B2b. It handles cache client.",
                "howItFits": "This external-service integrates with other components to handle external-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard external-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          },
          {
            "id": "queue-client",
            "type": "external-service",
            "position": {
              "x": 2200,
              "y": 460
            },
            "data": {
              "name": "QueueClient",
              "description": "Handles queue client",
              "color": "#6B7280",
              "metadata": {
                "technology": "TypeScript Class",
                "layer": "Infrastructure Layer",
                "layerIndex": 6,
                "methods": [
                  "enqueue(message)",
                  "dequeue()"
                ],
                "dependencies": []
              },
              "aiExplanation": {
                "whyChosen": "\"QueueClient\" provides essential external-service functionality for Build Multitenant B2b. It handles queue client.",
                "howItFits": "This external-service integrates with other components to handle external-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
                "bestPractices": "Follow standard external-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
              }
            }
          }
        ],
        "edges": [
          {
            "id": "edge-user-controller-authentication-service-0",
            "source": "user-controller",
            "target": "authentication-service",
            "type": "smoothstep",
            "label": "login(email, password)  Promise<User>",
            "data": {
              "protocol": "Method Call",
              "dataFlow": "UserCreateDTO"
            }
          },
          {
            "id": "edge-authentication-service-user-repository-1",
            "source": "authentication-service",
            "target": "user-repository",
            "type": "smoothstep",
            "label": "findByEmail(email)  Promise<User>",
            "data": {
              "protocol": "Method Call",
              "dataFlow": "UserCreateDTO"
            }
          },
          {
            "id": "edge-user-service-user-repository-2",
            "source": "user-service",
            "target": "user-repository",
            "type": "smoothstep",
            "label": "save(user)  Promise<User>",
            "data": {
              "protocol": "Method Call",
              "dataFlow": "UserCreateDTO"
            }
          },
          {
            "id": "edge-organization-service-organization-repository-3",
            "source": "organization-service",
            "target": "organization-repository",
            "type": "smoothstep",
            "label": "save(organization)  Promise<Organization>",
            "data": {
              "protocol": "Method Call",
              "dataFlow": "OrganizationCreateDTO"
            }
          },
          {
            "id": "edge-shipment-service-shipment-repository-4",
            "source": "shipment-service",
            "target": "shipment-repository",
            "type": "smoothstep",
            "label": "save(shipment)  Promise<Shipment>",
            "data": {
              "protocol": "Method Call",
              "dataFlow": "ShipmentCreateDTO"
            }
          },
          {
            "id": "edge-carrier-service-carrier-repository-5",
            "source": "carrier-service",
            "target": "carrier-repository",
            "type": "smoothstep",
            "label": "save(carrier)  Promise<Carrier>",
            "data": {
              "protocol": "Method Call",
              "dataFlow": "CarrierCreateDTO"
            }
          }
        ],
        "metadata": {
          "createdAt": "2025-12-09T17:28:43.176Z",
          "updatedAt": "2025-12-09T17:28:43.176Z",
          "version": "1.0.0",
          "aiGenerated": true,
          "complexity": "Detailed",
          "scalingStrategy": "Layered Architecture + Repository Pattern",
          "securityLevel": "Unit + Integration Tests Required"
        }
      },
      "dataflow": {
        "id": "dfd-1765301320918",
        "name": "Build Multitenant B2b Data Flow",
        "nodes": [
          {
            "id": "client-web",
            "type": "external-entity",
            "position": {
              "x": 0,
              "y": 250
            },
            "data": {
              "label": "Web Browser",
              "description": "React Client",
              "color": "#3B82F6",
              "nodeType": "external-entity",
              "metadata": {
                "technology": "Client",
                "operations": [
                  "HTTPS"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"Web Browser\" provides essential external-entity functionality for Build Multitenant B2b. It react client.",
                "howItFits": "This external-entity integrates with other components to handle external-entity responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard external-entity best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "client-mobile",
            "type": "external-entity",
            "position": {
              "x": 0,
              "y": 450
            },
            "data": {
              "label": "Mobile App",
              "description": "iOS/Android",
              "color": "#3B82F6",
              "nodeType": "external-entity",
              "metadata": {
                "technology": "Client",
                "operations": [
                  "HTTPS"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"Mobile App\" provides essential external-entity functionality for Build Multitenant B2b. It ios/android.",
                "howItFits": "This external-entity integrates with other components to handle external-entity responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard external-entity best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "api-gateway",
            "type": "gateway",
            "position": {
              "x": 400,
              "y": 225
            },
            "data": {
              "label": "API Gateway",
              "color": "#10B981",
              "nodeType": "gateway",
              "metadata": {
                "technology": "Nginx/Kong",
                "operations": [
                  "Route",
                  "Verify"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"API Gateway\" provides essential gateway functionality for Build Multitenant B2b. It handles critical system operations.",
                "howItFits": "This gateway integrates with other components to handle gateway responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's request routing.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard gateway best practices for configuration and deployment: configure rate limiting, implement authentication, enable logging."
              }
            }
          },
          {
            "id": "auth-service",
            "type": "gateway",
            "position": {
              "x": 400,
              "y": 475
            },
            "data": {
              "label": "Auth Service",
              "color": "#10B981",
              "nodeType": "gateway",
              "metadata": {
                "technology": "OAuth2",
                "operations": [
                  "Route",
                  "Verify"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"Auth Service\" provides essential gateway functionality for Build Multitenant B2b. It handles critical system operations.",
                "howItFits": "This gateway integrates with other components to handle gateway responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's request routing.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard gateway best practices for configuration and deployment: configure rate limiting, implement authentication, enable logging."
              }
            }
          },
          {
            "id": "svc-authentication",
            "type": "process",
            "position": {
              "x": 900,
              "y": 50
            },
            "data": {
              "label": "Authentication Service",
              "description": "Handles Authentication logic",
              "color": "#8B5CF6",
              "nodeType": "process",
              "metadata": {
                "technology": "Node.js",
                "operations": [
                  "POST",
                  "POST"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"Authentication Service\" provides essential process functionality for Build Multitenant B2b. It handles authentication logic.",
                "howItFits": "This process integrates with other components to handle process responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard process best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "svc-organizations",
            "type": "process",
            "position": {
              "x": 900,
              "y": 250
            },
            "data": {
              "label": "Organizations Service",
              "description": "Handles Organizations logic",
              "color": "#8B5CF6",
              "nodeType": "process",
              "metadata": {
                "technology": "Node.js",
                "operations": [
                  "GET",
                  "GET",
                  "POST"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"Organizations Service\" provides essential process functionality for Build Multitenant B2b. It handles organizations logic.",
                "howItFits": "This process integrates with other components to handle process responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard process best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "svc-shipments",
            "type": "process",
            "position": {
              "x": 900,
              "y": 450
            },
            "data": {
              "label": "Shipments Service",
              "description": "Handles Shipments logic",
              "color": "#8B5CF6",
              "nodeType": "process",
              "metadata": {
                "technology": "Node.js",
                "operations": [
                  "GET",
                  "GET",
                  "POST"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"Shipments Service\" provides essential process functionality for Build Multitenant B2b. It handles shipments logic.",
                "howItFits": "This process integrates with other components to handle process responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard process best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "svc-carriers",
            "type": "process",
            "position": {
              "x": 900,
              "y": 650
            },
            "data": {
              "label": "Carriers Service",
              "description": "Handles Carriers logic",
              "color": "#8B5CF6",
              "nodeType": "process",
              "metadata": {
                "technology": "Node.js",
                "operations": [
                  "GET",
                  "GET",
                  "POST"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"Carriers Service\" provides essential process functionality for Build Multitenant B2b. It handles carriers logic.",
                "howItFits": "This process integrates with other components to handle process responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard process best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "svc-settings",
            "type": "process",
            "position": {
              "x": 900,
              "y": 850
            },
            "data": {
              "label": "Settings Service",
              "description": "Handles Settings logic",
              "color": "#8B5CF6",
              "nodeType": "process",
              "metadata": {
                "technology": "Node.js",
                "operations": [
                  "GET",
                  "GET",
                  "POST"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"Settings Service\" provides essential process functionality for Build Multitenant B2b. It handles settings logic.",
                "howItFits": "This process integrates with other components to handle process responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard process best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "db-organizations",
            "type": "data-store",
            "position": {
              "x": 1400,
              "y": 50
            },
            "data": {
              "label": "organizations",
              "description": "Relational Data Store",
              "color": "#EF4444",
              "nodeType": "data-store",
              "metadata": {
                "technology": "Postgres",
                "dataTypes": [
                  "uuid",
                  "varchar",
                  "varchar"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"organizations\" provides essential data-store functionality for Build Multitenant B2b. It relational data store.",
                "howItFits": "This data-store integrates with other components to handle data-store responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard data-store best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "db-organization-users",
            "type": "data-store",
            "position": {
              "x": 1400,
              "y": 250
            },
            "data": {
              "label": "organization_users",
              "description": "Relational Data Store",
              "color": "#EF4444",
              "nodeType": "data-store",
              "metadata": {
                "technology": "Postgres",
                "dataTypes": [
                  "uuid",
                  "uuid",
                  "uuid"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"organization_users\" provides essential data-store functionality for Build Multitenant B2b. It relational data store.",
                "howItFits": "This data-store integrates with other components to handle data-store responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard data-store best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "db-users",
            "type": "data-store",
            "position": {
              "x": 1400,
              "y": 450
            },
            "data": {
              "label": "users",
              "description": "Relational Data Store",
              "color": "#EF4444",
              "nodeType": "data-store",
              "metadata": {
                "technology": "Postgres",
                "dataTypes": [
                  "uuid",
                  "varchar",
                  "varchar"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"users\" provides essential data-store functionality for Build Multitenant B2b. It relational data store.",
                "howItFits": "This data-store integrates with other components to handle data-store responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard data-store best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "db-shipments",
            "type": "data-store",
            "position": {
              "x": 1400,
              "y": 650
            },
            "data": {
              "label": "shipments",
              "description": "Relational Data Store",
              "color": "#EF4444",
              "nodeType": "data-store",
              "metadata": {
                "technology": "Postgres",
                "dataTypes": [
                  "uuid",
                  "uuid",
                  "uuid"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"shipments\" provides essential data-store functionality for Build Multitenant B2b. It relational data store.",
                "howItFits": "This data-store integrates with other components to handle data-store responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard data-store best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "db-carriers",
            "type": "data-store",
            "position": {
              "x": 1400,
              "y": 850
            },
            "data": {
              "label": "carriers",
              "description": "Relational Data Store",
              "color": "#EF4444",
              "nodeType": "data-store",
              "metadata": {
                "technology": "Postgres",
                "dataTypes": [
                  "uuid",
                  "varchar",
                  "varchar"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"carriers\" provides essential data-store functionality for Build Multitenant B2b. It relational data store.",
                "howItFits": "This data-store integrates with other components to handle data-store responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard data-store best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "db-shipment-status",
            "type": "data-store",
            "position": {
              "x": 1400,
              "y": 1050
            },
            "data": {
              "label": "shipment_status",
              "description": "Relational Data Store",
              "color": "#EF4444",
              "nodeType": "data-store",
              "metadata": {
                "technology": "Postgres",
                "dataTypes": [
                  "uuid",
                  "uuid",
                  "varchar"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"shipment_status\" provides essential data-store functionality for Build Multitenant B2b. It relational data store.",
                "howItFits": "This data-store integrates with other components to handle data-store responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard data-store best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "ext-email",
            "type": "data-store",
            "position": {
              "x": 1400,
              "y": 150
            },
            "data": {
              "label": "Email Provider",
              "description": "SendGrid/SES",
              "color": "#F59E0B",
              "nodeType": "external-service",
              "metadata": {
                "technology": "SaaS",
                "operations": [
                  "API"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"Email Provider\" provides essential data-store functionality for Build Multitenant B2b. It sendgrid/ses.",
                "howItFits": "This data-store integrates with other components to handle data-store responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard data-store best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          },
          {
            "id": "ext-cache",
            "type": "data-store",
            "position": {
              "x": 1400,
              "y": 550
            },
            "data": {
              "label": "Redis Cache",
              "description": "Session Store",
              "color": "#F59E0B",
              "nodeType": "external-service",
              "metadata": {
                "technology": "SaaS",
                "operations": [
                  "API"
                ]
              },
              "aiExplanation": {
                "whyChosen": "\"Redis Cache\" provides essential data-store functionality for Build Multitenant B2b. It session store.",
                "howItFits": "This data-store integrates with other components to handle data-store responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
                "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
                "bestPractices": "Follow standard data-store best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
              }
            }
          }
        ],
        "edges": [
          {
            "id": "e-client-web-api-gateway",
            "source": "client-web",
            "target": "api-gateway",
            "label": "HTTPS",
            "type": "smoothstep",
            "animated": true,
            "style": {
              "stroke": "#9CA3AF",
              "strokeWidth": 2
            }
          },
          {
            "id": "e-client-mobile-api-gateway",
            "source": "client-mobile",
            "target": "api-gateway",
            "label": "HTTPS",
            "type": "smoothstep",
            "animated": true,
            "style": {
              "stroke": "#9CA3AF",
              "strokeWidth": 2
            }
          },
          {
            "id": "e-api-gateway-svc-authentication",
            "source": "api-gateway",
            "target": "svc-authentication",
            "type": "smoothstep",
            "animated": true,
            "style": {
              "stroke": "#10B981",
              "strokeWidth": 2
            }
          },
          {
            "id": "e-api-gateway-svc-organizations",
            "source": "api-gateway",
            "target": "svc-organizations",
            "type": "smoothstep",
            "animated": true,
            "style": {
              "stroke": "#10B981",
              "strokeWidth": 2
            }
          },
          {
            "id": "e-api-gateway-svc-shipments",
            "source": "api-gateway",
            "target": "svc-shipments",
            "type": "smoothstep",
            "animated": true,
            "style": {
              "stroke": "#10B981",
              "strokeWidth": 2
            }
          },
          {
            "id": "e-api-gateway-svc-carriers",
            "source": "api-gateway",
            "target": "svc-carriers",
            "type": "smoothstep",
            "animated": true,
            "style": {
              "stroke": "#10B981",
              "strokeWidth": 2
            }
          },
          {
            "id": "e-api-gateway-svc-settings",
            "source": "api-gateway",
            "target": "svc-settings",
            "type": "smoothstep",
            "animated": true,
            "style": {
              "stroke": "#10B981",
              "strokeWidth": 2
            }
          },
          {
            "id": "e-api-gateway-auth-service",
            "source": "api-gateway",
            "target": "auth-service",
            "label": "Validate",
            "type": "smoothstep",
            "style": {
              "strokeDasharray": "5,5",
              "stroke": "#F59E0B"
            }
          },
          {
            "id": "e-svc-authentication-db-organizations",
            "source": "svc-authentication",
            "target": "db-organizations",
            "label": "Query",
            "type": "smoothstep",
            "style": {
              "stroke": "#EF4444"
            }
          },
          {
            "id": "e-svc-organizations-db-organizations",
            "source": "svc-organizations",
            "target": "db-organizations",
            "label": "Query",
            "type": "smoothstep",
            "style": {
              "stroke": "#EF4444"
            }
          },
          {
            "id": "e-svc-shipments-db-shipments",
            "source": "svc-shipments",
            "target": "db-shipments",
            "label": "Query",
            "type": "smoothstep",
            "style": {
              "stroke": "#EF4444"
            }
          },
          {
            "id": "e-svc-carriers-db-carriers",
            "source": "svc-carriers",
            "target": "db-carriers",
            "label": "Query",
            "type": "smoothstep",
            "style": {
              "stroke": "#EF4444"
            }
          },
          {
            "id": "e-svc-settings-db-carriers",
            "source": "svc-settings",
            "target": "db-carriers",
            "label": "Query",
            "type": "smoothstep",
            "style": {
              "stroke": "#EF4444"
            }
          },
          {
            "id": "e-svc-authentication-ext-cache",
            "source": "svc-authentication",
            "target": "ext-cache",
            "label": "Cache Hit/Miss",
            "type": "smoothstep",
            "style": {
              "strokeDasharray": "5,5",
              "stroke": "#F59E0B"
            }
          }
        ],
        "metadata": {
          "totalNodes": 17,
          "totalFlows": 14,
          "encryptedFlows": 2,
          "createdAt": "2025-12-09T17:28:40.918Z"
        },
        "aiInsights": {
          "bottlenecks": [
            "Diagram generated using fallback heuristics due to AI timeout/error."
          ],
          "securityIssues": [],
          "cachingOpportunities": [],
          "transformationPoints": []
        }
      },
      "erd": {
        "id": "erd-1765301318361",
        "name": "Build Multitenant B2b - Entity Relationship Diagram",
        "nodes": [
          {
            "id": "table-organizations",
            "type": "default",
            "position": {
              "x": 100,
              "y": 100
            },
            "data": {
              "label": "organizations",
              "description": "Enterprise client organizations",
              "fields": [
                {
                  "name": "id",
                  "type": "uuid",
                  "isPrimaryKey": true,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": true
                },
                {
                  "name": "name",
                  "type": "varchar(255)",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "email",
                  "type": "varchar(320)",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": true,
                  "isNullable": false
                },
                {
                  "name": "created_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "updated_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "deleted_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": true
                }
              ],
              "color": "#6B7280",
              "indexes": [
                "unique on email"
              ],
              "constraints": [
                "CHECK (email LIKE '%@%')"
              ],
              "aiExplanation": {
                "whyChosen": "The \"organizations\" table is essential for storing enterprise client organizations in Build Multitenant B2b. It operates as an independent entity in the database schema.",
                "howItFits": "This table integrates into the Build Multitenant B2b data model with 6 fields, using id as primary key. It stores self-contained data without direct dependencies.",
                "tradeoffs": "Balanced field count supports maintainability. Independence from other tables simplifies queries but may require data duplication.",
                "bestPractices": "Follow standard database best practices:  Primary key defined,  1 index defined, ensure proper data types, add constraints where needed, and document the schema."
              }
            },
            "style": {
              "width": 280,
              "height": 304,
              "border": "2px solid #6B7280",
              "borderRadius": "8px",
              "padding": "12px",
              "backgroundColor": "#ffffff"
            }
          },
          {
            "id": "table-organization_users",
            "type": "default",
            "position": {
              "x": 500,
              "y": 100
            },
            "data": {
              "label": "organization_users",
              "description": "Organization user relationships",
              "fields": [
                {
                  "name": "id",
                  "type": "uuid",
                  "isPrimaryKey": true,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": true
                },
                {
                  "name": "organization_id",
                  "type": "uuid",
                  "isPrimaryKey": false,
                  "isForeignKey": true,
                  "isUnique": false,
                  "isNullable": false,
                  "references": {
                    "table": "organizations",
                    "field": "id"
                  }
                },
                {
                  "name": "user_id",
                  "type": "uuid",
                  "isPrimaryKey": false,
                  "isForeignKey": true,
                  "isUnique": false,
                  "isNullable": false,
                  "references": {
                    "table": "users",
                    "field": "id"
                  }
                },
                {
                  "name": "role",
                  "type": "varchar(50)",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "created_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "updated_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "deleted_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": true
                }
              ],
              "color": "#3B82F6",
              "indexes": [
                "btree on organization_id",
                "btree on user_id"
              ],
              "constraints": [],
              "aiExplanation": {
                "whyChosen": "The \"organization_users\" table is essential for storing organization user relationships in Build Multitenant B2b. It maintains relationships with other tables through foreign keys.",
                "howItFits": "This table integrates into the Build Multitenant B2b data model with 7 fields, using id as primary key. Its foreign key relationships ensure data integrity across the system.",
                "tradeoffs": "Balanced field count supports maintainability. Foreign key relationships ensure data integrity but may impact write performance.",
                "bestPractices": "Follow standard database best practices:  Primary key defined,  2 indexes defined,  Referential integrity via foreign keys, ensure proper data types, add constraints where needed, and document the schema."
              }
            },
            "style": {
              "width": 280,
              "height": 328,
              "border": "2px solid #3B82F6",
              "borderRadius": "8px",
              "padding": "12px",
              "backgroundColor": "#ffffff"
            }
          },
          {
            "id": "table-users",
            "type": "default",
            "position": {
              "x": 900,
              "y": 100
            },
            "data": {
              "label": "users",
              "description": "Platform users",
              "fields": [
                {
                  "name": "id",
                  "type": "uuid",
                  "isPrimaryKey": true,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": true
                },
                {
                  "name": "email",
                  "type": "varchar(320)",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": true,
                  "isNullable": false
                },
                {
                  "name": "password",
                  "type": "varchar(255)",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "created_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "updated_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "deleted_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": true
                }
              ],
              "color": "#3B82F6",
              "indexes": [
                "unique on email"
              ],
              "constraints": [
                "CHECK (email LIKE '%@%')"
              ],
              "aiExplanation": {
                "whyChosen": "The \"users\" table is essential for storing platform users in Build Multitenant B2b. It operates as an independent entity in the database schema.",
                "howItFits": "This table integrates into the Build Multitenant B2b data model with 6 fields, using id as primary key. It stores self-contained data without direct dependencies.",
                "tradeoffs": "Balanced field count supports maintainability. Independence from other tables simplifies queries but may require data duplication.",
                "bestPractices": "Follow standard database best practices:  Primary key defined,  1 index defined, ensure proper data types, add constraints where needed, and document the schema."
              }
            },
            "style": {
              "width": 280,
              "height": 304,
              "border": "2px solid #3B82F6",
              "borderRadius": "8px",
              "padding": "12px",
              "backgroundColor": "#ffffff"
            }
          },
          {
            "id": "table-shipments",
            "type": "default",
            "position": {
              "x": 100,
              "y": 400
            },
            "data": {
              "label": "shipments",
              "description": "Daily shipments",
              "fields": [
                {
                  "name": "id",
                  "type": "uuid",
                  "isPrimaryKey": true,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": true
                },
                {
                  "name": "organization_id",
                  "type": "uuid",
                  "isPrimaryKey": false,
                  "isForeignKey": true,
                  "isUnique": false,
                  "isNullable": false,
                  "references": {
                    "table": "organizations",
                    "field": "id"
                  }
                },
                {
                  "name": "carrier_id",
                  "type": "uuid",
                  "isPrimaryKey": false,
                  "isForeignKey": true,
                  "isUnique": false,
                  "isNullable": false,
                  "references": {
                    "table": "carriers",
                    "field": "id"
                  }
                },
                {
                  "name": "tracking_number",
                  "type": "varchar(255)",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": true,
                  "isNullable": false
                },
                {
                  "name": "created_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "updated_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "deleted_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": true
                }
              ],
              "color": "#6B7280",
              "indexes": [
                "btree on organization_id",
                "btree on carrier_id",
                "unique on tracking_number"
              ],
              "constraints": [],
              "aiExplanation": {
                "whyChosen": "The \"shipments\" table is essential for storing daily shipments in Build Multitenant B2b. It maintains relationships with other tables through foreign keys.",
                "howItFits": "This table integrates into the Build Multitenant B2b data model with 7 fields, using id as primary key. Its foreign key relationships ensure data integrity across the system.",
                "tradeoffs": "Balanced field count supports maintainability. Foreign key relationships ensure data integrity but may impact write performance.",
                "bestPractices": "Follow standard database best practices:  Primary key defined,  3 indexes defined,  Referential integrity via foreign keys, ensure proper data types, add constraints where needed, and document the schema."
              }
            },
            "style": {
              "width": 280,
              "height": 348,
              "border": "2px solid #6B7280",
              "borderRadius": "8px",
              "padding": "12px",
              "backgroundColor": "#ffffff"
            }
          },
          {
            "id": "table-carriers",
            "type": "default",
            "position": {
              "x": 500,
              "y": 400
            },
            "data": {
              "label": "carriers",
              "description": "Shipping carriers",
              "fields": [
                {
                  "name": "id",
                  "type": "uuid",
                  "isPrimaryKey": true,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": true
                },
                {
                  "name": "name",
                  "type": "varchar(255)",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "api_key",
                  "type": "varchar(255)",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "created_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "updated_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "deleted_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": true
                }
              ],
              "color": "#6B7280",
              "indexes": [
                "unique on name"
              ],
              "constraints": [],
              "aiExplanation": {
                "whyChosen": "The \"carriers\" table is essential for storing shipping carriers in Build Multitenant B2b. It operates as an independent entity in the database schema.",
                "howItFits": "This table integrates into the Build Multitenant B2b data model with 6 fields, using id as primary key. It stores self-contained data without direct dependencies.",
                "tradeoffs": "Balanced field count supports maintainability. Independence from other tables simplifies queries but may require data duplication.",
                "bestPractices": "Follow standard database best practices:  Primary key defined,  1 index defined, ensure proper data types, add constraints where needed, and document the schema."
              }
            },
            "style": {
              "width": 280,
              "height": 284,
              "border": "2px solid #6B7280",
              "borderRadius": "8px",
              "padding": "12px",
              "backgroundColor": "#ffffff"
            }
          },
          {
            "id": "table-shipment_status",
            "type": "default",
            "position": {
              "x": 900,
              "y": 400
            },
            "data": {
              "label": "shipment_status",
              "description": "Shipment status",
              "fields": [
                {
                  "name": "id",
                  "type": "uuid",
                  "isPrimaryKey": true,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": true
                },
                {
                  "name": "shipment_id",
                  "type": "uuid",
                  "isPrimaryKey": false,
                  "isForeignKey": true,
                  "isUnique": false,
                  "isNullable": false,
                  "references": {
                    "table": "shipments",
                    "field": "id"
                  }
                },
                {
                  "name": "status",
                  "type": "varchar(50)",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "created_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "updated_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "deleted_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": true
                }
              ],
              "color": "#6B7280",
              "indexes": [
                "btree on shipment_id"
              ],
              "constraints": [],
              "aiExplanation": {
                "whyChosen": "The \"shipment_status\" table is essential for storing shipment status in Build Multitenant B2b. It maintains relationships with other tables through foreign keys.",
                "howItFits": "This table integrates into the Build Multitenant B2b data model with 6 fields, using id as primary key. Its foreign key relationships ensure data integrity across the system.",
                "tradeoffs": "Balanced field count supports maintainability. Foreign key relationships ensure data integrity but may impact write performance.",
                "bestPractices": "Follow standard database best practices:  Primary key defined,  1 index defined,  Referential integrity via foreign keys, ensure proper data types, add constraints where needed, and document the schema."
              }
            },
            "style": {
              "width": 280,
              "height": 284,
              "border": "2px solid #6B7280",
              "borderRadius": "8px",
              "padding": "12px",
              "backgroundColor": "#ffffff"
            }
          },
          {
            "id": "table-shipment_locations",
            "type": "default",
            "position": {
              "x": 100,
              "y": 700
            },
            "data": {
              "label": "shipment_locations",
              "description": "Shipment locations",
              "fields": [
                {
                  "name": "id",
                  "type": "uuid",
                  "isPrimaryKey": true,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": true
                },
                {
                  "name": "shipment_id",
                  "type": "uuid",
                  "isPrimaryKey": false,
                  "isForeignKey": true,
                  "isUnique": false,
                  "isNullable": false,
                  "references": {
                    "table": "shipments",
                    "field": "id"
                  }
                },
                {
                  "name": "latitude",
                  "type": "decimal",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "longitude",
                  "type": "decimal",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "created_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "updated_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "deleted_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": true
                }
              ],
              "color": "#6B7280",
              "indexes": [
                "btree on shipment_id"
              ],
              "constraints": [],
              "aiExplanation": {
                "whyChosen": "The \"shipment_locations\" table is essential for storing shipment locations in Build Multitenant B2b. It maintains relationships with other tables through foreign keys.",
                "howItFits": "This table integrates into the Build Multitenant B2b data model with 7 fields, using id as primary key. Its foreign key relationships ensure data integrity across the system.",
                "tradeoffs": "Balanced field count supports maintainability. Foreign key relationships ensure data integrity but may impact write performance.",
                "bestPractices": "Follow standard database best practices:  Primary key defined,  1 index defined,  Referential integrity via foreign keys, ensure proper data types, add constraints where needed, and document the schema."
              }
            },
            "style": {
              "width": 280,
              "height": 308,
              "border": "2px solid #6B7280",
              "borderRadius": "8px",
              "padding": "12px",
              "backgroundColor": "#ffffff"
            }
          },
          {
            "id": "table-shipment_alerts",
            "type": "default",
            "position": {
              "x": 500,
              "y": 700
            },
            "data": {
              "label": "shipment_alerts",
              "description": "Shipment alerts",
              "fields": [
                {
                  "name": "id",
                  "type": "uuid",
                  "isPrimaryKey": true,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": true
                },
                {
                  "name": "shipment_id",
                  "type": "uuid",
                  "isPrimaryKey": false,
                  "isForeignKey": true,
                  "isUnique": false,
                  "isNullable": false,
                  "references": {
                    "table": "shipments",
                    "field": "id"
                  }
                },
                {
                  "name": "alert_type",
                  "type": "varchar(50)",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "created_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "updated_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "deleted_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": true
                }
              ],
              "color": "#6B7280",
              "indexes": [
                "btree on shipment_id"
              ],
              "constraints": [],
              "aiExplanation": {
                "whyChosen": "The \"shipment_alerts\" table is essential for storing shipment alerts in Build Multitenant B2b. It maintains relationships with other tables through foreign keys.",
                "howItFits": "This table integrates into the Build Multitenant B2b data model with 6 fields, using id as primary key. Its foreign key relationships ensure data integrity across the system.",
                "tradeoffs": "Balanced field count supports maintainability. Foreign key relationships ensure data integrity but may impact write performance.",
                "bestPractices": "Follow standard database best practices:  Primary key defined,  1 index defined,  Referential integrity via foreign keys, ensure proper data types, add constraints where needed, and document the schema."
              }
            },
            "style": {
              "width": 280,
              "height": 284,
              "border": "2px solid #6B7280",
              "borderRadius": "8px",
              "padding": "12px",
              "backgroundColor": "#ffffff"
            }
          },
          {
            "id": "table-settings",
            "type": "default",
            "position": {
              "x": 900,
              "y": 700
            },
            "data": {
              "label": "settings",
              "description": "Platform settings",
              "fields": [
                {
                  "name": "id",
                  "type": "uuid",
                  "isPrimaryKey": true,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": true
                },
                {
                  "name": "organization_id",
                  "type": "uuid",
                  "isPrimaryKey": false,
                  "isForeignKey": true,
                  "isUnique": false,
                  "isNullable": false,
                  "references": {
                    "table": "organizations",
                    "field": "id"
                  }
                },
                {
                  "name": "setting_key",
                  "type": "varchar(255)",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "setting_value",
                  "type": "varchar(255)",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "created_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "updated_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "deleted_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": true
                }
              ],
              "color": "#6B7280",
              "indexes": [
                "btree on organization_id"
              ],
              "constraints": [],
              "aiExplanation": {
                "whyChosen": "The \"settings\" table is essential for storing platform settings in Build Multitenant B2b. It maintains relationships with other tables through foreign keys.",
                "howItFits": "This table integrates into the Build Multitenant B2b data model with 7 fields, using id as primary key. Its foreign key relationships ensure data integrity across the system.",
                "tradeoffs": "Balanced field count supports maintainability. Foreign key relationships ensure data integrity but may impact write performance.",
                "bestPractices": "Follow standard database best practices:  Primary key defined,  1 index defined,  Referential integrity via foreign keys, ensure proper data types, add constraints where needed, and document the schema."
              }
            },
            "style": {
              "width": 280,
              "height": 308,
              "border": "2px solid #6B7280",
              "borderRadius": "8px",
              "padding": "12px",
              "backgroundColor": "#ffffff"
            }
          },
          {
            "id": "table-audit_logs",
            "type": "default",
            "position": {
              "x": 500,
              "y": 1000
            },
            "data": {
              "label": "audit_logs",
              "description": "Audit logs",
              "fields": [
                {
                  "name": "id",
                  "type": "uuid",
                  "isPrimaryKey": true,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": true
                },
                {
                  "name": "organization_id",
                  "type": "uuid",
                  "isPrimaryKey": false,
                  "isForeignKey": true,
                  "isUnique": false,
                  "isNullable": false,
                  "references": {
                    "table": "organizations",
                    "field": "id"
                  }
                },
                {
                  "name": "log_level",
                  "type": "varchar(50)",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "log_message",
                  "type": "text",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "created_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "updated_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": false
                },
                {
                  "name": "deleted_at",
                  "type": "timestamptz",
                  "isPrimaryKey": false,
                  "isForeignKey": false,
                  "isUnique": false,
                  "isNullable": true
                }
              ],
              "color": "#CA8A04",
              "indexes": [
                "btree on organization_id"
              ],
              "constraints": [],
              "aiExplanation": {
                "whyChosen": "The \"audit_logs\" table is essential for storing audit logs in Build Multitenant B2b. It maintains relationships with other tables through foreign keys.",
                "howItFits": "This table integrates into the Build Multitenant B2b data model with 7 fields, using id as primary key. Its foreign key relationships ensure data integrity across the system.",
                "tradeoffs": "Balanced field count supports maintainability. Foreign key relationships ensure data integrity but may impact write performance.",
                "bestPractices": "Follow standard database best practices:  Primary key defined,  1 index defined,  Referential integrity via foreign keys, ensure proper data types, add constraints where needed, and document the schema."
              }
            },
            "style": {
              "width": 280,
              "height": 308,
              "border": "2px solid #CA8A04",
              "borderRadius": "8px",
              "padding": "12px",
              "backgroundColor": "#ffffff"
            }
          }
        ],
        "edges": [
          {
            "id": "rel-1",
            "source": "table-organization_users",
            "target": "table-organizations",
            "type": "smoothstep",
            "label": "organization_id",
            "animated": true,
            "style": {
              "stroke": "#6B7280",
              "strokeWidth": 2
            },
            "markerEnd": {
              "type": "arrowclosed",
              "color": "#6B7280"
            },
            "data": {
              "sourceField": "organization_id",
              "targetField": "id",
              "relationType": "many-to-many"
            }
          },
          {
            "id": "rel-2",
            "source": "table-organization_users",
            "target": "table-users",
            "type": "smoothstep",
            "label": "user_id",
            "animated": true,
            "style": {
              "stroke": "#3B82F6",
              "strokeWidth": 2
            },
            "markerEnd": {
              "type": "arrowclosed",
              "color": "#3B82F6"
            },
            "data": {
              "sourceField": "user_id",
              "targetField": "id",
              "relationType": "many-to-many"
            }
          },
          {
            "id": "rel-3",
            "source": "table-shipments",
            "target": "table-organizations",
            "type": "smoothstep",
            "label": "organization_id",
            "animated": false,
            "style": {
              "stroke": "#6B7280",
              "strokeWidth": 2
            },
            "markerEnd": {
              "type": "arrowclosed",
              "color": "#6B7280"
            },
            "data": {
              "sourceField": "organization_id",
              "targetField": "id",
              "relationType": "one-to-many"
            }
          },
          {
            "id": "rel-4",
            "source": "table-shipments",
            "target": "table-carriers",
            "type": "smoothstep",
            "label": "carrier_id",
            "animated": false,
            "style": {
              "stroke": "#6B7280",
              "strokeWidth": 2
            },
            "markerEnd": {
              "type": "arrowclosed",
              "color": "#6B7280"
            },
            "data": {
              "sourceField": "carrier_id",
              "targetField": "id",
              "relationType": "one-to-many"
            }
          },
          {
            "id": "rel-5",
            "source": "table-shipment_status",
            "target": "table-shipments",
            "type": "smoothstep",
            "label": "shipment_id",
            "animated": true,
            "style": {
              "stroke": "#6B7280",
              "strokeWidth": 2
            },
            "markerEnd": {
              "type": "arrowclosed",
              "color": "#6B7280"
            },
            "data": {
              "sourceField": "shipment_id",
              "targetField": "id",
              "relationType": "many-to-many"
            }
          },
          {
            "id": "rel-6",
            "source": "table-shipment_locations",
            "target": "table-shipments",
            "type": "smoothstep",
            "label": "shipment_id",
            "animated": true,
            "style": {
              "stroke": "#6B7280",
              "strokeWidth": 2
            },
            "markerEnd": {
              "type": "arrowclosed",
              "color": "#6B7280"
            },
            "data": {
              "sourceField": "shipment_id",
              "targetField": "id",
              "relationType": "many-to-many"
            }
          },
          {
            "id": "rel-7",
            "source": "table-shipment_alerts",
            "target": "table-shipments",
            "type": "smoothstep",
            "label": "shipment_id",
            "animated": true,
            "style": {
              "stroke": "#6B7280",
              "strokeWidth": 2
            },
            "markerEnd": {
              "type": "arrowclosed",
              "color": "#6B7280"
            },
            "data": {
              "sourceField": "shipment_id",
              "targetField": "id",
              "relationType": "many-to-many"
            }
          },
          {
            "id": "rel-8",
            "source": "table-settings",
            "target": "table-organizations",
            "type": "smoothstep",
            "label": "organization_id",
            "animated": false,
            "style": {
              "stroke": "#6B7280",
              "strokeWidth": 2
            },
            "markerEnd": {
              "type": "arrowclosed",
              "color": "#6B7280"
            },
            "data": {
              "sourceField": "organization_id",
              "targetField": "id",
              "relationType": "one-to-many"
            }
          },
          {
            "id": "rel-9",
            "source": "table-audit_logs",
            "target": "table-organizations",
            "type": "smoothstep",
            "label": "organization_id",
            "animated": false,
            "style": {
              "stroke": "#6B7280",
              "strokeWidth": 2
            },
            "markerEnd": {
              "type": "arrowclosed",
              "color": "#6B7280"
            },
            "data": {
              "sourceField": "organization_id",
              "targetField": "id",
              "relationType": "one-to-many"
            }
          }
        ],
        "metadata": {
          "totalTables": 10,
          "totalRelationships": 9,
          "totalFields": 65,
          "createdAt": "2025-12-09T17:28:38.361Z"
        },
        "aiInsights": {
          "relationships": [
            {
              "from": "organizations",
              "to": "organization_users",
              "type": "one-to-many",
              "description": "An organization can have multiple users, but a user can be part of multiple organizations"
            },
            {
              "from": "organization_users",
              "to": "users",
              "type": "many-to-one",
              "description": "Multiple organization-user pairs can reference the same user"
            },
            {
              "from": "organizations",
              "to": "shipments",
              "type": "one-to-many",
              "description": "An organization can have multiple shipments"
            },
            {
              "from": "carriers",
              "to": "shipments",
              "type": "one-to-many",
              "description": "A carrier can handle multiple shipments"
            },
            {
              "from": "shipments",
              "to": "shipment_status",
              "type": "one-to-many",
              "description": "A shipment can have multiple status updates"
            },
            {
              "from": "shipments",
              "to": "shipment_locations",
              "type": "one-to-many",
              "description": "A shipment can have multiple location updates"
            },
            {
              "from": "shipments",
              "to": "shipment_alerts",
              "type": "one-to-many",
              "description": "A shipment can have multiple alerts"
            }
          ],
          "indexRecommendations": [
            {
              "table": "organization_users",
              "fields": [
                "user_id",
                "organization_id"
              ],
              "reason": "Frequent filtering and joining on these columns"
            },
            {
              "table": "shipments",
              "fields": [
                "organization_id",
                "carrier_id"
              ],
              "reason": "Frequent filtering on these columns"
            },
            {
              "table": "shipment_status",
              "fields": [
                "shipment_id",
                "status"
              ],
              "reason": "Frequent filtering on these columns"
            },
            {
              "table": "shipment_locations",
              "fields": [
                "shipment_id",
                "location"
              ],
              "reason": "Frequent filtering on these columns"
            }
          ],
          "normalizationIssues": [
            {
              "table": "shipments",
              "issue": "Storing carrier information in shipments table",
              "suggestion": "Store only carrier_id in shipments table and retrieve carrier details from carriers table"
            },
            {
              "table": "shipment_status",
              "issue": "Storing shipment information in shipment_status table",
              "suggestion": "Store only shipment_id in shipment_status table and retrieve shipment details from shipments table"
            }
          ],
          "performanceWarnings": [
            "Frequent inserts, updates, and deletes on large tables like shipments and shipment_status may lead to performance issues",
            "Lack of indexes on frequently filtered columns may lead to slow query performance",
            "High cardinality of columns like shipment_id in shipment_status and shipment_locations tables may lead to slow query performance"
          ]
        }
      },
      "apiMap": {
        "id": "api-map-1765301320300",
        "name": "Build Multitenant B2b - API Endpoints Map",
        "groups": [
          {
            "id": "group-authentication",
            "name": "Authentication",
            "endpoints": [
              {
                "id": "endpoint-authentication-0",
                "method": "POST",
                "path": "/api/v1/auth/login",
                "description": "User login - POST /api/v1/auth/login",
                "group": "Authentication",
                "requiresAuth": false,
                "requestBody": {
                  "email": "string",
                  "password": "string"
                },
                "responseType": "JSON",
                "statusCodes": [
                  200,
                  400,
                  401,
                  500
                ],
                "position": {
                  "x": 100,
                  "y": 100
                }
              },
              {
                "id": "endpoint-authentication-1",
                "method": "POST",
                "path": "/api/v1/auth/register",
                "description": "User registration - POST /api/v1/auth/register",
                "group": "Authentication",
                "requiresAuth": false,
                "requestBody": {
                  "email": "string",
                  "password": "string"
                },
                "responseType": "JSON",
                "statusCodes": [
                  200,
                  400,
                  401,
                  500
                ],
                "position": {
                  "x": 100,
                  "y": 180
                }
              }
            ],
            "color": "#F59E0B",
            "position": {
              "x": 100,
              "y": 100
            },
            "endpointPaths": [
              "POST /api/v1/auth/login",
              "POST /api/v1/auth/register"
            ],
            "description": "Authentication - 2 endpoints",
            "formattedEndpoints": "1. POST /api/v1/auth/login\n2. POST /api/v1/auth/register"
          },
          {
            "id": "group-organizations",
            "name": "Organizations",
            "endpoints": [
              {
                "id": "endpoint-organizations-0",
                "method": "GET",
                "path": "/api/v1/organizations",
                "description": "Get all organizations - GET /api/v1/organizations (Auth Required)",
                "group": "Organizations",
                "requiresAuth": true,
                "responseType": "JSON",
                "statusCodes": [
                  200,
                  400,
                  401,
                  500
                ],
                "position": {
                  "x": 550,
                  "y": 100
                }
              },
              {
                "id": "endpoint-organizations-1",
                "method": "GET",
                "path": "/api/v1/organizations/{organization_id}",
                "description": "Get organization by ID - GET /api/v1/organizations/{organization_id} (Auth Required)",
                "group": "Organizations",
                "requiresAuth": true,
                "responseType": "JSON",
                "statusCodes": [
                  200,
                  400,
                  401,
                  500
                ],
                "position": {
                  "x": 550,
                  "y": 180
                }
              },
              {
                "id": "endpoint-organizations-2",
                "method": "POST",
                "path": "/api/v1/organizations",
                "description": "Create new organization - POST /api/v1/organizations (Auth Required)",
                "group": "Organizations",
                "requiresAuth": true,
                "requestBody": {
                  "name": "string",
                  "email": "string"
                },
                "responseType": "JSON",
                "statusCodes": [
                  200,
                  400,
                  401,
                  500
                ],
                "position": {
                  "x": 550,
                  "y": 260
                }
              },
              {
                "id": "endpoint-organizations-3",
                "method": "PUT",
                "path": "/api/v1/organizations/{organization_id}",
                "description": "Update organization - PUT /api/v1/organizations/{organization_id} (Auth Required)",
                "group": "Organizations",
                "requiresAuth": true,
                "requestBody": {
                  "name": "string",
                  "email": "string"
                },
                "responseType": "JSON",
                "statusCodes": [
                  200,
                  400,
                  401,
                  500
                ],
                "position": {
                  "x": 550,
                  "y": 340
                }
              },
              {
                "id": "endpoint-organizations-4",
                "method": "DELETE",
                "path": "/api/v1/organizations/{organization_id}",
                "description": "Delete organization - DELETE /api/v1/organizations/{organization_id} (Auth Required)",
                "group": "Organizations",
                "requiresAuth": true,
                "responseType": "JSON",
                "statusCodes": [
                  200,
                  400,
                  401,
                  500
                ],
                "position": {
                  "x": 550,
                  "y": 420
                }
              }
            ],
            "color": "#6B7280",
            "position": {
              "x": 550,
              "y": 100
            },
            "endpointPaths": [
              "GET /api/v1/organizations",
              "GET /api/v1/organizations/{organization_id}",
              "POST /api/v1/organizations",
              "PUT /api/v1/organizations/{organization_id}",
              "DELETE /api/v1/organizations/{organization_id}"
            ],
            "description": "Organizations - 5 endpoints",
            "formattedEndpoints": "1. GET /api/v1/organizations\n2. GET /api/v1/organizations/{organization_id}\n3. POST /api/v1/organizations\n4. PUT /api/v1/organizations/{organization_id}\n5. DELETE /api/v1/organizations/{organization_id}"
          },
          {
            "id": "group-shipments",
            "name": "Shipments",
            "endpoints": [
              {
                "id": "endpoint-shipments-0",
                "method": "GET",
                "path": "/api/v1/shipments",
                "description": "Get all shipments - GET /api/v1/shipments (Auth Required)",
                "group": "Shipments",
                "requiresAuth": true,
                "responseType": "JSON",
                "statusCodes": [
                  200,
                  400,
                  401,
                  500
                ],
                "position": {
                  "x": 1000,
                  "y": 100
                }
              },
              {
                "id": "endpoint-shipments-1",
                "method": "GET",
                "path": "/api/v1/shipments/{shipment_id}",
                "description": "Get shipment by ID - GET /api/v1/shipments/{shipment_id} (Auth Required)",
                "group": "Shipments",
                "requiresAuth": true,
                "responseType": "JSON",
                "statusCodes": [
                  200,
                  400,
                  401,
                  500
                ],
                "position": {
                  "x": 1000,
                  "y": 180
                }
              },
              {
                "id": "endpoint-shipments-2",
                "method": "POST",
                "path": "/api/v1/shipments",
                "description": "Create new shipment - POST /api/v1/shipments (Auth Required)",
                "group": "Shipments",
                "requiresAuth": true,
                "requestBody": {
                  "organization_id": "uuid",
                  "carrier_id": "uuid",
                  "tracking_number": "string"
                },
                "responseType": "JSON",
                "statusCodes": [
                  200,
                  400,
                  401,
                  500
                ],
                "position": {
                  "x": 1000,
                  "y": 260
                }
              },
              {
                "id": "endpoint-shipments-3",
                "method": "PUT",
                "path": "/api/v1/shipments/{shipment_id}",
                "description": "Update shipment - PUT /api/v1/shipments/{shipment_id} (Auth Required)",
                "group": "Shipments",
                "requiresAuth": true,
                "requestBody": {
                  "organization_id": "uuid",
                  "carrier_id": "uuid",
                  "tracking_number": "string"
                },
                "responseType": "JSON",
                "statusCodes": [
                  200,
                  400,
                  401,
                  500
                ],
                "position": {
                  "x": 1000,
                  "y": 340
                }
              },
              {
                "id": "endpoint-shipments-4",
                "method": "DELETE",
                "path": "/api/v1/shipments/{shipment_id}",
                "description": "Delete shipment - DELETE /api/v1/shipments/{shipment_id} (Auth Required)",
                "group": "Shipments",
                "requiresAuth": true,
                "responseType": "JSON",
                "statusCodes": [
                  200,
                  400,
                  401,
                  500
                ],
                "position": {
                  "x": 1000,
                  "y": 420
                }
              }
            ],
            "color": "#6B7280",
            "position": {
              "x": 1000,
              "y": 100
            },
            "endpointPaths": [
              "GET /api/v1/shipments",
              "GET /api/v1/shipments/{shipment_id}",
              "POST /api/v1/shipments",
              "PUT /api/v1/shipments/{shipment_id}",
              "DELETE /api/v1/shipments/{shipment_id}"
            ],
            "description": "Shipments - 5 endpoints",
            "formattedEndpoints": "1. GET /api/v1/shipments\n2. GET /api/v1/shipments/{shipment_id}\n3. POST /api/v1/shipments\n4. PUT /api/v1/shipments/{shipment_id}\n5. DELETE /api/v1/shipments/{shipment_id}"
          },
          {
            "id": "group-carriers",
            "name": "Carriers",
            "endpoints": [
              {
                "id": "endpoint-carriers-0",
                "method": "GET",
                "path": "/api/v1/carriers",
                "description": "Get all carriers - GET /api/v1/carriers (Auth Required)",
                "group": "Carriers",
                "requiresAuth": true,
                "responseType": "JSON",
                "statusCodes": [
                  200,
                  400,
                  401,
                  500
                ],
                "position": {
                  "x": 100,
                  "y": 460
                }
              },
              {
                "id": "endpoint-carriers-1",
                "method": "GET",
                "path": "/api/v1/carriers/{carrier_id}",
                "description": "Get carrier by ID - GET /api/v1/carriers/{carrier_id} (Auth Required)",
                "group": "Carriers",
                "requiresAuth": true,
                "responseType": "JSON",
                "statusCodes": [
                  200,
                  400,
                  401,
                  500
                ],
                "position": {
                  "x": 100,
                  "y": 540
                }
              },
              {
                "id": "endpoint-carriers-2",
                "method": "POST",
                "path": "/api/v1/carriers",
                "description": "Create new carrier - POST /api/v1/carriers (Auth Required)",
                "group": "Carriers",
                "requiresAuth": true,
                "requestBody": {
                  "name": "string",
                  "api_key": "string"
                },
                "responseType": "JSON",
                "statusCodes": [
                  200,
                  400,
                  401,
                  500
                ],
                "position": {
                  "x": 100,
                  "y": 620
                }
              },
              {
                "id": "endpoint-carriers-3",
                "method": "PUT",
                "path": "/api/v1/carriers/{carrier_id}",
                "description": "Update carrier - PUT /api/v1/carriers/{carrier_id} (Auth Required)",
                "group": "Carriers",
                "requiresAuth": true,
                "requestBody": {
                  "name": "string",
                  "api_key": "string"
                },
                "responseType": "JSON",
                "statusCodes": [
                  200,
                  400,
                  401,
                  500
                ],
                "position": {
                  "x": 100,
                  "y": 700
                }
              },
              {
                "id": "endpoint-carriers-4",
                "method": "DELETE",
                "path": "/api/v1/carriers/{carrier_id}",
                "description": "Delete carrier - DELETE /api/v1/carriers/{carrier_id} (Auth Required)",
                "group": "Carriers",
                "requiresAuth": true,
                "responseType": "JSON",
                "statusCodes": [
                  200,
                  400,
                  401,
                  500
                ],
                "position": {
                  "x": 100,
                  "y": 780
                }
              }
            ],
            "color": "#6B7280",
            "position": {
              "x": 100,
              "y": 460
            },
            "endpointPaths": [
              "GET /api/v1/carriers",
              "GET /api/v1/carriers/{carrier_id}",
              "POST /api/v1/carriers",
              "PUT /api/v1/carriers/{carrier_id}",
              "DELETE /api/v1/carriers/{carrier_id}"
            ],
            "description": "Carriers - 5 endpoints",
            "formattedEndpoints": "1. GET /api/v1/carriers\n2. GET /api/v1/carriers/{carrier_id}\n3. POST /api/v1/carriers\n4. PUT /api/v1/carriers/{carrier_id}\n5. DELETE /api/v1/carriers/{carrier_id}"
          },
          {
            "id": "group-settings",
            "name": "Settings",
            "endpoints": [
              {
                "id": "endpoint-settings-0",
                "method": "GET",
                "path": "/api/v1/settings",
                "description": "Get all settings - GET /api/v1/settings (Auth Required)",
                "group": "Settings",
                "requiresAuth": true,
                "responseType": "JSON",
                "statusCodes": [
                  200,
                  400,
                  401,
                  500
                ],
                "position": {
                  "x": 550,
                  "y": 460
                }
              },
              {
                "id": "endpoint-settings-1",
                "method": "GET",
                "path": "/api/v1/settings/{setting_id}",
                "description": "Get setting by ID - GET /api/v1/settings/{setting_id} (Auth Required)",
                "group": "Settings",
                "requiresAuth": true,
                "responseType": "JSON",
                "statusCodes": [
                  200,
                  400,
                  401,
                  500
                ],
                "position": {
                  "x": 550,
                  "y": 540
                }
              },
              {
                "id": "endpoint-settings-2",
                "method": "POST",
                "path": "/api/v1/settings",
                "description": "Create new setting - POST /api/v1/settings (Auth Required)",
                "group": "Settings",
                "requiresAuth": true,
                "requestBody": {
                  "organization_id": "uuid",
                  "setting_key": "string",
                  "setting_value": "string"
                },
                "responseType": "JSON",
                "statusCodes": [
                  200,
                  400,
                  401,
                  500
                ],
                "position": {
                  "x": 550,
                  "y": 620
                }
              },
              {
                "id": "endpoint-settings-3",
                "method": "PUT",
                "path": "/api/v1/settings/{setting_id}",
                "description": "Update setting - PUT /api/v1/settings/{setting_id} (Auth Required)",
                "group": "Settings",
                "requiresAuth": true,
                "requestBody": {
                  "organization_id": "uuid",
                  "setting_key": "string",
                  "setting_value": "string"
                },
                "responseType": "JSON",
                "statusCodes": [
                  200,
                  400,
                  401,
                  500
                ],
                "position": {
                  "x": 550,
                  "y": 700
                }
              },
              {
                "id": "endpoint-settings-4",
                "method": "DELETE",
                "path": "/api/v1/settings/{setting_id}",
                "description": "Delete setting - DELETE /api/v1/settings/{setting_id} (Auth Required)",
                "group": "Settings",
                "requiresAuth": true,
                "responseType": "JSON",
                "statusCodes": [
                  200,
                  400,
                  401,
                  500
                ],
                "position": {
                  "x": 550,
                  "y": 780
                }
              }
            ],
            "color": "#6B7280",
            "position": {
              "x": 550,
              "y": 460
            },
            "endpointPaths": [
              "GET /api/v1/settings",
              "GET /api/v1/settings/{setting_id}",
              "POST /api/v1/settings",
              "PUT /api/v1/settings/{setting_id}",
              "DELETE /api/v1/settings/{setting_id}"
            ],
            "description": "Settings - 5 endpoints",
            "formattedEndpoints": "1. GET /api/v1/settings\n2. GET /api/v1/settings/{setting_id}\n3. POST /api/v1/settings\n4. PUT /api/v1/settings/{setting_id}\n5. DELETE /api/v1/settings/{setting_id}"
          }
        ],
        "flows": [
          {
            "id": "flow-1",
            "source": "group-authentication",
            "target": "group-organizations",
            "method": "HTTP",
            "label": "Authentication  Organizations: API workflow connection"
          },
          {
            "id": "flow-2",
            "source": "group-organizations",
            "target": "group-shipments",
            "method": "HTTP",
            "label": "Organizations  Shipments: API workflow connection"
          },
          {
            "id": "flow-3",
            "source": "group-shipments",
            "target": "group-carriers",
            "method": "HTTP",
            "label": "Shipments  Carriers: API workflow connection"
          },
          {
            "id": "flow-4",
            "source": "group-carriers",
            "target": "group-settings",
            "method": "HTTP",
            "label": "Carriers  Settings: API workflow connection"
          }
        ],
        "metadata": {
          "totalEndpoints": 22,
          "totalGroups": 5,
          "authEndpoints": 20,
          "publicEndpoints": 2,
          "createdAt": "2025-12-09T17:28:40.300Z"
        }
      }
    },
    "endpoints": [
      {
        "method": "POST",
        "path": "/api/v1/auth/login",
        "description": "User login",
        "body": {
          "email": "string",
          "password": "string"
        },
        "auth": false,
        "group": "Authentication"
      },
      {
        "method": "POST",
        "path": "/api/v1/auth/register",
        "description": "User registration",
        "body": {
          "email": "string",
          "password": "string"
        },
        "auth": false,
        "group": "Authentication"
      },
      {
        "method": "GET",
        "path": "/api/v1/organizations",
        "description": "Get all organizations",
        "auth": true,
        "group": "Organizations"
      },
      {
        "method": "GET",
        "path": "/api/v1/organizations/{organization_id}",
        "description": "Get organization by ID",
        "auth": true,
        "group": "Organizations"
      },
      {
        "method": "POST",
        "path": "/api/v1/organizations",
        "description": "Create new organization",
        "body": {
          "name": "string",
          "email": "string"
        },
        "auth": true,
        "group": "Organizations"
      },
      {
        "method": "PUT",
        "path": "/api/v1/organizations/{organization_id}",
        "description": "Update organization",
        "body": {
          "name": "string",
          "email": "string"
        },
        "auth": true,
        "group": "Organizations"
      },
      {
        "method": "DELETE",
        "path": "/api/v1/organizations/{organization_id}",
        "description": "Delete organization",
        "auth": true,
        "group": "Organizations"
      },
      {
        "method": "GET",
        "path": "/api/v1/shipments",
        "description": "Get all shipments",
        "auth": true,
        "group": "Shipments"
      },
      {
        "method": "GET",
        "path": "/api/v1/shipments/{shipment_id}",
        "description": "Get shipment by ID",
        "auth": true,
        "group": "Shipments"
      },
      {
        "method": "POST",
        "path": "/api/v1/shipments",
        "description": "Create new shipment",
        "body": {
          "organization_id": "uuid",
          "carrier_id": "uuid",
          "tracking_number": "string"
        },
        "auth": true,
        "group": "Shipments"
      },
      {
        "method": "PUT",
        "path": "/api/v1/shipments/{shipment_id}",
        "description": "Update shipment",
        "body": {
          "organization_id": "uuid",
          "carrier_id": "uuid",
          "tracking_number": "string"
        },
        "auth": true,
        "group": "Shipments"
      },
      {
        "method": "DELETE",
        "path": "/api/v1/shipments/{shipment_id}",
        "description": "Delete shipment",
        "auth": true,
        "group": "Shipments"
      },
      {
        "method": "GET",
        "path": "/api/v1/carriers",
        "description": "Get all carriers",
        "auth": true,
        "group": "Carriers"
      },
      {
        "method": "GET",
        "path": "/api/v1/carriers/{carrier_id}",
        "description": "Get carrier by ID",
        "auth": true,
        "group": "Carriers"
      },
      {
        "method": "POST",
        "path": "/api/v1/carriers",
        "description": "Create new carrier",
        "body": {
          "name": "string",
          "api_key": "string"
        },
        "auth": true,
        "group": "Carriers"
      },
      {
        "method": "PUT",
        "path": "/api/v1/carriers/{carrier_id}",
        "description": "Update carrier",
        "body": {
          "name": "string",
          "api_key": "string"
        },
        "auth": true,
        "group": "Carriers"
      },
      {
        "method": "DELETE",
        "path": "/api/v1/carriers/{carrier_id}",
        "description": "Delete carrier",
        "auth": true,
        "group": "Carriers"
      },
      {
        "method": "GET",
        "path": "/api/v1/settings",
        "description": "Get all settings",
        "auth": true,
        "group": "Settings"
      },
      {
        "method": "GET",
        "path": "/api/v1/settings/{setting_id}",
        "description": "Get setting by ID",
        "auth": true,
        "group": "Settings"
      },
      {
        "method": "POST",
        "path": "/api/v1/settings",
        "description": "Create new setting",
        "body": {
          "organization_id": "uuid",
          "setting_key": "string",
          "setting_value": "string"
        },
        "auth": true,
        "group": "Settings"
      },
      {
        "method": "PUT",
        "path": "/api/v1/settings/{setting_id}",
        "description": "Update setting",
        "body": {
          "organization_id": "uuid",
          "setting_key": "string",
          "setting_value": "string"
        },
        "auth": true,
        "group": "Settings"
      },
      {
        "method": "DELETE",
        "path": "/api/v1/settings/{setting_id}",
        "description": "Delete setting",
        "auth": true,
        "group": "Settings"
      }
    ],
    "database": {
      "type": "postgresql",
      "reasoning": "Recommended for this use case",
      "confidence": 0.9,
      "features": [
        "ACID compliance",
        "Complex queries",
        "Scalability"
      ]
    },
    "architecture": {
      "id": "arch-1765301322151",
      "name": "Build Multitenant B2b System Architecture",
      "description": "Moderate architecture with 25 components",
      "nodes": [
        {
          "id": "cdn-1",
          "type": "cdn",
          "position": {
            "x": 100,
            "y": 100
          },
          "data": {
            "name": "Content Delivery Network",
            "description": "Distributes frontend assets",
            "color": "#0891B2",
            "metadata": {
              "layer": "Layer 0 (Client)",
              "layerIndex": 0
            },
            "aiExplanation": {
              "whyChosen": "\"Content Delivery Network\" provides essential cdn functionality for Build Multitenant B2b. It distributes frontend assets.",
              "howItFits": "This cdn integrates with other components to handle cdn responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard cdn best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "build-multitenant-b2b-frontend-1",
          "type": "frontend",
          "position": {
            "x": 100,
            "y": 300
          },
          "data": {
            "name": "Build Multitenant B2b Frontend",
            "description": "Handles client-side logic",
            "color": "#3B82F6",
            "metadata": {
              "layer": "Layer 0 (Client)",
              "layerIndex": 0
            },
            "aiExplanation": {
              "whyChosen": "\"Build Multitenant B2b Frontend\" provides essential frontend functionality for Build Multitenant B2b. It handles client-side logic.",
              "howItFits": "This frontend integrates with other components to handle frontend responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard frontend best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "mobile-1",
          "type": "mobile",
          "position": {
            "x": 100,
            "y": 500
          },
          "data": {
            "name": "Mobile Application",
            "description": "Provides mobile access to the application",
            "color": "#06B6D4",
            "metadata": {
              "layer": "Layer 0 (Client)",
              "layerIndex": 0
            },
            "aiExplanation": {
              "whyChosen": "\"Mobile Application\" provides essential mobile functionality for Build Multitenant B2b. It provides mobile access to the application.",
              "howItFits": "This mobile integrates with other components to handle mobile responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard mobile best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "load-balancer-1",
          "type": "load-balancer",
          "position": {
            "x": 500,
            "y": 100
          },
          "data": {
            "name": "Load Balancer",
            "description": "Routes traffic to services",
            "color": "#10B981",
            "metadata": {
              "layer": "Layer 1 (Gateway)",
              "layerIndex": 1
            },
            "aiExplanation": {
              "whyChosen": "\"Load Balancer\" provides essential load-balancer functionality for Build Multitenant B2b. It routes traffic to services.",
              "howItFits": "This load-balancer integrates with other components to handle load-balancer responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard load-balancer best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "api-gateway-1",
          "type": "api-gateway",
          "position": {
            "x": 500,
            "y": 300
          },
          "data": {
            "name": "API Gateway",
            "description": "Handles API requests and routing",
            "color": "#059669",
            "metadata": {
              "layer": "Layer 1 (Gateway)",
              "layerIndex": 1
            },
            "aiExplanation": {
              "whyChosen": "\"API Gateway\" provides essential api-gateway functionality for Build Multitenant B2b. It handles api requests and routing.",
              "howItFits": "This api-gateway integrates with other components to handle api-gateway responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's request routing.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard api-gateway best practices for configuration and deployment: configure rate limiting, implement authentication, enable logging."
            }
          }
        },
        {
          "id": "authentication-1",
          "type": "authentication",
          "position": {
            "x": 500,
            "y": 500
          },
          "data": {
            "name": "Authentication",
            "description": "Handles authentication operations",
            "color": "#F59E0B",
            "metadata": {
              "layer": "Layer 1 (Gateway)",
              "layerIndex": 1
            },
            "aiExplanation": {
              "whyChosen": "\"Authentication\" provides essential authentication functionality for Build Multitenant B2b. It handles authentication operations.",
              "howItFits": "This authentication integrates with other components to handle authentication responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard authentication best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "authentication-service-1",
          "type": "api-service",
          "position": {
            "x": 900,
            "y": 100
          },
          "data": {
            "name": "Authentication Service",
            "description": "Handles 2 POST endpoints for authentication management",
            "color": "#8B5CF6",
            "metadata": {
              "layer": "Layer 2 (Application)",
              "layerIndex": 2
            },
            "aiExplanation": {
              "whyChosen": "\"Authentication Service\" provides essential api-service functionality for Build Multitenant B2b. It handles 2 post endpoints for authentication management.",
              "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
              "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
            }
          }
        },
        {
          "id": "organizations-service-1",
          "type": "api-service",
          "position": {
            "x": 900,
            "y": 300
          },
          "data": {
            "name": "Organizations Service",
            "description": "Manages organizations table via 5 endpoints (GET, POST, PUT, DELETE)",
            "color": "#8B5CF6",
            "metadata": {
              "layer": "Layer 2 (Application)",
              "layerIndex": 2
            },
            "aiExplanation": {
              "whyChosen": "\"Organizations Service\" provides essential api-service functionality for Build Multitenant B2b. It manages organizations table via 5 endpoints (get, post, put, delete).",
              "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
              "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
            }
          }
        },
        {
          "id": "shipments-service-1",
          "type": "api-service",
          "position": {
            "x": 900,
            "y": 500
          },
          "data": {
            "name": "Shipments Service",
            "description": "Manages shipments table via 5 endpoints (GET, POST, PUT, DELETE)",
            "color": "#8B5CF6",
            "metadata": {
              "layer": "Layer 2 (Application)",
              "layerIndex": 2
            },
            "aiExplanation": {
              "whyChosen": "\"Shipments Service\" provides essential api-service functionality for Build Multitenant B2b. It manages shipments table via 5 endpoints (get, post, put, delete).",
              "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
              "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
            }
          }
        },
        {
          "id": "carriers-service-1",
          "type": "api-service",
          "position": {
            "x": 900,
            "y": 700
          },
          "data": {
            "name": "Carriers Service",
            "description": "Manages carriers table via 5 endpoints (GET, POST, PUT, DELETE)",
            "color": "#8B5CF6",
            "metadata": {
              "layer": "Layer 2 (Application)",
              "layerIndex": 2
            },
            "aiExplanation": {
              "whyChosen": "\"Carriers Service\" provides essential api-service functionality for Build Multitenant B2b. It manages carriers table via 5 endpoints (get, post, put, delete).",
              "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
              "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
            }
          }
        },
        {
          "id": "settings-service-1",
          "type": "api-service",
          "position": {
            "x": 900,
            "y": 900
          },
          "data": {
            "name": "Settings Service",
            "description": "Manages settings table via 5 endpoints (GET, POST, PUT, DELETE)",
            "color": "#8B5CF6",
            "metadata": {
              "layer": "Layer 2 (Application)",
              "layerIndex": 2
            },
            "aiExplanation": {
              "whyChosen": "\"Settings Service\" provides essential api-service functionality for Build Multitenant B2b. It manages settings table via 5 endpoints (get, post, put, delete).",
              "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
              "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
            }
          }
        },
        {
          "id": "cache-1",
          "type": "cache",
          "position": {
            "x": 900,
            "y": 1100
          },
          "data": {
            "name": "Cache",
            "description": "Improves performance by caching frequently accessed data",
            "color": "#DC2626",
            "metadata": {
              "layer": "Layer 2 (Application)",
              "layerIndex": 2
            },
            "aiExplanation": {
              "whyChosen": "\"Cache\" provides essential cache functionality for Build Multitenant B2b. It improves performance by caching frequently accessed data.",
              "howItFits": "This cache integrates with other components to handle cache responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's performance optimization.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Caching improves speed but requires cache invalidation strategy.",
              "bestPractices": "Follow standard cache best practices for configuration and deployment: set appropriate TTLs, implement cache warming, monitor hit rates."
            }
          }
        },
        {
          "id": "queue-1",
          "type": "queue",
          "position": {
            "x": 900,
            "y": 1300
          },
          "data": {
            "name": "Message Queue",
            "description": "Handles asynchronous tasks and messaging",
            "color": "#F97316",
            "metadata": {
              "layer": "Layer 2 (Application)",
              "layerIndex": 2
            },
            "aiExplanation": {
              "whyChosen": "\"Message Queue\" provides essential queue functionality for Build Multitenant B2b. It handles asynchronous tasks and messaging.",
              "howItFits": "This queue integrates with other components to handle queue responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard queue best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "database-1",
          "type": "database",
          "position": {
            "x": 1300,
            "y": 100
          },
          "data": {
            "name": "PostgreSQL Database",
            "description": "Stores data in the following tables: organizations, organization_users, users, shipments, carriers, shipment_status, shipment_locations, shipment_alerts, settings, audit_logs",
            "color": "#EF4444",
            "metadata": {
              "layer": "Layer 3 (Data)",
              "layerIndex": 3
            },
            "aiExplanation": {
              "whyChosen": "\"PostgreSQL Database\" provides essential database functionality for Build Multitenant B2b. It stores data in the following tables: organizations, organization_users, users, shipments, carriers, shipment_status, shipment_locations, shipment_alerts, settings, audit_logs.",
              "howItFits": "This database integrates with other components to handle database responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's data persistence.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Centralized data storage ensures consistency but may become a bottleneck.",
              "bestPractices": "Follow standard database best practices for configuration and deployment: optimize queries, implement backup strategies, use connection pooling."
            }
          }
        },
        {
          "id": "search-engine-1",
          "type": "search-engine",
          "position": {
            "x": 1300,
            "y": 300
          },
          "data": {
            "name": "Search Engine",
            "description": "Provides full-text search capabilities",
            "color": "#B45309",
            "metadata": {
              "layer": "Layer 3 (Data)",
              "layerIndex": 3
            },
            "aiExplanation": {
              "whyChosen": "\"Search Engine\" provides essential search-engine functionality for Build Multitenant B2b. It provides full-text search capabilities.",
              "howItFits": "This search-engine integrates with other components to handle search-engine responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard search-engine best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "storage-1",
          "type": "backup-storage",
          "position": {
            "x": 1300,
            "y": 500
          },
          "data": {
            "name": "Storage",
            "description": "Stores and retrieves files and assets",
            "color": "#4B5563",
            "metadata": {
              "layer": "Layer 3 (Data)",
              "layerIndex": 3
            },
            "aiExplanation": {
              "whyChosen": "\"Storage\" provides essential backup-storage functionality for Build Multitenant B2b. It stores and retrieves files and assets.",
              "howItFits": "This backup-storage integrates with other components to handle backup-storage responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard backup-storage best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "replica-1",
          "type": "database",
          "position": {
            "x": 1300,
            "y": 700
          },
          "data": {
            "name": "Database Replica",
            "description": "Provides a read-only replica of the primary database",
            "color": "#EF4444",
            "metadata": {
              "layer": "Layer 3 (Data)",
              "layerIndex": 3
            },
            "aiExplanation": {
              "whyChosen": "\"Database Replica\" provides essential database functionality for Build Multitenant B2b. It provides a read-only replica of the primary database.",
              "howItFits": "This database integrates with other components to handle database responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's data persistence.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Centralized data storage ensures consistency but may become a bottleneck.",
              "bestPractices": "Follow standard database best practices for configuration and deployment: optimize queries, implement backup strategies, use connection pooling."
            }
          }
        },
        {
          "id": "monitoring-1",
          "type": "monitoring",
          "position": {
            "x": 1700,
            "y": 100
          },
          "data": {
            "name": "Monitoring",
            "description": "Tracks system performance and health",
            "color": "#EA580C",
            "metadata": {
              "layer": "Layer 4 (Infrastructure)",
              "layerIndex": 4
            },
            "aiExplanation": {
              "whyChosen": "\"Monitoring\" provides essential monitoring functionality for Build Multitenant B2b. It tracks system performance and health.",
              "howItFits": "This monitoring integrates with other components to handle monitoring responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard monitoring best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "logging-1",
          "type": "logging",
          "position": {
            "x": 1700,
            "y": 300
          },
          "data": {
            "name": "Logging",
            "description": "Handles log collection and analysis",
            "color": "#CA8A04",
            "metadata": {
              "layer": "Layer 4 (Infrastructure)",
              "layerIndex": 4
            },
            "aiExplanation": {
              "whyChosen": "\"Logging\" provides essential logging functionality for Build Multitenant B2b. It handles log collection and analysis.",
              "howItFits": "This logging integrates with other components to handle logging responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard logging best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "notifications-1",
          "type": "notification-service",
          "position": {
            "x": 1700,
            "y": 500
          },
          "data": {
            "name": "Notifications",
            "description": "Sends notifications to users and administrators",
            "color": "#8B5CF6",
            "metadata": {
              "layer": "Layer 4 (Infrastructure)",
              "layerIndex": 4
            },
            "aiExplanation": {
              "whyChosen": "\"Notifications\" provides essential notification-service functionality for Build Multitenant B2b. It sends notifications to users and administrators.",
              "howItFits": "This notification-service integrates with other components to handle notification-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
              "bestPractices": "Follow standard notification-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
            }
          }
        },
        {
          "id": "analytics-1",
          "type": "analytics",
          "position": {
            "x": 1700,
            "y": 700
          },
          "data": {
            "name": "Analytics",
            "description": "Provides insights into system usage and performance",
            "color": "#7C3AED",
            "metadata": {
              "layer": "Layer 4 (Infrastructure)",
              "layerIndex": 4
            },
            "aiExplanation": {
              "whyChosen": "\"Analytics\" provides essential analytics functionality for Build Multitenant B2b. It provides insights into system usage and performance.",
              "howItFits": "This analytics integrates with other components to handle analytics responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard analytics best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "ci-cd-1",
          "type": "ci-cd",
          "position": {
            "x": 2100,
            "y": 100
          },
          "data": {
            "name": "CI/CD Pipeline",
            "description": "Automates build, test, and deployment processes",
            "color": "#059669",
            "metadata": {
              "layer": "Layer 5 (DevOps)",
              "layerIndex": 5
            },
            "aiExplanation": {
              "whyChosen": "\"CI/CD Pipeline\" provides essential ci-cd functionality for Build Multitenant B2b. It automates build, test, and deployment processes.",
              "howItFits": "This ci-cd integrates with other components to handle ci-cd responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard ci-cd best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "secrets-manager-1",
          "type": "secrets-manager",
          "position": {
            "x": 2100,
            "y": 300
          },
          "data": {
            "name": "Secrets Manager",
            "description": "Stores and manages sensitive data",
            "color": "#374151",
            "metadata": {
              "layer": "Layer 5 (DevOps)",
              "layerIndex": 5
            },
            "aiExplanation": {
              "whyChosen": "\"Secrets Manager\" provides essential secrets-manager functionality for Build Multitenant B2b. It stores and manages sensitive data.",
              "howItFits": "This secrets-manager integrates with other components to handle secrets-manager responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard secrets-manager best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "backup-1",
          "type": "backup-storage",
          "position": {
            "x": 2100,
            "y": 500
          },
          "data": {
            "name": "Backup",
            "description": "Stores and retrieves backups of the system",
            "color": "#4B5563",
            "metadata": {
              "layer": "Layer 5 (DevOps)",
              "layerIndex": 5
            },
            "aiExplanation": {
              "whyChosen": "\"Backup\" provides essential backup-storage functionality for Build Multitenant B2b. It stores and retrieves backups of the system.",
              "howItFits": "This backup-storage integrates with other components to handle backup-storage responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard backup-storage best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "container-registry-1",
          "type": "container-registry",
          "position": {
            "x": 2100,
            "y": 700
          },
          "data": {
            "name": "Container Registry",
            "description": "Stores and manages container images",
            "color": "#6B7280",
            "metadata": {
              "layer": "Layer 5 (DevOps)",
              "layerIndex": 5
            },
            "aiExplanation": {
              "whyChosen": "\"Container Registry\" provides essential container-registry functionality for Build Multitenant B2b. It stores and manages container images.",
              "howItFits": "This container-registry integrates with other components to handle container-registry responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard container-registry best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        }
      ],
      "edges": [
        {
          "id": "edge-cdn-1-build-multitenant-b2b-frontend-1-0",
          "source": "cdn-1",
          "target": "build-multitenant-b2b-frontend-1",
          "label": "GET Frontend Assets"
        },
        {
          "id": "edge-build-multitenant-b2b-frontend-1-load-balancer-1-1",
          "source": "build-multitenant-b2b-frontend-1",
          "target": "load-balancer-1",
          "label": "GET/POST/PATCH Frontend Requests"
        },
        {
          "id": "edge-load-balancer-1-api-gateway-1-2",
          "source": "load-balancer-1",
          "target": "api-gateway-1",
          "label": "POST/GET API Requests"
        },
        {
          "id": "edge-api-gateway-1-authentication-1-3",
          "source": "api-gateway-1",
          "target": "authentication-1",
          "label": "POST Authentication Data"
        },
        {
          "id": "edge-api-gateway-1-authentication-service-1-4",
          "source": "api-gateway-1",
          "target": "authentication-service-1",
          "label": "POST Authentication Data"
        },
        {
          "id": "edge-api-gateway-1-organizations-service-1-5",
          "source": "api-gateway-1",
          "target": "organizations-service-1",
          "label": "GET/POST Organizations Data"
        },
        {
          "id": "edge-api-gateway-1-shipments-service-1-6",
          "source": "api-gateway-1",
          "target": "shipments-service-1",
          "label": "GET/POST Shipments Data"
        },
        {
          "id": "edge-api-gateway-1-carriers-service-1-7",
          "source": "api-gateway-1",
          "target": "carriers-service-1",
          "label": "GET/POST Carriers Data"
        },
        {
          "id": "edge-api-gateway-1-settings-service-1-8",
          "source": "api-gateway-1",
          "target": "settings-service-1",
          "label": "GET/POST Settings Data"
        },
        {
          "id": "edge-organizations-service-1-database-1-9",
          "source": "organizations-service-1",
          "target": "database-1",
          "label": "GET/POST Organizations Table"
        },
        {
          "id": "edge-shipments-service-1-database-1-10",
          "source": "shipments-service-1",
          "target": "database-1",
          "label": "GET/POST Shipments Table"
        },
        {
          "id": "edge-carriers-service-1-database-1-11",
          "source": "carriers-service-1",
          "target": "database-1",
          "label": "GET/POST Carriers Table"
        },
        {
          "id": "edge-settings-service-1-database-1-12",
          "source": "settings-service-1",
          "target": "database-1",
          "label": "GET/POST Settings Table"
        },
        {
          "id": "edge-database-1-replica-1-13",
          "source": "database-1",
          "target": "replica-1",
          "label": "Replication Data"
        },
        {
          "id": "edge-database-1-search-engine-1-14",
          "source": "database-1",
          "target": "search-engine-1",
          "label": "Search Indexing"
        },
        {
          "id": "edge-ci-cd-1-container-registry-1-15",
          "source": "ci-cd-1",
          "target": "container-registry-1",
          "label": "Image Deployment"
        },
        {
          "id": "edge-ci-cd-1-load-balancer-1-16",
          "source": "ci-cd-1",
          "target": "load-balancer-1",
          "label": "Deployment"
        },
        {
          "id": "edge-secrets-manager-1-ci-cd-1-17",
          "source": "secrets-manager-1",
          "target": "ci-cd-1",
          "label": "Secrets Injection"
        }
      ],
      "metadata": {
        "createdAt": "2025-12-09T17:28:42.151Z",
        "updatedAt": "2025-12-09T17:28:42.151Z",
        "version": "2.0.0",
        "aiGenerated": true,
        "complexity": "Moderate",
        "scalingStrategy": "Horizontal",
        "securityLevel": "Standard"
      }
    },
    "decisions": {
      "projectName": "Task Manager",
      "architecture": {
        "complexity": "moderate",
        "components": 25,
        "estimatedCost": {
          "development": "$50,000",
          "monthly": "$500",
          "annual": "$6,000"
        },
        "timeline": {
          "mvp": "16 weeks",
          "production": "24 weeks",
          "scale": "36 weeks"
        }
      },
      "decisions": [
        {
          "id": "decision-database",
          "title": "Database Selection",
          "description": "Choose the best database solution for storing task data, user information, and real-time sync with strong ACID compliance and query performance",
          "category": "database",
          "component": "database",
          "recommendations": [
            {
              "id": "postgresql",
              "category": "Database",
              "component": "database",
              "name": "PostgreSQL",
              "type": "open-source",
              "description": "Advanced open-source relational database with excellent ACID compliance, rich feature set including JSON support, full-text search, and extensibility through custom functions and extensions",
              "pros": [
                "ACID compliant for transaction safety",
                "Rich feature set with JSON and JSONB support",
                "Strong community and extensive documentation",
                "Excellent performance for complex queries",
                "Free and open-source"
              ],
              "cons": [
                "Memory intensive for large datasets",
                "Complex configuration and tuning required",
                "Steeper learning curve compared to MySQL"
              ],
              "pricing": {
                "model": "free",
                "cost": "",
                "details": "Free to use, hosting and infrastructure costs vary"
              },
              "complexity": "medium",
              "popularity": 95,
              "documentation": "Excellent",
              "alternatives": [
                "MySQL",
                "Amazon RDS PostgreSQL",
                "Azure Database for PostgreSQL"
              ],
              "integration": {
                "effort": "low",
                "timeEstimate": "1-2 days",
                "dependencies": [
                  "Node.js pg driver",
                  "Connection pooling library",
                  "Database migration tool"
                ]
              },
              "metadata": {
                "website": "https://postgresql.org",
                "github": "https://github.com/postgres/postgres",
                "cloudProvider": "",
                "supportLevel": "community"
              },
              "enterpriseScore": 88
            },
            {
              "id": "amazon-aurora",
              "category": "Database",
              "component": "database",
              "name": "Amazon Aurora",
              "type": "managed-service",
              "description": "Cloud-native relational database with MySQL and PostgreSQL compatibility, offering 5x performance improvement with automated backups, auto-scaling storage, and multi-AZ deployments",
              "pros": [
                "High performance with 5x MySQL throughput",
                "Auto-scaling storage up to 128TB",
                "Continuous backup to S3",
                "Multi-AZ high availability",
                "Serverless option available"
              ],
              "cons": [
                "AWS vendor lock-in",
                "Higher cost than standard RDS",
                "Complex pricing model",
                "Limited to AWS ecosystem"
              ],
              "pricing": {
                "model": "usage-based",
                "cost": "$100-500/month",
                "details": "Pay for compute, storage, and I/O separately. Costs scale with usage."
              },
              "complexity": "low",
              "popularity": 82,
              "documentation": "Excellent",
              "alternatives": [
                "Google Cloud Spanner",
                "Azure SQL Database",
                "CockroachDB"
              ],
              "integration": {
                "effort": "low",
                "timeEstimate": "1-2 days",
                "dependencies": [
                  "AWS VPC configuration",
                  "Parameter groups",
                  "Security groups",
                  "IAM roles"
                ]
              },
              "metadata": {
                "website": "https://aws.amazon.com/aurora/",
                "github": "",
                "cloudProvider": "AWS",
                "supportLevel": "enterprise"
              },
              "enterpriseScore": 91
            },
            {
              "id": "mongodb",
              "category": "Database",
              "component": "database",
              "name": "MongoDB",
              "type": "open-source",
              "description": "Document-oriented NoSQL database with flexible schema design, horizontal scaling capabilities, and rich query language for handling unstructured data",
              "pros": [
                "Schema flexibility for rapid iteration",
                "Horizontal scaling with sharding",
                "Rich query language with aggregation",
                "Strong ecosystem and tooling",
                "Good for unstructured data"
              ],
              "cons": [
                "Higher memory usage",
                "No ACID transactions across documents",
                "Learning curve for query optimization",
                "Potential data consistency issues"
              ],
              "pricing": {
                "model": "freemium",
                "cost": "",
                "details": "Community edition free, Enterprise features and Atlas managed service paid"
              },
              "complexity": "medium",
              "popularity": 89,
              "documentation": "Excellent",
              "alternatives": [
                "Amazon DocumentDB",
                "Azure Cosmos DB",
                "CouchDB"
              ],
              "integration": {
                "effort": "low",
                "timeEstimate": "1-2 days",
                "dependencies": [
                  "MongoDB driver",
                  "Schema design",
                  "Index optimization"
                ]
              },
              "metadata": {
                "website": "https://www.mongodb.com",
                "github": "https://github.com/mongodb/mongo",
                "cloudProvider": "",
                "supportLevel": "commercial"
              },
              "enterpriseScore": 84
            },
            {
              "id": "mysql",
              "category": "Database",
              "component": "database",
              "name": "MySQL",
              "type": "open-source",
              "description": "Popular open-source relational database known for reliability, ease of use, and wide adoption in web applications with strong read performance",
              "pros": [
                "Easy to learn and use",
                "Wide adoption and support",
                "Good read performance",
                "Mature replication features",
                "Large community"
              ],
              "cons": [
                "Limited advanced features vs PostgreSQL",
                "Weaker support for complex queries",
                "Less flexible indexing options"
              ],
              "pricing": {
                "model": "free",
                "cost": "",
                "details": "Free and open-source, hosting costs vary"
              },
              "complexity": "low",
              "popularity": 93,
              "documentation": "Excellent",
              "alternatives": [
                "MariaDB",
                "Amazon RDS MySQL",
                "Percona Server"
              ],
              "integration": {
                "effort": "low",
                "timeEstimate": "1 day",
                "dependencies": [
                  "MySQL driver",
                  "Connection pooling"
                ]
              },
              "metadata": {
                "website": "https://www.mysql.com",
                "github": "https://github.com/mysql/mysql-server",
                "cloudProvider": "",
                "supportLevel": "community"
              },
              "enterpriseScore": 86
            }
          ],
          "selectedTool": "postgresql",
          "reasoning": "PostgreSQL is recommended for this task manager application due to its strong ACID compliance ensuring data integrity for transactions, excellent support for complex queries needed for task management, and JSON support for flexible task attributes. The open-source nature keeps costs low while providing enterprise-grade features. Strong community support and extensive documentation reduce development risk.",
          "impact": "high",
          "urgency": "critical"
        },
        {
          "id": "decision-cloud-provider",
          "title": "Cloud Infrastructure Selection",
          "description": "Select the cloud platform that will host the entire application infrastructure, providing compute, storage, networking, and managed services",
          "category": "infrastructure",
          "component": "cloud-provider",
          "recommendations": [
            {
              "id": "aws",
              "category": "Cloud Infrastructure",
              "component": "cloud-provider",
              "name": "Amazon Web Services (AWS)",
              "type": "managed-service",
              "description": "Leading cloud platform with the most comprehensive service portfolio including EC2, S3, RDS, Lambda, and 200+ services for building scalable applications",
              "pros": [
                "Largest service portfolio in the industry",
                "Global presence with 30+ regions",
                "Mature ecosystem with extensive tooling",
                "Enterprise-grade security and compliance",
                "Strong marketplace and partner network"
              ],
              "cons": [
                "Complex pricing can be difficult to predict",
                "Steep learning curve for beginners",
                "Potential vendor lock-in",
                "Can become expensive without optimization"
              ],
              "pricing": {
                "model": "usage-based",
                "cost": "Variable",
                "details": "Pay-as-you-go for most services, reserved instances available for cost savings"
              },
              "complexity": "high",
              "popularity": 94,
              "documentation": "Excellent",
              "alternatives": [
                "Google Cloud Platform",
                "Microsoft Azure",
                "DigitalOcean"
              ],
              "integration": {
                "effort": "medium",
                "timeEstimate": "1-2 weeks",
                "dependencies": [
                  "AWS account setup",
                  "IAM roles and policies",
                  "VPC network configuration",
                  "Security groups"
                ]
              },
              "metadata": {
                "website": "https://aws.amazon.com",
                "github": "",
                "cloudProvider": "AWS",
                "supportLevel": "enterprise"
              },
              "enterpriseScore": 92
            },
            {
              "id": "gcp",
              "category": "Cloud Infrastructure",
              "component": "cloud-provider",
              "name": "Google Cloud Platform",
              "type": "managed-service",
              "description": "Google's cloud platform with strong AI/ML capabilities, competitive pricing, and excellent Kubernetes support through GKE",
              "pros": [
                "Strong AI/ML services and BigQuery",
                "Competitive pricing (20-30% cheaper than AWS)",
                "Excellent Kubernetes support with GKE",
                "Simple and predictable pricing",
                "Strong focus on developer experience"
              ],
              "cons": [
                "Smaller service ecosystem than AWS",
                "Less enterprise adoption",
                "Frequent service changes and deprecations",
                "Smaller partner ecosystem"
              ],
              "pricing": {
                "model": "usage-based",
                "cost": "Variable",
                "details": "Generally 20-30% cheaper than AWS for compute and storage with sustained use discounts"
              },
              "complexity": "medium",
              "popularity": 78,
              "documentation": "Good",
              "alternatives": [
                "AWS",
                "Microsoft Azure",
                "IBM Cloud"
              ],
              "integration": {
                "effort": "medium",
                "timeEstimate": "1-2 weeks",
                "dependencies": [
                  "GCP account",
                  "Service accounts",
                  "VPC setup",
                  "IAM policies"
                ]
              },
              "metadata": {
                "website": "https://cloud.google.com",
                "github": "",
                "cloudProvider": "GCP",
                "supportLevel": "enterprise"
              },
              "enterpriseScore": 85
            },
            {
              "id": "azure",
              "category": "Cloud Infrastructure",
              "component": "cloud-provider",
              "name": "Microsoft Azure",
              "type": "managed-service",
              "description": "Microsoft's cloud platform with excellent enterprise integration, strong hybrid cloud capabilities, and deep integration with Microsoft products",
              "pros": [
                "Excellent Microsoft product integration",
                "Strong hybrid cloud capabilities",
                "Enterprise-focused features",
                "Good compliance certifications",
                "Active Directory integration"
              ],
              "cons": [
                "Complex portal interface",
                "Service reliability concerns",
                "Pricing complexity",
                "Inconsistent API design"
              ],
              "pricing": {
                "model": "usage-based",
                "cost": "Variable",
                "details": "Competitive with AWS, good discounts for Microsoft customers with Enterprise Agreements"
              },
              "complexity": "medium",
              "popularity": 82,
              "documentation": "Good",
              "alternatives": [
                "AWS",
                "Google Cloud Platform",
                "Oracle Cloud"
              ],
              "integration": {
                "effort": "medium",
                "timeEstimate": "1-2 weeks",
                "dependencies": [
                  "Azure subscription",
                  "Resource groups",
                  "Active Directory setup",
                  "Virtual networks"
                ]
              },
              "metadata": {
                "website": "https://azure.microsoft.com",
                "github": "",
                "cloudProvider": "Azure",
                "supportLevel": "enterprise"
              },
              "enterpriseScore": 87
            }
          ],
          "selectedTool": "aws",
          "reasoning": "AWS is recommended as the cloud provider due to its comprehensive service portfolio that can support all components of the task manager application, mature ecosystem with proven reliability at scale, and strong marketplace for third-party integrations. While pricing is complex, the extensive documentation and large community make it easier to optimize costs. The global presence ensures low latency for customers worldwide.",
          "impact": "high",
          "urgency": "critical"
        },
        {
          "id": "decision-api-gateway",
          "title": "API Gateway Selection",
          "description": "Choose the API gateway that will handle incoming requests, provide security, and route traffic to backend services",
          "category": "infrastructure",
          "component": "api-gateway",
          "recommendations": [
            {
              "id": "aws-api-gateway",
              "category": "API Gateway",
              "component": "api-gateway",
              "name": "AWS API Gateway",
              "type": "managed-service",
              "description": "Fully managed API gateway with REST, WebSocket, and HTTP APIs, supporting Lambda, EC2, and Elastic Beanstalk integrations",
              "pros": [
                "Tight integration with AWS services",
                "Support for REST, WebSocket, and HTTP APIs",
                "Security features like IAM roles and API keys",
                "Scalability and high availability",
                "Monitoring and analytics"
              ],
              "cons": [
                "Pricing complexity",
                "Steep learning curve",
                "Vendor lock-in",
                "Limited support for non-AWS services"
              ],
              "pricing": {
                "model": "usage-based",
                "cost": "$3.50 per million API calls",
                "details": "Pay for API calls, data transfer, and cache storage"
              },
              "complexity": "medium",
              "popularity": 85,
              "documentation": "Excellent",
              "alternatives": [
                "NGINX",
                "Kong",
                "Azure API Management"
              ],
              "integration": {
                "effort": "medium",
                "timeEstimate": "2-3 days",
                "dependencies": [
                  "AWS account",
                  "IAM roles",
                  "API Gateway setup"
                ]
              },
              "metadata": {
                "website": "https://aws.amazon.com/api-gateway/",
                "github": "",
                "cloudProvider": "AWS",
                "supportLevel": "enterprise"
              },
              "enterpriseScore": 88
            },
            {
              "id": "kong",
              "category": "API Gateway",
              "component": "api-gateway",
              "name": "Kong",
              "type": "open-source",
              "description": "Open-source API gateway with service discovery, load balancing, and security features, supporting multiple protocols and plug-ins",
              "pros": [
                "Highly customizable",
                "Support for multiple protocols",
                "Service discovery and load balancing",
                "Security features like authentication and rate limiting",
                "Free and open-source"
              ],
              "cons": [
                "Complex setup and configuration",
                "Resource intensive",
                "Limited support for non-open-source plugins"
              ],
              "pricing": {
                "model": "free",
                "cost": "",
                "details": "Free to use, support and enterprise features paid"
              },
              "complexity": "high",
              "popularity": 80,
              "documentation": "Good",
              "alternatives": [
                "NGINX",
                "AWS API Gateway",
                "Azure API Management"
              ],
              "integration": {
                "effort": "high",
                "timeEstimate": "3-5 days",
                "dependencies": [
                  "Kong setup",
                  "Plugin installation",
                  "Configuration"
                ]
              },
              "metadata": {
                "website": "https://konghq.com",
                "github": "https://github.com/Kong/kong",
                "cloudProvider": "",
                "supportLevel": "community"
              },
              "enterpriseScore": 82
            },
            {
              "id": "nginx",
              "category": "API Gateway",
              "component": "api-gateway",
              "name": "NGINX",
              "type": "open-source",
              "description": "Popular open-source web server with API gateway capabilities, supporting load balancing, caching, and security features",
              "pros": [
                "Highly customizable",
                "Support for load balancing and caching",
                "Security features like SSL/TLS and access control",
                "Free and open-source",
                "Large community"
              ],
              "cons": [
                "Complex setup and configuration",
                "Limited support for non-web protocols",
                "Resource intensive"
              ],
              "pricing": {
                "model": "free",
                "cost": "",
                "details": "Free to use, support and enterprise features paid"
              },
              "complexity": "high",
              "popularity": 90,
              "documentation": "Excellent",
              "alternatives": [
                "Kong",
                "AWS API Gateway",
                "Azure API Management"
              ],
              "integration": {
                "effort": "high",
                "timeEstimate": "3-5 days",
                "dependencies": [
                  "NGINX setup",
                  "Configuration",
                  "Plugin installation"
                ]
              },
              "metadata": {
                "website": "https://www.nginx.com",
                "github": "https://github.com/nginx/nginx",
                "cloudProvider": "",
                "supportLevel": "community"
              },
              "enterpriseScore": 85
            }
          ],
          "selectedTool": "aws-api-gateway",
          "reasoning": "AWS API Gateway is recommended for its tight integration with AWS services, support for REST, WebSocket, and HTTP APIs, and security features like IAM roles and API keys. The scalability and high availability ensure that the API gateway can handle a large volume of requests.",
          "impact": "medium",
          "urgency": "recommended"
        },
        {
          "id": "decision-authentication",
          "title": "Authentication Service Selection",
          "description": "Choose the authentication service that will handle user authentication and authorization",
          "category": "security",
          "component": "authentication",
          "recommendations": [
            {
              "id": "aws-cognito",
              "category": "Authentication",
              "component": "authentication",
              "name": "AWS Cognito",
              "type": "managed-service",
              "description": "Fully managed authentication service with user pools, identity pools, and federated identities, supporting multiple protocols and integrations",
              "pros": [
                "Tight integration with AWS services",
                "Support for multiple protocols",
                "Federated identities and social login",
                "Security features like MFA and password policies",
                "Scalability and high availability"
              ],
              "cons": [
                "Pricing complexity",
                "Steep learning curve",
                "Vendor lock-in",
                "Limited support for non-AWS services"
              ],
              "pricing": {
                "model": "usage-based",
                "cost": "$0.0055 per user-month",
                "details": "Pay for active users, data storage, and SMS messages"
              },
              "complexity": "medium",
              "popularity": 80,
              "documentation": "Excellent",
              "alternatives": [
                "Auth0",
                "Okta",
                "Google Cloud Identity"
              ],
              "integration": {
                "effort": "medium",
                "timeEstimate": "2-3 days",
                "dependencies": [
                  "AWS account",
                  "IAM roles",
                  "Cognito setup"
                ]
              },
              "metadata": {
                "website": "https://aws.amazon.com/cognito/",
                "github": "",
                "cloudProvider": "AWS",
                "supportLevel": "enterprise"
              },
              "enterpriseScore": 85
            },
            {
              "id": "auth0",
              "category": "Authentication",
              "component": "authentication",
              "name": "Auth0",
              "type": "commercial",
              "description": "Universal authentication platform with social login, MFA, and passwordless authentication, supporting multiple protocols and integrations",
              "pros": [
                "Highly customizable",
                "Support for multiple protocols",
                "Social login and MFA",
                "Passwordless authentication",
                "Good documentation and support"
              ],
              "cons": [
                "Pricing complexity",
                "Steep learning curve",
                "Limited support for non-web protocols"
              ],
              "pricing": {
                "model": "subscription",
                "cost": "$99-499/month",
                "details": "Pay for active users, features, and support"
              },
              "complexity": "high",
              "popularity": 85,
              "documentation": "Excellent",
              "alternatives": [
                "AWS Cognito",
                "Okta",
                "Google Cloud Identity"
              ],
              "integration": {
                "effort": "high",
                "timeEstimate": "3-5 days",
                "dependencies": [
                  "Auth0 setup",
                  "Configuration",
                  "Integration with backend"
                ]
              },
              "metadata": {
                "website": "https://auth0.com",
                "github": "https://github.com/auth0",
                "cloudProvider": "",
                "supportLevel": "commercial"
              },
              "enterpriseScore": 88
            },
            {
              "id": "okta",
              "category": "Authentication",
              "component": "authentication",
              "name": "Okta",
              "type": "commercial",
              "description": "Cloud-based identity and access management platform with single sign-on, MFA, and user lifecycle management, supporting multiple protocols and integrations",
              "pros": [
                "Highly customizable",
                "Support for multiple protocols",
                "Single sign-on and MFA",
                "User lifecycle management",
                "Good documentation and support"
              ],
              "cons": [
                "Pricing complexity",
                "Steep learning curve",
                "Limited support for non-web protocols"
              ],
              "pricing": {
                "model": "subscription",
                "cost": "$1-5 per user-month",
                "details": "Pay for active users, features, and support"
              },
              "complexity": "high",
              "popularity": 80,
              "documentation": "Excellent",
              "alternatives": [
                "Auth0",
                "AWS Cognito",
                "Google Cloud Identity"
              ],
              "integration": {
                "effort": "high",
                "timeEstimate": "3-5 days",
                "dependencies": [
                  "Okta setup",
                  "Configuration",
                  "Integration with backend"
                ]
              },
              "metadata": {
                "website": "https://www.okta.com",
                "github": "https://github.com/okta",
                "cloudProvider": "",
                "supportLevel": "commercial"
              },
              "enterpriseScore": 87
            }
          ],
          "selectedTool": "aws-cognito",
          "reasoning": "AWS Cognito is recommended for its tight integration with AWS services, support for multiple protocols, and security features like MFA and password policies. The scalability and high availability ensure that the authentication service can handle a large volume of requests.",
          "impact": "medium",
          "urgency": "recommended"
        },
        {
          "id": "decision-cache",
          "title": "Cache Layer Selection",
          "description": "Choose the cache layer that will improve application performance by reducing database queries and improving response times",
          "category": "infrastructure",
          "component": "cache",
          "recommendations": [
            {
              "id": "redis",
              "category": "Cache",
              "component": "cache",
              "name": "Redis",
              "type": "open-source",
              "description": "In-memory data store with high performance, supporting multiple data structures and protocols",
              "pros": [
                "High performance and low latency",
                "Support for multiple data structures",
                "Pub/sub messaging and transactions",
                "Free and open-source",
                "Large community"
              ],
              "cons": [
                "Limited persistence and data durability",
                "Complex setup and configuration",
                "Resource intensive"
              ],
              "pricing": {
                "model": "free",
                "cost": "",
                "details": "Free to use, support and enterprise features paid"
              },
              "complexity": "high",
              "popularity": 90,
              "documentation": "Excellent",
              "alternatives": [
                "Memcached",
                "Amazon ElastiCache",
                "Google Cloud Memorystore"
              ],
              "integration": {
                "effort": "high",
                "timeEstimate": "3-5 days",
                "dependencies": [
                  "Redis setup",
                  "Configuration",
                  "Integration with backend"
                ]
              },
              "metadata": {
                "website": "https://redis.io",
                "github": "https://github.com/redis/redis",
                "cloudProvider": "",
                "supportLevel": "community"
              },
              "enterpriseScore": 85
            },
            {
              "id": "memcached",
              "category": "Cache",
              "component": "cache",
              "name": "Memcached",
              "type": "open-source",
              "description": "High-performance, distributed memory object caching system with simple protocol and small codebase",
              "pros": [
                "High performance and low latency",
                "Simple protocol and small codebase",
                "Free and open-source",
                "Large community"
              ],
              "cons": [
                "Limited features and functionality",
                "No support for multiple data structures",
                "Limited persistence and data durability"
              ],
              "pricing": {
                "model": "free",
                "cost": "",
                "details": "Free to use, support and enterprise features paid"
              },
              "complexity": "medium",
              "popularity": 80,
              "documentation": "Good",
              "alternatives": [
                "Redis",
                "Amazon ElastiCache",
                "Google Cloud Memorystore"
              ],
              "integration": {
                "effort": "medium",
                "timeEstimate": "2-3 days",
                "dependencies": [
                  "Memcached setup",
                  "Configuration",
                  "Integration with backend"
                ]
              },
              "metadata": {
                "website": "https://memcached.org",
                "github": "https://github.com/memcached/memcached",
                "cloudProvider": "",
                "supportLevel": "community"
              },
              "enterpriseScore": 80
            },
            {
              "id": "amazon-elasticache",
              "category": "Cache",
              "component": "cache",
              "name": "Amazon ElastiCache",
              "type": "managed-service",
              "description": "Fully managed in-memory cache service with support for Redis and Memcached, offering high performance and low latency",
              "pros": [
                "High performance and low latency",
                "Support for Redis and Memcached",
                "Fully managed service with automatic patching and backups",
                "Scalability and high availability",
                "Tight integration with AWS services"
              ],
              "cons": [
                "Pricing complexity",
                "Steep learning curve",
                "Vendor lock-in",
                "Limited support for non-AWS services"
              ],
              "pricing": {
                "model": "usage-based",
                "cost": "$0.0175 per hour",
                "details": "Pay for cache node hours, data transfer, and storage"
              },
              "complexity": "medium",
              "popularity": 85,
              "documentation": "Excellent",
              "alternatives": [
                "Redis",
                "Memcached",
                "Google Cloud Memorystore"
              ],
              "integration": {
                "effort": "medium",
                "timeEstimate": "2-3 days",
                "dependencies": [
                  "AWS account",
                  "IAM roles",
                  "ElastiCache setup"
                ]
              },
              "metadata": {
                "website": "https://aws.amazon.com/elasticache/",
                "github": "",
                "cloudProvider": "AWS",
                "supportLevel": "enterprise"
              },
              "enterpriseScore": 88
            }
          ],
          "selectedTool": "redis",
          "reasoning": "Redis is recommended for its high performance and low latency, support for multiple data structures, and pub/sub messaging and transactions. The open-source nature and large community ensure that the cache layer can be customized and extended as needed.",
          "impact": "medium",
          "urgency": "recommended"
        },
        {
          "id": "decision-search-engine",
          "title": "Search Engine Selection",
          "description": "Choose the search engine that will provide full-text search capabilities for the application",
          "category": "infrastructure",
          "component": "search-engine",
          "recommendations": [
            {
              "id": "elasticsearch",
              "category": "Search Engine",
              "component": "search-engine",
              "name": "Elasticsearch",
              "type": "open-source",
              "description": "Popular open-source search and analytics engine with high performance, scalability, and support for multiple data formats",
              "pros": [
                "High performance and scalability",
                "Support for multiple data formats",
                "Full-text search and filtering",
                "Free and open-source",
                "Large community"
              ],
              "cons": [
                "Complex setup and configuration",
                "Resource intensive",
                "Limited support for non-search use cases"
              ],
              "pricing": {
                "model": "free",
                "cost": "",
                "details": "Free to use, support and enterprise features paid"
              },
              "complexity": "high",
              "popularity": 90,
              "documentation": "Excellent",
              "alternatives": [
                "Apache Solr",
                "Amazon CloudSearch",
                "Google Cloud Search"
              ],
              "integration": {
                "effort": "high",
                "timeEstimate": "3-5 days",
                "dependencies": [
                  "Elasticsearch setup",
                  "Configuration",
                  "Integration with backend"
                ]
              },
              "metadata": {
                "website": "https://www.elastic.co",
                "github": "https://github.com/elastic/elasticsearch",
                "cloudProvider": "",
                "supportLevel": "community"
              },
              "enterpriseScore": 85
            },
            {
              "id": "apache-solr",
              "category": "Search Engine",
              "component": "search-engine",
              "name": "Apache Solr",
              "type": "open-source",
              "description": "Popular open-source search engine with high performance, scalability, and support for multiple data formats",
              "pros": [
                "High performance and scalability",
                "Support for multiple data formats",
                "Full-text search and filtering",
                "Free and open-source",
                "Large community"
              ],
              "cons": [
                "Complex setup and configuration",
                "Resource intensive",
                "Limited support for non-search use cases"
              ],
              "pricing": {
                "model": "free",
                "cost": "",
                "details": "Free to use, support and enterprise features paid"
              },
              "complexity": "high",
              "popularity": 80,
              "documentation": "Good",
              "alternatives": [
                "Elasticsearch",
                "Amazon CloudSearch",
                "Google Cloud Search"
              ],
              "integration": {
                "effort": "high",
                "timeEstimate": "3-5 days",
                "dependencies": [
                  "Solr setup",
                  "Configuration",
                  "Integration with backend"
                ]
              },
              "metadata": {
                "website": "https://lucene.apache.org/solr/",
                "github": "https://github.com/apache/solr",
                "cloudProvider": "",
                "supportLevel": "community"
              },
              "enterpriseScore": 80
            },
            {
              "id": "amazon-cloudsearch",
              "category": "Search Engine",
              "component": "search-engine",
              "name": "Amazon CloudSearch",
              "type": "managed-service",
              "description": "Fully managed search service with support for multiple data formats, offering high performance and scalability",
              "pros": [
                "High performance and scalability",
                "Support for multiple data formats",
                "Full-text search and filtering",
                "Fully managed service with automatic patching and backups",
                "Scalability and high availability",
                "Tight integration with AWS services"
              ],
              "cons": [
                "Pricing complexity",
                "Steep learning curve",
                "Vendor lock-in",
                "Limited support for non-AWS services"
              ],
              "pricing": {
                "model": "usage-based",
                "cost": "$0.0175 per hour",
                "details": "Pay for search instance hours, data transfer, and storage"
              },
              "complexity": "medium",
              "popularity": 85,
              "documentation": "Excellent",
              "alternatives": [
                "Elasticsearch",
                "Apache Solr",
                "Google Cloud Search"
              ],
              "integration": {
                "effort": "medium",
                "timeEstimate": "2-3 days",
                "dependencies": [
                  "AWS account",
                  "IAM roles",
                  "CloudSearch setup"
                ]
              },
              "metadata": {
                "website": "https://aws.amazon.com/cloudsearch/",
                "github": "",
                "cloudProvider": "AWS",
                "supportLevel": "enterprise"
              },
              "enterpriseScore": 88
            }
          ],
          "selectedTool": "elasticsearch",
          "reasoning": "Elasticsearch is recommended for its high performance and scalability, support for multiple data formats, and full-text search and filtering capabilities. The open-source nature and large community ensure that the search engine can be customized and extended as needed.",
          "impact": "medium",
          "urgency": "recommended"
        },
        {
          "id": "decision-load-balancer",
          "title": "Load Balancer Selection",
          "description": "Choose the load balancer that will distribute incoming traffic across multiple instances",
          "category": "infrastructure",
          "component": "load-balancer",
          "recommendations": [
            {
              "id": "nginx",
              "category": "Load Balancer",
              "component": "load-balancer",
              "name": "NGINX",
              "type": "open-source",
              "description": "Popular open-source web server with load balancing capabilities, supporting multiple protocols and configurations",
              "pros": [
                "High performance and scalability",
                "Support for multiple protocols",
                "Load balancing and caching",
                "Free and open-source",
                "Large community"
              ],
              "cons": [
                "Complex setup and configuration",
                "Resource intensive",
                "Limited support for non-web protocols"
              ],
              "pricing": {
                "model": "free",
                "cost": "",
                "details": "Free to use, support and enterprise features paid"
              },
              "complexity": "high",
              "popularity": 90,
              "documentation": "Excellent",
              "alternatives": [
                "HAProxy",
                "Amazon ELB",
                "Google Cloud Load Balancing"
              ],
              "integration": {
                "effort": "high",
                "timeEstimate": "3-5 days",
                "dependencies": [
                  "NGINX setup",
                  "Configuration",
                  "Integration with backend"
                ]
              },
              "metadata": {
                "website": "https://www.nginx.com",
                "github": "https://github.com/nginx/nginx",
                "cloudProvider": "",
                "supportLevel": "community"
              },
              "enterpriseScore": 85
            },
            {
              "id": "haproxy",
              "category": "Load Balancer",
              "component": "load-balancer",
              "name": "HAProxy",
              "type": "open-source",
              "description": "Popular open-source load balancer with high performance, scalability, and support for multiple protocols",
              "pros": [
                "High performance and scalability",
                "Support for multiple protocols",
                "Load balancing and caching",
                "Free and open-source",
                "Large community"
              ],
              "cons": [
                "Complex setup and configuration",
                "Resource intensive",
                "Limited support for non-web protocols"
              ],
              "pricing": {
                "model": "free",
                "cost": "",
                "details": "Free to use, support and enterprise features paid"
              },
              "complexity": "high",
              "popularity": 80,
              "documentation": "Good",
              "alternatives": [
                "NGINX",
                "Amazon ELB",
                "Google Cloud Load Balancing"
              ],
              "integration": {
                "effort": "high",
                "timeEstimate": "3-5 days",
                "dependencies": [
                  "HAProxy setup",
                  "Configuration",
                  "Integration with backend"
                ]
              },
              "metadata": {
                "website": "https://www.haproxy.org",
                "github": "https://github.com/haproxy/haproxy",
                "cloudProvider": "",
                "supportLevel": "community"
              },
              "enterpriseScore": 80
            },
            {
              "id": "amazon-elb",
              "category": "Load Balancer",
              "component": "load-balancer",
              "name": "Amazon ELB",
              "type": "managed-service",
              "description": "Fully managed load balancer with support for multiple protocols, offering high performance and scalability",
              "pros": [
                "High performance and scalability",
                "Support for multiple protocols",
                "Load balancing and caching",
                "Fully managed service with automatic patching and backups",
                "Scalability and high availability",
                "Tight integration with AWS services"
              ],
              "cons": [
                "Pricing complexity",
                "Steep learning curve",
                "Vendor lock-in",
                "Limited support for non-AWS services"
              ],
              "pricing": {
                "model": "usage-based",
                "cost": "$0.0175 per hour",
                "details": "Pay for load balancer hours, data transfer, and storage"
              },
              "complexity": "medium",
              "popularity": 85,
              "documentation": "Excellent",
              "alternatives": [
                "NGINX",
                "HAProxy",
                "Google Cloud Load Balancing"
              ],
              "integration": {
                "effort": "medium",
                "timeEstimate": "2-3 days",
                "dependencies": [
                  "AWS account",
                  "IAM roles",
                  "ELB setup"
                ]
              },
              "metadata": {
                "website": "https://aws.amazon.com/elasticloadbalancing/",
                "github": "",
                "cloudProvider": "AWS",
                "supportLevel": "enterprise"
              },
              "enterpriseScore": 88
            }
          ],
          "selectedTool": "nginx",
          "reasoning": "NGINX is recommended for its high performance and scalability, support for multiple protocols, and load balancing and caching capabilities. The open-source nature and large community ensure that the load balancer can be customized and extended as needed.",
          "impact": "medium",
          "urgency": "recommended"
        },
        {
          "id": "decision-ci-cd",
          "title": "CI/CD Pipeline Selection",
          "description": "Choose the CI/CD pipeline that will automate build, test, and deployment workflows",
          "category": "deployment",
          "component": "ci-cd",
          "recommendations": [
            {
              "id": "github-actions",
              "category": "CI/CD",
              "component": "ci-cd",
              "name": "GitHub Actions",
              "type": "freemium",
              "description": "Integrated CI/CD platform built into GitHub with workflow automation, rich marketplace of actions, and seamless integration with repositories",
              "pros": [
                "Tight GitHub integration",
                "Easy setup with YAML workflows",
                "Rich marketplace of pre-built actions",
                "Free for public repositories",
                "Matrix builds for multiple environments"
              ],
              "cons": [
                "Requires GitHub as source control",
                "Limited for complex enterprise workflows",
                "Pricing for private repos can add up",
                "Less flexible than Jenkins"
              ],
              "pricing": {
                "model": "freemium",
                "cost": "$0.008 per minute",
                "details": "Free for public repos, pay-per-use for private repos (2,000 free minutes/month)"
              },
              "complexity": "low",
              "popularity": 91,
              "documentation": "Excellent",
              "alternatives": [
                "Jenkins",
                "GitLab CI/CD",
                "AWS CodePipeline"
              ],
              "integration": {
                "effort": "low",
                "timeEstimate": "1-2 days",
                "dependencies": [
                  "GitHub repository",
                  "YAML workflow files",
                  "Secrets configuration"
                ]
              },
              "metadata": {
                "website": "https://github.com/features/actions",
                "github": "",
                "cloudProvider": "",
                "supportLevel": "commercial"
              },
              "enterpriseScore": 89
            },
            {
              "id": "gitlab-ci-cd",
              "category": "CI/CD",
              "component": "ci-cd",
              "name": "GitLab CI/CD",
              "type": "freemium",
              "description": "Integrated DevOps platform with built-in CI/CD, security scanning, container registry, and comprehensive deployment capabilities",
              "pros": [
                "Complete DevOps platform",
                "Built-in security scanning",
                "Kubernetes integration",
                "Self-hosted option available",
                "Auto DevOps for automatic pipelines"
              ],
              "cons": [
                "Resource intensive",
                "Complex for simple projects",
                "Learning curve for advanced features",
                "Runner management overhead"
              ],
              "pricing": {
                "model": "freemium",
                "cost": "$19-99 per user/month",
                "details": "Free tier available, paid plans for advanced features (400 CI/CD minutes free)"
              },
              "complexity": "medium",
              "popularity": 85,
              "documentation": "Excellent",
              "alternatives": [
                "GitHub Actions",
                "Azure DevOps",
                "CircleCI"
              ],
              "integration": {
                "effort": "medium",
                "timeEstimate": "3-5 days",
                "dependencies": [
                  "GitLab repository",
                  "Runners setup",
                  "Pipeline configuration"
                ]
              },
              "metadata": {
                "website": "https://about.gitlab.com",
                "github": "",
                "cloudProvider": "",
                "supportLevel": "commercial"
              },
              "enterpriseScore": 87
            },
            {
              "id": "jenkins",
              "category": "CI/CD",
              "component": "ci-cd",
              "name": "Jenkins",
              "type": "open-source",
              "description": "Leading open-source automation server with extensive plugin ecosystem for building complex CI/CD pipelines",
              "pros": [
                "Highly customizable",
                "Vast plugin ecosystem (1800+ plugins)",
                "Self-hosted control",
                "Active community",
                "Free and open-source"
              ],
              "cons": [
                "Complex setup and maintenance",
                "Maintenance overhead",
                "Dated UI",
                "Security concerns with plugins",
                "Requires dedicated infrastructure"
              ],
              "pricing": {
                "model": "free",
                "cost": "",
                "details": "Free to use, infrastructure costs for hosting servers"
              },
              "complexity": "high",
              "popularity": 78,
              "documentation": "Good",
              "alternatives": [
                "GitHub Actions",
                "GitLab CI/CD",
                "TeamCity"
              ],
              "integration": {
                "effort": "high",
                "timeEstimate": "5-7 days",
                "dependencies": [
                  "Server setup",
                  "Plugin installation",
                  "Pipeline configuration",
                  "Security hardening"
                ]
              },
              "metadata": {
                "website": "https://www.jenkins.io",
                "github": "https://github.com/jenkinsci/jenkins",
                "cloudProvider": "",
                "supportLevel": "community"
              },
              "enterpriseScore": 75
            }
          ],
          "selectedTool": "github-actions",
          "reasoning": "GitHub Actions is recommended for its tight integration with GitHub repositories, ease of setup with YAML workflows, and rich marketplace of pre-built actions. The low complexity and excellent documentation enable rapid implementation. Free tier for public repositories provides cost-effective starting point, and the platform scales well as the project grows.",
          "impact": "medium",
          "urgency": "recommended"
        }
      ],
      "integrationPlan": {
        "phase1": [
          "Database Selection",
          "Cloud Infrastructure Selection",
          "API Gateway Selection"
        ],
        "phase2": [
          "Load Balancer Selection",
          "Cache Layer Selection",
          "Search Engine Selection"
        ],
        "phase3": [
          "CI/CD Pipeline Selection",
          "Authentication Service Selection",
          "Monitoring and Logging Setup"
        ]
      },
      "totalCostEstimate": {
        "development": 50000,
        "monthlyOperational": 500,
        "annualOperational": 6000
      },
      "riskAssessment": {
        "technical": [
          "PostgreSQL requires careful query optimization to maintain performance at scale",
          "Complex AWS service integration may require specialized expertise",
          "Database migration complexity if switching from development to production database"
        ],
        "operational": [
          "AWS vendor lock-in makes it difficult to migrate to other cloud providers",
          "Team needs training on AWS services and best practices",
          "CI/CD pipeline maintenance requires ongoing attention"
        ],
        "financial": [
          "AWS costs can increase rapidly with traffic growth without proper monitoring",
          "Database storage costs will scale with data volume",
          "Need to implement cost monitoring and alerts to prevent budget overruns"
        ]
      },
      "success": true,
      "validation": {
        "isValid": true,
        "errors": []
      }
    },
    "selectedTools": {
      "decision-database": "postgresql",
      "decision-cloud-provider": "aws",
      "decision-api-gateway": "aws-api-gateway",
      "decision-authentication": "aws-cognito",
      "decision-cache": "redis",
      "decision-search-engine": "elasticsearch",
      "decision-load-balancer": "nginx",
      "decision-ci-cd": "github-actions"
    },
    "analysis": {
      "useCase": {
        "key": "saas",
        "label": "Multi-tenant B2B SaaS platform for supply chain visibility",
        "features": [
          "real-time tracking",
          "predictive alerts",
          "multi-carrier integration",
          "org hierarchies",
          "analytics dashboard"
        ],
        "complexity": "complex"
      },
      "databaseRecommendations": [
        {
          "name": "PostgreSQL",
          "score": 92,
          "reasons": [
            "maturity and reliability for large-scale enterprise applications",
            "strong support for multi-tenancy and row-level security"
          ],
          "bestFor": "transactional and analytical workloads with high data integrity",
          "pros": [
            "ACID compliance",
            "support for advanced data types and indexing",
            "extensive support for SQL and extensions"
          ],
          "cons": [
            "may require additional configuration for optimal performance",
            "not optimized for real-time analytics out-of-the-box"
          ],
          "whyForUseCase": [
            "supports complex org hierarchies and multi-tenancy",
            "provides robust security features for compliance with SOC 2 Type II, ISO 27001, GDPR"
          ]
        },
        {
          "name": "CockroachDB",
          "score": 90,
          "reasons": [
            "distributed architecture for high availability and scalability across regions",
            "strong support for multi-tenancy and data isolation"
          ],
          "bestFor": "globally distributed, multi-tenant applications with high availability and scalability requirements",
          "pros": [
            "distributed architecture for high availability",
            "strong support for multi-tenancy and data isolation",
            "ACID compliance"
          ],
          "cons": [
            "relatively new and less mature than PostgreSQL or MySQL",
            "may require additional expertise for optimal configuration"
          ],
          "whyForUseCase": [
            "supports global deployment across NA/EU/APAC regions with high availability",
            "provides robust security features for compliance with SOC 2 Type II, ISO 27001, GDPR"
          ]
        },
        {
          "name": "MongoDB",
          "score": 88,
          "reasons": [
            "flexible schema for handling diverse shipment and carrier data",
            "high performance for real-time tracking and predictive alerts"
          ],
          "bestFor": "handling large amounts of semi-structured or unstructured data with high scalability",
          "pros": [
            "flexible data model",
            "high scalability and performance",
            "support for real-time analytics"
          ],
          "cons": [
            "may require additional data modeling and schema design",
            "not as strong in transactional workloads as relational databases"
          ],
          "whyForUseCase": [
            "handles large volumes of shipment data with ease",
            "supports real-time analytics for predictive alerts and tracking"
          ]
        },
        {
          "name": "MySQL",
          "score": 85,
          "reasons": [
            "maturity and wide adoption in enterprise environments",
            "strong support for transactional workloads and data integrity"
          ],
          "bestFor": "transactional workloads with high data consistency and reliability",
          "pros": [
            "wide community support and resources",
            "strong support for SQL and stored procedures",
            "cost-effective"
          ],
          "cons": [
            "may not perform as well as PostgreSQL in complex, multi-tenant scenarios",
            "not as flexible in schema design as NoSQL databases"
          ],
          "whyForUseCase": [
            "supports transactional workloads for shipment and carrier data",
            "provides a cost-effective solution for smaller to medium-sized deployments"
          ]
        }
      ],
      "smartRecommendations": [
        {
          "title": "Implement Microservices Architecture",
          "description": "Design the platform using a microservices architecture to enable scalability, modularity, and easier maintenance. Each microservice should handle a specific business capability, such as tracking, alerts, or analytics, and communicate with other services through APIs. This will allow for more efficient development, deployment, and scaling of individual services.",
          "type": "architecture",
          "priority": "High",
          "implementationEffort": "High"
        },
        {
          "title": "Use a Cloud-Native Database",
          "description": "Utilize a cloud-native database, such as Amazon Aurora or Google Cloud SQL, to handle the large volume of shipment data and support high availability, scalability, and performance. This will enable the platform to efficiently manage 1M+ daily shipments and support the growth of 50 to 5K enterprise clients.",
          "type": "performance",
          "priority": "High",
          "implementationEffort": "Medium"
        },
        {
          "title": "Implement Multi-Tenant Data Isolation",
          "description": "Design a data isolation strategy to ensure that each tenant's data is separated and secure. Use a combination of database schema separation, row-level security, and encryption to prevent unauthorized access to sensitive data. This will help achieve SOC 2 Type II, ISO 27001, and GDPR compliance.",
          "type": "security",
          "priority": "High",
          "implementationEffort": "Medium"
        },
        {
          "title": "Develop a Real-Time Data Processing Pipeline",
          "description": "Create a real-time data processing pipeline using technologies like Apache Kafka, Apache Storm, or AWS Kinesis to handle the high volume of shipment data and support predictive alerts and analytics. This will enable the platform to process and analyze data in real-time, providing valuable insights to clients.",
          "type": "performance",
          "priority": "Medium",
          "implementationEffort": "High"
        },
        {
          "title": "Implement Load Balancing and Auto-Scaling",
          "description": "Use load balancing and auto-scaling techniques to ensure the platform can handle increased traffic and scale to meet the needs of growing clients. Utilize cloud providers' load balancing and auto-scaling services, such as AWS ELB or Google Cloud Load Balancing, to distribute traffic and scale resources efficiently.",
          "type": "scalability",
          "priority": "Medium",
          "implementationEffort": "Low"
        },
        {
          "title": "Use a Centralized Authentication and Authorization Service",
          "description": "Implement a centralized authentication and authorization service, such as Okta or Auth0, to manage user identities and access to the platform. This will simplify user management, improve security, and support SOC 2 Type II, ISO 27001, and GDPR compliance.",
          "type": "security",
          "priority": "Medium",
          "implementationEffort": "Low"
        }
      ],
      "optimizationSuggestions": [
        {
          "type": "indexing",
          "title": "Optimize Database Indexes for Shipments Table",
          "description": "Create composite indexes on the shipments table for columns like organization_id, carrier_id, and shipment_status to improve query performance for real-time tracking and analytics. This will reduce query execution time and improve overall system responsiveness.",
          "impact": "High",
          "complexity": "Medium"
        },
        {
          "type": "caching",
          "title": "Implement Redis Caching for Frequently Accessed Data",
          "description": "Use Redis to cache frequently accessed data like organization hierarchies, carrier information, and shipment status to reduce database queries and improve performance. This will help reduce latency and improve the overall user experience.",
          "impact": "High",
          "complexity": "Medium"
        },
        {
          "type": "infrastructure",
          "title": "Use Load Balancing and Auto-Scaling for High Availability",
          "description": "Implement load balancing and auto-scaling to ensure high availability and scalability across NA/EU/APAC regions. This will help distribute traffic efficiently, reduce downtime, and improve overall system responsiveness.",
          "impact": "High",
          "complexity": "High"
        },
        {
          "type": "performance",
          "title": "Optimize Query Performance for Predictive Alerts",
          "description": "Optimize database queries for predictive alerts to reduce execution time and improve performance. This can be achieved by using efficient algorithms, indexing, and caching. This will help improve the accuracy and timeliness of predictive alerts.",
          "impact": "Medium",
          "complexity": "Medium"
        },
        {
          "type": "security",
          "title": "Implement Efficient Authentication and Authorization",
          "description": "Implement efficient authentication and authorization mechanisms to ensure secure access to the platform. This can be achieved by using OAuth, JWT, and role-based access control. This will help improve security and reduce the risk of unauthorized access.",
          "impact": "High",
          "complexity": "Medium"
        },
        {
          "type": "maintenance",
          "title": "Implement Automated Cleanup and Log Rotation",
          "description": "Implement automated cleanup and log rotation mechanisms to ensure efficient use of storage and improve system performance. This can be achieved by using scheduled tasks and log rotation tools. This will help reduce storage costs and improve system responsiveness.",
          "impact": "Low",
          "complexity": "Low"
        },
        {
          "type": "monitoring",
          "title": "Implement Performance Monitoring and Alerting",
          "description": "Implement performance monitoring and alerting mechanisms to detect and respond to performance issues in real-time. This can be achieved by using tools like Prometheus, Grafana, and PagerDuty. This will help improve system responsiveness and reduce downtime.",
          "impact": "High",
          "complexity": "Medium"
        }
      ],
      "securityRecommendations": [
        {
          "title": "Implement Multi-Factor Authentication (MFA) for all users",
          "description": "Enforce MFA for all users to prevent unauthorized access to the platform, using a combination of password, biometric, or one-time password (OTP) authentication. This will significantly reduce the risk of phishing and password-based attacks.",
          "priority": "High",
          "category": "authentication"
        },
        {
          "title": "Encrypt sensitive data at rest and in transit",
          "description": "Use industry-standard encryption protocols (e.g., TLS 1.2, AES-256) to protect sensitive data, such as shipment details, organization information, and user credentials, both in storage and during transmission. This will ensure confidentiality and integrity of data.",
          "priority": "High",
          "category": "data"
        },
        {
          "title": "Implement Role-Based Access Control (RBAC) and Attribute-Based Access Control (ABAC)",
          "description": "Design and implement a robust access control system, using RBAC and ABAC, to restrict access to sensitive features and data based on user roles, permissions, and attributes. This will prevent unauthorized access and ensure that users can only perform actions within their designated roles.",
          "priority": "Medium",
          "category": "authorization"
        },
        {
          "title": "Conduct regular security audits and penetration testing",
          "description": "Perform regular security audits and penetration testing to identify vulnerabilities and weaknesses in the platform, and address them promptly. This will help ensure the platform's security posture and compliance with regulatory requirements.",
          "priority": "Medium",
          "category": "infrastructure"
        },
        {
          "title": "Implement a Web Application Firewall (WAF) and Intrusion Detection System (IDS)",
          "description": "Deploy a WAF and IDS to detect and prevent common web attacks, such as SQL injection, cross-site scripting (XSS), and cross-site request forgery (CSRF). This will help protect the platform from external threats and ensure the security of user data.",
          "priority": "Medium",
          "category": "infrastructure"
        },
        {
          "title": "Develop a comprehensive incident response plan",
          "description": "Establish a well-defined incident response plan, including procedures for incident detection, containment, eradication, recovery, and post-incident activities. This will ensure that the platform is prepared to respond to security incidents and minimize their impact.",
          "priority": "Low",
          "category": "infrastructure"
        }
      ],
      "scalingInsights": {
        "expectedLoad": "High",
        "readWriteRatio": "90:10",
        "cachingStrategy": "Redis + CDN",
        "indexingPriority": [
          {
            "table": "shipments",
            "priority": "High",
            "reason": "High volume of daily shipments requires efficient querying and indexing for real-time tracking"
          },
          {
            "table": "shipment_status",
            "priority": "High",
            "reason": "Frequent updates to shipment status require optimized indexing for fast data retrieval"
          },
          {
            "table": "shipment_locations",
            "priority": "Medium",
            "reason": "Location data is important for real-time tracking, but updates may be less frequent than shipment status"
          },
          {
            "table": "organizations",
            "priority": "Low",
            "reason": "Organization data is relatively static and can be queried less frequently"
          }
        ]
      },
      "performanceMetrics": [
        {
          "label": "Expected QPS",
          "value": "5000-20000",
          "description": "Queries per second estimate based on 1M+ daily shipments and real-time tracking features"
        },
        {
          "label": "Data Growth",
          "value": "10TB/year",
          "description": "Estimated data growth rate based on 1M+ daily shipments and analytics dashboard features"
        }
      ]
    },
    "deployments": [],
    "createdAt": "2025-12-09T17:29:21.348Z",
    "updatedAt": "2025-12-09T17:51:38.906Z",
    "generatedCode": {
      "files": [
        {
          "path": "package.json",
          "content": "{\n  \"name\": \"build-multitenant-b2b\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Build a multi-tenant B2B SaaS platform for supply chain visibility serving 1M+ daily shipments. Key features: real-time tracking, predictive alerts, multi-carrier integration, org hierarchies, analytics dashboard. Scale to 50 to 5K enterprise clients over 3 years across NA/EU/APAC regions and ensure SOC 2 Type II, ISO 27001, GDPR compliance.\",\n  \"main\": \"src/index.js\",\n  \"scripts\": {\n    \"start\": \"node src/index.js\",\n    \"dev\": \"nodemon src/index.js\",\n    \"migrate\": \"node src/database/migrate.js\",\n    \"migrate:create\": \"node src/database/migrate.js create\",\n    \"migrate:up\": \"node src/database/migrate.js up\",\n    \"migrate:down\": \"node src/database/migrate.js down\",\n    \"db:seed\": \"node src/database/seed.js\",\n    \"db:reset\": \"npm run migrate:down && npm run migrate:up && npm run db:seed\",\n    \"lint\": \"eslint src/\",\n    \"lint:fix\": \"eslint src/ --fix\",\n    \"format\": \"prettier --write \\\"src/**/*.js\\\"\",\n    \"test\": \"jest --coverage\",\n    \"test:watch\": \"jest --watch\",\n    \"test:integration\": \"jest --testPathPattern=tests/integration\"\n  },\n  \"keywords\": [\n    \"api\",\n    \"express\",\n    \"postgresql\",\n    \"rest\",\n    \"functional\",\n    \"mvc\",\n    \"docker\"\n  ],\n  \"author\": \"\",\n  \"license\": \"MIT\",\n  \"dependencies\": {\n    \"dotenv\": \"^16.3.1\",\n    \"cors\": \"^2.8.5\",\n    \"helmet\": \"^7.1.0\",\n    \"compression\": \"^1.7.4\",\n    \"pg\": \"^8.11.0\",\n    \"express\": \"^4.18.2\",\n    \"express-validator\": \"^7.0.1\",\n    \"bull\": \"^4.11.5\",\n    \"bullmq\": \"^5.0.0\",\n    \"uuid\": \"^9.0.0\"\n  },\n  \"devDependencies\": {\n    \"nodemon\": \"^3.0.1\",\n    \"eslint\": \"^8.57.0\",\n    \"prettier\": \"^3.1.1\",\n    \"jest\": \"^29.7.0\",\n    \"supertest\": \"^6.3.3\",\n    \"@jest/globals\": \"^29.7.0\",\n    \"@actions/core\": \"^1.10.1\",\n    \"@actions/github\": \"^6.0.0\"\n  },\n  \"engines\": {\n    \"node\": \">=18.0.0\",\n    \"npm\": \">=9.0.0\"\n  },\n  \"config\": {\n    \"database\": \"build_multitenant_b2b\"\n  }\n}",
          "description": "Node.js package configuration"
        },
        {
          "path": ".eslintrc.json",
          "content": "{\n  \"env\": {\n    \"node\": true,\n    \"es2021\": true\n  },\n  \"extends\": \"eslint:recommended\",\n  \"parserOptions\": {\n    \"ecmaVersion\": 12\n  },\n  \"rules\": {\n    \"no-console\": \"off\",\n    \"prefer-const\": \"error\"\n  }\n}",
          "description": "ESLint configuration following recommended rules.",
          "exports": []
        },
        {
          "path": ".env.example",
          "content": "# =============================================================================\n# BUILD MULTITENANT B2B - ENVIRONMENT CONFIGURATION\n# =============================================================================\n# Copy this file to .env and update with your actual values\n# NEVER commit .env to version control!\n\n# =============================================================================\n# Server Configuration\n# =============================================================================\nNODE_ENV=production\nPORT=3000\n\n# =============================================================================\n# Database Configuration (AWS RDS)\n# =============================================================================\n# For AWS RDS, use the RDS endpoint\nDB_HOST=your-rds-instance.region.rds.amazonaws.com\nDB_PORT=5432\nDB_USER=postgres\nDB_PASSWORD=your-secure-password\nDB_NAME=build_multitenant_b2b\n\n# Full connection string (alternative)\nDATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:${DB_PORT}/${DB_NAME}?sslmode=require\n\n# Connection pool settings (optimized for AWS RDS)\nDB_POOL_MIN=2\nDB_POOL_MAX=10\nDB_POOL_IDLE=10000\n\n# SSL Configuration for AWS RDS\nDB_SSL=true\nDB_SSL_REJECT_UNAUTHORIZED=false\n\n# =============================================================================\n# Local Development (override for local PostgreSQL)\n# =============================================================================\n# Uncomment these for local development:\n# DB_HOST=localhost\n# DB_SSL=false\n\n# =============================================================================\n# Logging\n# =============================================================================\nLOG_LEVEL=info\nLOG_FORMAT=json\n\n# =============================================================================\n# CORS Configuration\n# =============================================================================\nCORS_ORIGIN=http://localhost:3000,http://localhost:5173,https://yourdomain.com\nCORS_CREDENTIALS=true\n\n# =============================================================================\n# Rate Limiting (optional)\n# =============================================================================\nRATE_LIMIT_WINDOW_MS=900000\nRATE_LIMIT_MAX_REQUESTS=100\n\n# =============================================================================\n# AWS Configuration (for ECS deployment)\n# =============================================================================\nAWS_REGION=us-east-1\nAWS_ACCOUNT_ID=your-account-id\n\n# =============================================================================\n# Health Check Configuration\n# =============================================================================\nHEALTH_CHECK_TIMEOUT=5000",
          "description": "Complete environment configuration template with AWS RDS SSL settings"
        },
        {
          "path": ".gitignore",
          "content": "node_modules/\n.env\nnpm-debug.log\n.DS_Store\ncoverage/\nlogs/\n*.log",
          "description": "Git ignore patterns for node modules, env files, logs, etc.",
          "exports": []
        },
        {
          "path": "README.md",
          "content": "# Build MultiTenant B2B\n\nA Node.js/Express starter project backed by PostgreSQL, designed for a multitenant B2B platform.\n\n## Table of Contents\n- [Prerequisites](#prerequisites)\n- [Setup](#setup)\n- [Scripts](#scripts)\n- [Environment Variables](#environment-variables)\n- [Database Setup](#database-setup)\n- [License](#license)\n\n## Prerequisites\n- **Node.js** (v14 or later)\n- **npm** (v6+)\n- **PostgreSQL** (v12+)\n- **Git**\n\n## Setup\n1. Clone the repository:\n   ```bash\n   git clone <repository-url>\n   cd build-multitenant-b2b\n   ```\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n3. Copy the example environment file and fill in your values:\n   ```bash\n   cp .env.example .env\n   ```\n4. Create the PostgreSQL database (replace `<user>` with your PostgreSQL user):\n   ```bash\n   createdb -U <user> build_multitenant_b2b\n   ```\n5. Run database migrations or schema creation scripts as needed (not included in this starter).\n\n## Scripts\n- **`npm start`**  Starts the application in production mode.\n- **`npm run dev`**  Starts the application with **nodemon** for hotreloading during development.\n- **`npm run lint`**  Runs ESLint over the codebase.\n\n## Environment Variables\n| Variable | Description |\n|----------|-------------|\n| `DB_HOST` | PostgreSQL host (default: `localhost`) |\n| `DB_PORT` | PostgreSQL port (default: `5432`) |\n| `DB_USER` | PostgreSQL user |\n| `DB_PASSWORD` | PostgreSQL password |\n| `DB_NAME` | Database name (`build_multitenant_b2b`) |\n| `NODE_ENV` | `development` or `production` |\n| `PORT` | Port on which the Express server will listen |\n\n## Database Setup\nThe project expects the following PostgreSQL extensions and column types:\n- **UUID primary keys** using `uuid_generate_v4()` (enable the `uuid-ossp` extension).\n- **TIMESTAMPTZ** for all timestamp columns.\n- **JSONB** for flexible attribute storage.\n\nExample to enable the extension:\n```sql\nCREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";\n```\n\n## License\nMIT  2025\n",
          "description": "Basic project documentation with setup instructions and environment details.",
          "exports": []
        },
        {
          "path": "docker-entrypoint.sh",
          "content": "#!/bin/sh\nset -e\n\necho \" Starting Build Multitenant B2b...\"\necho \"================================\"\n\n# Display environment info\necho \" Environment:\"\necho \"   NODE_ENV: ${NODE_ENV:-development}\"\necho \"   DB_HOST: ${DB_HOST}\"\necho \"   DB_PORT: ${DB_PORT:-5432}\"\necho \"   DB_NAME: ${DB_NAME}\"\necho \"   DB_USER: ${DB_USER}\"\necho \"\"\n\n# Function to check PostgreSQL connection\ncheck_postgres() {\n  # Extract hostname if DB_HOST contains port\n  DB_HOST_CLEAN=$(echo \"${DB_HOST}\" | cut -d: -f1)\n  \n  PGPASSWORD=$DB_PASSWORD psql -h \"$DB_HOST_CLEAN\" -p \"${DB_PORT:-5432}\" -U \"$DB_USER\" -d \"postgres\" -c '\\q' 2>/dev/null\n}\n\n# Wait for PostgreSQL with timeout\necho \" Waiting for PostgreSQL to be ready...\"\nMAX_TRIES=60\nCOUNTER=0\n\nuntil check_postgres; do\n  COUNTER=$((COUNTER + 1))\n  if [ $COUNTER -gt $MAX_TRIES ]; then\n    echo \" PostgreSQL is unavailable after $MAX_TRIES attempts - exiting\"\n    echo \"   Check DB_HOST: ${DB_HOST}\"\n    echo \"   Check DB_PORT: ${DB_PORT:-5432}\"\n    echo \"   Check DB_USER: ${DB_USER}\"\n    exit 1\n  fi\n  echo \"   PostgreSQL is unavailable (attempt $COUNTER/$MAX_TRIES) - sleeping\"\n  sleep 2\ndone\n\necho \" PostgreSQL is ready!\"\n\n# Extract hostname for database operations\nDB_HOST_CLEAN=$(echo \"${DB_HOST}\" | cut -d: -f1)\n\n# Create database if it doesn't exist\necho \" Ensuring database '$DB_NAME' exists...\"\nDB_EXISTS=$(PGPASSWORD=$DB_PASSWORD psql -h \"$DB_HOST_CLEAN\" -p \"${DB_PORT:-5432}\" -U \"$DB_USER\" -d \"postgres\" -tAc \"SELECT 1 FROM pg_database WHERE datname='$DB_NAME'\" 2>/dev/null || echo \"0\")\n\nif [ \"$DB_EXISTS\" != \"1\" ]; then\n  echo \"   Creating database '$DB_NAME'...\"\n  PGPASSWORD=$DB_PASSWORD psql -h \"$DB_HOST_CLEAN\" -p \"${DB_PORT:-5432}\" -U \"$DB_USER\" -d \"postgres\" -c \"CREATE DATABASE $DB_NAME\" 2>&1\n  \n  if [ $? -eq 0 ]; then\n    echo \"    Database created!\"\n  else\n    echo \"     Database creation had issues (may already exist)\"\n  fi\nelse\n  echo \"    Database already exists!\"\nfi\n\n# Test connection to the application database\necho \" Testing connection to application database...\"\nif PGPASSWORD=$DB_PASSWORD psql -h \"$DB_HOST_CLEAN\" -p \"${DB_PORT:-5432}\" -U \"$DB_USER\" -d \"$DB_NAME\" -c \"SELECT 1\" > /dev/null 2>&1; then\n  echo \" Successfully connected to '$DB_NAME' database!\"\nelse\n  echo \" Failed to connect to '$DB_NAME' database\"\n  exit 1\nfi\n\n# Check if migrations directory exists\nif [ ! -d \"/app/src/database/migrations\" ]; then\n  echo \"  No migrations directory found - skipping migrations\"\nelse\n  # Run migrations\n  echo \" Running database migrations...\"\n  cd /app\n  \n  if node src/database/migrate.js; then\n    echo \" Migrations completed successfully!\"\n  else\n    echo \" Migration failed - exiting\"\n    exit 1\n  fi\nfi\n\necho \"================================\"\necho \" Setup complete - starting application...\"\necho \"\"\n\n# Execute the main command (node src/index.js)\nexec \"$@\"",
          "description": "Enhanced Docker entrypoint with robust database connectivity"
        },
        {
          "path": "Dockerfile",
          "content": "# Multi-stage build for Build Multitenant B2b\nFROM node:18-alpine AS base\n\n# Install dependencies for PostgreSQL client\nRUN apk add --no-cache \\\n    postgresql-client \\\n    libc6-compat \\\n    && rm -rf /var/cache/apk/*\n\n# =============================================================================\n# Dependencies stage - separate for better caching\n# =============================================================================\nFROM base AS deps\nWORKDIR /app\n\n# Copy only package files first (better caching)\nCOPY package*.json ./\n\n# Install production dependencies\nRUN npm install --only=production && \\\n    npm cache clean --force\n\n# =============================================================================\n# Builder stage - for any build steps if needed\n# =============================================================================\nFROM base AS builder\nWORKDIR /app\n\n# Copy package files\nCOPY package*.json ./\n\n# Install all dependencies (including dev)\nRUN npm install && npm cache clean --force\n\n# Copy source code\nCOPY . .\n\n# =============================================================================\n# Production stage\n# =============================================================================\nFROM base AS runner\nWORKDIR /app\n\n# Set environment\nENV NODE_ENV=production\nENV PORT=3000\n\n# Create non-root user for security\nRUN addgroup --system --gid 1001 nodejs && \\\n    adduser --system --uid 1001 nodejs\n\n# Copy dependencies from deps stage\nCOPY --from=deps --chown=nodejs:nodejs /app/node_modules ./node_modules\n\n# Copy application code\nCOPY --from=builder --chown=nodejs:nodejs /app/src ./src\nCOPY --from=builder --chown=nodejs:nodejs /app/package*.json ./\n\n# Copy entrypoint script\nCOPY --chown=nodejs:nodejs docker-entrypoint.sh ./\nRUN chmod +x docker-entrypoint.sh\n\n# Switch to non-root user\nUSER nodejs\n\n# Expose application port\nEXPOSE 3000\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=3s --start-period=40s --retries=3 \\\n  CMD node -e \"require('http').get('http://localhost:3000/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})\"\n\n# Use entrypoint script\nENTRYPOINT [\"./docker-entrypoint.sh\"]\n\n# Default command\nCMD [\"node\", \"src/index.js\"]",
          "description": "Production-ready Dockerfile with optimized layers"
        },
        {
          "path": "docker-compose.yml",
          "content": "version: '3.8'\n\nservices:\n  # =============================================================================\n  # PostgreSQL Database\n  # =============================================================================\n  db:\n    image: postgres:15-alpine\n    container_name: build-multitenant-b2b-db\n    restart: unless-stopped\n    environment:\n      POSTGRES_USER: ${DB_USER:-postgres}\n      POSTGRES_PASSWORD: ${DB_PASSWORD:-postgres}\n      POSTGRES_DB: ${DB_NAME:-build_multitenant_b2b}\n      POSTGRES_INITDB_ARGS: \"--encoding=UTF8 --locale=en_US.UTF-8\"\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n      - postgres_logs:/var/log/postgresql\n    ports:\n      - \"${DB_PORT:-5432}:5432\"\n    networks:\n      - app_network\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U ${DB_USER:-postgres} -d ${DB_NAME:-build_multitenant_b2b}\"]\n      interval: 5s\n      timeout: 5s\n      retries: 10\n      start_period: 10s\n    command: >\n      postgres\n      -c max_connections=100\n      -c shared_buffers=256MB\n      -c effective_cache_size=1GB\n      -c maintenance_work_mem=64MB\n      -c checkpoint_completion_target=0.9\n      -c wal_buffers=16MB\n      -c default_statistics_target=100\n\n  # =============================================================================\n  # Application Service\n  # =============================================================================\n  app:\n    build:\n      context: .\n      dockerfile: Dockerfile\n      target: runner\n    container_name: build-multitenant-b2b-app\n    restart: unless-stopped\n    ports:\n      - \"${PORT:-3000}:3000\"\n    environment:\n      NODE_ENV: production\n      PORT: 3000\n      \n      DATABASE_URL: postgresql://${DB_USER:-postgres}:${DB_PASSWORD:-postgres}@db:5432/${DB_NAME:-build_multitenant_b2b}\n      DB_HOST: db\n      DB_PORT: 5432\n      DB_USER: ${DB_USER:-postgres}\n      DB_PASSWORD: ${DB_PASSWORD:-postgres}\n      DB_NAME: ${DB_NAME:-build_multitenant_b2b}\n      \n      DB_POOL_MIN: ${DB_POOL_MIN:-2}\n      DB_POOL_MAX: ${DB_POOL_MAX:-10}\n      DB_POOL_IDLE: ${DB_POOL_IDLE:-10000}\n      \n      LOG_LEVEL: ${LOG_LEVEL:-info}\n      \n    depends_on:\n      db:\n        condition: service_healthy\n    networks:\n      - app_network\n    healthcheck:\n      test: [\"CMD\", \"node\", \"-e\", \"require('http').get('http://localhost:3000/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 60s\n    volumes:\n      - ./src/database/migrations:/app/src/database/migrations:ro\n\nnetworks:\n  app_network:\n    driver: bridge\n    name: build-multitenant-b2b_network\n\nvolumes:\n  postgres_data:\n    driver: local\n    name: build-multitenant-b2b_postgres_data\n  postgres_logs:\n    driver: local\n    name: build-multitenant-b2b_postgres_logs",
          "description": "Production-ready docker-compose with health checks"
        },
        {
          "path": ".dockerignore",
          "content": "# Dependencies\nnode_modules\nnpm-debug.log\nyarn-error.log\npackage-lock.json\nyarn.lock\n\n# Environment files\n.env\n.env.local\n.env.*.local\n\n# IDE\n.vscode\n.idea\n*.swp\n*.swo\n*~\n\n# OS\n.DS_Store\nThumbs.db\n\n# Tests\ncoverage\n*.test.js\ntests/\n\n# Documentation\n*.md\n!README.md\n\n# Git\n.git\n.gitignore\n\n# Docker\nDockerfile\ndocker-compose*.yml\n.dockerignore\n\n# Logs\nlogs\n*.log\n\n# Misc\n.eslintrc*\n.prettierrc*\n.editorconfig",
          "description": "Docker ignore file"
        },
        {
          "path": "src/utils/logger.js",
          "content": "// Simple functional logger\nconst createLogger = () => {\n  const log = (message, meta = {}) => {\n    console.log(JSON.stringify({\n      level: 'info',\n      message,\n      timestamp: new Date().toISOString(),\n      ...meta\n    }));\n  };\n\n  const error = (message, meta = {}) => {\n    console.error(JSON.stringify({\n      level: 'error',\n      message,\n      timestamp: new Date().toISOString(),\n      ...meta\n    }));\n  };\n\n  const warn = (message, meta = {}) => {\n    console.warn(JSON.stringify({\n      level: 'warn',\n      message,\n      timestamp: new Date().toISOString(),\n      ...meta\n    }));\n  };\n\n  const debug = (message, meta = {}) => {\n    if (process.env.NODE_ENV === 'development') {\n      console.log(JSON.stringify({\n        level: 'debug',\n        message,\n        timestamp: new Date().toISOString(),\n        ...meta\n      }));\n    }\n  };\n\n  return {\n    info: log,\n    error,\n    warn,\n    debug\n  };\n};\n\nmodule.exports = { createLogger };",
          "description": "Simple functional logger utility",
          "exports": [
            "createLogger"
          ]
        },
        {
          "path": "src/utils/errors.js",
          "content": "// Error creation functions\nconst createError = (message, statusCode = 500, code = 'INTERNAL_ERROR') => {\n  const error = new Error(message);\n  error.statusCode = statusCode;\n  error.code = code;\n  return error;\n};\n\nconst createValidationError = (message, details = null) => {\n  const error = createError(message, 400, 'VALIDATION_ERROR');\n  if (details) error.details = details;\n  return error;\n};\n\nconst createNotFoundError = (resource = 'Resource') => {\n  return createError(`${resource} not found`, 404, 'NOT_FOUND');\n};\n\nconst createUnauthorizedError = (message = 'Unauthorized') => {\n  return createError(message, 401, 'UNAUTHORIZED');\n};\n\nconst createForbiddenError = (message = 'Forbidden') => {\n  return createError(message, 403, 'FORBIDDEN');\n};\n\nconst createConflictError = (message = 'Resource already exists') => {\n  return createError(message, 409, 'CONFLICT');\n};\n\nmodule.exports = {\n  createError,\n  createValidationError,\n  createNotFoundError,\n  createUnauthorizedError,\n  createForbiddenError,\n  createConflictError\n};",
          "description": "Utility functions for creating standardized errors",
          "exports": [
            "createError",
            "createValidationError",
            "createNotFoundError",
            "createUnauthorizedError",
            "createForbiddenError",
            "createConflictError"
          ]
        },
        {
          "path": "src/utils/responses.js",
          "content": "// Response formatting functions\nconst sendSuccess = (res, data, message = 'Success', statusCode = 200) => {\n  return res.status(statusCode).json({\n    success: true,\n    message,\n    data,\n    timestamp: new Date().toISOString()\n  });\n};\n\nconst sendError = (res, error, statusCode = 500) => {\n  return res.status(statusCode).json({\n    success: false,\n    error: {\n      message: error.message || 'Internal server error',\n      code: error.code || 'INTERNAL_ERROR',\n      ...(error.details && { details: error.details })\n    },\n    timestamp: new Date().toISOString()\n  });\n};\n\nconst sendCreated = (res, data, message = 'Resource created successfully') => {\n  return sendSuccess(res, data, message, 201);\n};\n\nconst sendNoContent = (res) => {\n  return res.status(204).send();\n};\n\nconst sendPaginated = (res, data, pagination) => {\n  return res.status(200).json({\n    success: true,\n    data,\n    pagination: {\n      page: pagination.page,\n      limit: pagination.limit,\n      total: pagination.total,\n      totalPages: Math.ceil(pagination.total / pagination.limit)\n    },\n    timestamp: new Date().toISOString()\n  });\n};\n\nmodule.exports = {\n  sendSuccess,\n  sendError,\n  sendCreated,\n  sendNoContent,\n  sendPaginated\n};",
          "description": "Utility functions for consistent HTTP responses",
          "exports": [
            "sendSuccess",
            "sendError",
            "sendCreated",
            "sendNoContent",
            "sendPaginated"
          ]
        },
        {
          "path": "src/utils/validations.js",
          "content": "const { createValidationError } = require('./errors');\n\n// Validation helper functions\nconst isValidEmail = (email) => {\n  const emailRegex = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n  return emailRegex.test(email);\n};\n\nconst isValidUUID = (uuid) => {\n  const uuidRegex = /^[0-9a-f]{8}-[0-9a-f]{4}-4[0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i;\n  return uuidRegex.test(uuid);\n};\n\nconst validateRequired = (fields, data) => {\n  const missing = fields.filter(field => !data[field]);\n  if (missing.length > 0) {\n    throw createValidationError(\n      'Missing required fields',\n      { missing }\n    );\n  }\n};\n\nconst validateEmail = (email) => {\n  if (!isValidEmail(email)) {\n    throw createValidationError('Invalid email format');\n  }\n};\n\nconst validateUUID = (uuid, fieldName = 'ID') => {\n  if (!isValidUUID(uuid)) {\n    throw createValidationError(`Invalid ${fieldName} format`);\n  }\n};\n\nconst sanitizeString = (str) => {\n  if (typeof str !== 'string') return str;\n  return str.trim().replace(/[<>]/g, '');\n};\n\nmodule.exports = {\n  isValidEmail,\n  isValidUUID,\n  validateRequired,\n  validateEmail,\n  validateUUID,\n  sanitizeString\n};",
          "description": "Helper functions for input validation and sanitization",
          "exports": [
            "isValidEmail",
            "isValidUUID",
            "validateRequired",
            "validateEmail",
            "validateUUID",
            "sanitizeString"
          ]
        },
        {
          "path": "src/utils/index.js",
          "content": "const { createLogger } = require('./logger');\nconst {\n  createError,\n  createValidationError,\n  createNotFoundError,\n  createUnauthorizedError,\n  createForbiddenError,\n  createConflictError\n} = require('./errors');\nconst {\n  sendSuccess,\n  sendError,\n  sendCreated,\n  sendNoContent,\n  sendPaginated\n} = require('./responses');\nconst {\n  isValidEmail,\n  isValidUUID,\n  validateRequired,\n  validateEmail,\n  validateUUID,\n  sanitizeString\n} = require('./validations');\n\nmodule.exports = {\n  // Logger\n  createLogger,\n  \n  // Errors\n  createError,\n  createValidationError,\n  createNotFoundError,\n  createUnauthorizedError,\n  createForbiddenError,\n  createConflictError,\n  \n  // Responses\n  sendSuccess,\n  sendError,\n  sendCreated,\n  sendNoContent,\n  sendPaginated,\n  \n  // Validations\n  isValidEmail,\n  isValidUUID,\n  validateRequired,\n  validateEmail,\n  validateUUID,\n  sanitizeString\n};",
          "description": "Re-export all utility functions for easy import",
          "exports": [
            "createValidationError",
            "createNotFoundError",
            "createUnauthorizedError",
            "createForbiddenError",
            "createConflictError",
            "sendError",
            "sendCreated",
            "sendNoContent",
            "sendPaginated",
            "isValidUUID",
            "validateRequired",
            "validateEmail",
            "validateUUID",
            "sanitizeString"
          ]
        },
        {
          "path": "src/database/connections.js",
          "content": "const { Pool } = require('pg');\n\nconst sslConfig = process.env.NODE_ENV === 'production' \n  ? { rejectUnauthorized: false }\n  : false;\n\nlet pool = null;\n\nconst createPools = () => {\n  if (!pool) {\n    pool = new Pool({\n      user: process.env.DB_USER,\n      host: process.env.DB_HOST,\n      database: process.env.DB_NAME,\n      password: process.env.DB_PASSWORD,\n      port: process.env.DB_PORT,\n      ssl: sslConfig,\n      max: process.env.DB_POOL_MAX || 10,\n      min: process.env.DB_POOL_MIN || 2,\n      idleTimeoutMillis: process.env.DB_POOL_IDLE || 10000,\n      connectionTimeoutMillis: 2000\n    });\n\n    pool.on('error', (err) => {\n      console.error('Unexpected database pool error:', err);\n    });\n  }\n  \n  return pool;\n};\n\nconst getPools = () => {\n  return createPools();\n};\n\nconst closePools = async () => {\n  if (pool) {\n    await pool.end();\n    pool = null;\n  }\n};\n\nmodule.exports = { createPools, getPools, closePools };",
          "description": "Singleton PostgreSQL pool with SSL autodetection and proper cleanup",
          "exports": [
            "createPools",
            "getPools",
            "closePools"
          ]
        },
        {
          "path": "src/database/index.js",
          "content": "const { createPools, getPools, closePools } = require('./connections');\n\nmodule.exports = {\n  createPools,\n  getPools,\n  closePools\n};",
          "description": "Reexports connection helpers for easy import",
          "exports": [
            "createPools",
            "getPools",
            "closePools"
          ]
        },
        {
          "path": "src/database/migrations.js",
          "content": "const fs = require('fs');\nconst path = require('path');\nconst { getPools } = require('./connections');\n\n/**\n * Runs all .sql files in the migrations folder in lexical order.\n * Each file is executed inside its own query call  migrations are\n * expected to be idempotent (CREATE IF NOT EXISTS, etc.).\n */\nconst runMigrations = async () => {\n  const pool = getPools();\n  const migrationsDir = path.join(__dirname, 'migrations');\n  const files = fs.readdirSync(migrationsDir)\n    .filter((f) => f.endsWith('.sql'))\n    .sort();\n\n  for (const file of files) {\n    const filePath = path.join(migrationsDir, file);\n    const sql = fs.readFileSync(filePath, 'utf8');\n    try {\n      await pool.query(sql);\n      console.log(` Migration ${file} applied`);\n    } catch (err) {\n      console.error(` Migration ${file} failed`, err);\n      throw err;\n    }\n  }\n};\n\nmodule.exports = { runMigrations };",
          "description": "Utility to execute all SQL migration files sequentially",
          "exports": [
            "runMigrations"
          ]
        },
        {
          "path": "src/database/migrations/001_initial_schema.sql",
          "content": "-- ===========================================================================\n-- Database: build_multitenant_b2b\n-- Generated: 2025-12-09T17:48:50.347Z\n-- ===========================================================================\n\n-- ===========================================================================\n-- Enable UUID Extension (AWS RDS Compatible)\n-- ===========================================================================\nCREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";\n\n-- ===========================================================================\n-- Update Trigger Function (shared by all tables)\n-- ===========================================================================\nCREATE OR REPLACE FUNCTION update_updated_at_column()\nRETURNS TRIGGER AS $$\nBEGIN\n    NEW.updated_at = CURRENT_TIMESTAMP;\n    RETURN NEW;\nEND;\n$$ language 'plpgsql';\n\n-- ===========================================================================\n-- Tables with Auto-Generated UUIDs\n-- ===========================================================================\n\n-- Table: organizations\nCREATE TABLE IF NOT EXISTS organizations (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  name VARCHAR(255),\n  email VARCHAR(255),\n  created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  updated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  deleted_at TIMESTAMPTZ\n);\n\n-- Indexes for organizations\nCREATE INDEX IF NOT EXISTS idx_organizations_created_at ON organizations(created_at DESC);\nCREATE INDEX IF NOT EXISTS idx_organizations_deleted_at ON organizations(deleted_at) WHERE deleted_at IS NULL;\n\n\n-- Update trigger for organizations\nCREATE TRIGGER update_organizations_updated_at BEFORE UPDATE ON organizations\nFOR EACH ROW EXECUTE FUNCTION update_updated_at_column();\n\n\n-- Table: organization_users\nCREATE TABLE IF NOT EXISTS organization_users (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  organization_id UUID,\n  user_id UUID,\n  role VARCHAR(255),\n  created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  updated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  deleted_at TIMESTAMPTZ\n);\n\n-- Indexes for organization_users\nCREATE INDEX IF NOT EXISTS idx_organization_users_created_at ON organization_users(created_at DESC);\nCREATE INDEX IF NOT EXISTS idx_organization_users_deleted_at ON organization_users(deleted_at) WHERE deleted_at IS NULL;\n\n\n-- Update trigger for organization_users\nCREATE TRIGGER update_organization_users_updated_at BEFORE UPDATE ON organization_users\nFOR EACH ROW EXECUTE FUNCTION update_updated_at_column();\n\n\n-- Table: users\nCREATE TABLE IF NOT EXISTS users (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  email VARCHAR(255),\n  password VARCHAR(255),\n  created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  updated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  deleted_at TIMESTAMPTZ\n);\n\n-- Indexes for users\nCREATE INDEX IF NOT EXISTS idx_users_created_at ON users(created_at DESC);\nCREATE INDEX IF NOT EXISTS idx_users_deleted_at ON users(deleted_at) WHERE deleted_at IS NULL;\n\n\n-- Update trigger for users\nCREATE TRIGGER update_users_updated_at BEFORE UPDATE ON users\nFOR EACH ROW EXECUTE FUNCTION update_updated_at_column();\n\n\n-- Table: shipments\nCREATE TABLE IF NOT EXISTS shipments (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  organization_id UUID,\n  carrier_id UUID,\n  tracking_number VARCHAR(255),\n  created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  updated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  deleted_at TIMESTAMPTZ\n);\n\n-- Indexes for shipments\nCREATE INDEX IF NOT EXISTS idx_shipments_created_at ON shipments(created_at DESC);\nCREATE INDEX IF NOT EXISTS idx_shipments_deleted_at ON shipments(deleted_at) WHERE deleted_at IS NULL;\n\n\n-- Update trigger for shipments\nCREATE TRIGGER update_shipments_updated_at BEFORE UPDATE ON shipments\nFOR EACH ROW EXECUTE FUNCTION update_updated_at_column();\n\n\n-- Table: carriers\nCREATE TABLE IF NOT EXISTS carriers (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  name VARCHAR(255),\n  api_key VARCHAR(255),\n  created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  updated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  deleted_at TIMESTAMPTZ\n);\n\n-- Indexes for carriers\nCREATE INDEX IF NOT EXISTS idx_carriers_created_at ON carriers(created_at DESC);\nCREATE INDEX IF NOT EXISTS idx_carriers_deleted_at ON carriers(deleted_at) WHERE deleted_at IS NULL;\n\n\n-- Update trigger for carriers\nCREATE TRIGGER update_carriers_updated_at BEFORE UPDATE ON carriers\nFOR EACH ROW EXECUTE FUNCTION update_updated_at_column();\n\n\n-- Table: shipment_status\nCREATE TABLE IF NOT EXISTS shipment_status (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  shipment_id UUID,\n  status VARCHAR(255),\n  created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  updated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  deleted_at TIMESTAMPTZ\n);\n\n-- Indexes for shipment_status\nCREATE INDEX IF NOT EXISTS idx_shipment_status_created_at ON shipment_status(created_at DESC);\nCREATE INDEX IF NOT EXISTS idx_shipment_status_deleted_at ON shipment_status(deleted_at) WHERE deleted_at IS NULL;\n\n\n-- Update trigger for shipment_status\nCREATE TRIGGER update_shipment_status_updated_at BEFORE UPDATE ON shipment_status\nFOR EACH ROW EXECUTE FUNCTION update_updated_at_column();\n\n\n-- Table: shipment_locations\nCREATE TABLE IF NOT EXISTS shipment_locations (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  shipment_id UUID,\n  latitude DECIMAL(10, 2),\n  longitude DECIMAL(10, 2),\n  created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  updated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  deleted_at TIMESTAMPTZ\n);\n\n-- Indexes for shipment_locations\nCREATE INDEX IF NOT EXISTS idx_shipment_locations_created_at ON shipment_locations(created_at DESC);\nCREATE INDEX IF NOT EXISTS idx_shipment_locations_deleted_at ON shipment_locations(deleted_at) WHERE deleted_at IS NULL;\n\n\n-- Update trigger for shipment_locations\nCREATE TRIGGER update_shipment_locations_updated_at BEFORE UPDATE ON shipment_locations\nFOR EACH ROW EXECUTE FUNCTION update_updated_at_column();\n\n\n-- Table: shipment_alerts\nCREATE TABLE IF NOT EXISTS shipment_alerts (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  shipment_id UUID,\n  alert_type VARCHAR(255),\n  created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  updated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  deleted_at TIMESTAMPTZ\n);\n\n-- Indexes for shipment_alerts\nCREATE INDEX IF NOT EXISTS idx_shipment_alerts_created_at ON shipment_alerts(created_at DESC);\nCREATE INDEX IF NOT EXISTS idx_shipment_alerts_deleted_at ON shipment_alerts(deleted_at) WHERE deleted_at IS NULL;\n\n\n-- Update trigger for shipment_alerts\nCREATE TRIGGER update_shipment_alerts_updated_at BEFORE UPDATE ON shipment_alerts\nFOR EACH ROW EXECUTE FUNCTION update_updated_at_column();\n\n\n-- Table: settings\nCREATE TABLE IF NOT EXISTS settings (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  organization_id UUID,\n  setting_key VARCHAR(255),\n  setting_value VARCHAR(255),\n  created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  updated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  deleted_at TIMESTAMPTZ\n);\n\n-- Indexes for settings\nCREATE INDEX IF NOT EXISTS idx_settings_created_at ON settings(created_at DESC);\nCREATE INDEX IF NOT EXISTS idx_settings_deleted_at ON settings(deleted_at) WHERE deleted_at IS NULL;\n\n\n-- Update trigger for settings\nCREATE TRIGGER update_settings_updated_at BEFORE UPDATE ON settings\nFOR EACH ROW EXECUTE FUNCTION update_updated_at_column();\n\n\n-- Table: audit_logs\nCREATE TABLE IF NOT EXISTS audit_logs (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  organization_id UUID,\n  log_level VARCHAR(255),\n  log_message VARCHAR(255),\n  created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  updated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  deleted_at TIMESTAMPTZ\n);\n\n-- Indexes for audit_logs\nCREATE INDEX IF NOT EXISTS idx_audit_logs_created_at ON audit_logs(created_at DESC);\nCREATE INDEX IF NOT EXISTS idx_audit_logs_deleted_at ON audit_logs(deleted_at) WHERE deleted_at IS NULL;\n\n\n-- Update trigger for audit_logs\nCREATE TRIGGER update_audit_logs_updated_at BEFORE UPDATE ON audit_logs\nFOR EACH ROW EXECUTE FUNCTION update_updated_at_column();\n\n\n-- ===========================================================================\n-- Verification Queries (Uncomment to run)\n-- ===========================================================================\n-- SELECT table_name FROM information_schema.tables WHERE table_schema = 'public';\n-- SELECT tablename, indexname FROM pg_indexes WHERE schemaname = 'public' ORDER BY tablename;",
          "description": "Initial schema creation for all required tables",
          "exports": []
        },
        {
          "path": "src/database/seeds.js",
          "content": "const { getPools } = require('./connections');\nconst { v4: uuidv4 } = require('uuid');\n\n/**\n * Inserts a minimal set of sample records useful for local development.\n * All inserts are wrapped in a transaction  on error the transaction is rolled back.\n */\nconst seedDatabase = async () => {\n  const pool = getPools();\n\n  try {\n    await pool.query('BEGIN');\n\n    // Organization\n    const orgId = uuidv4();\n    await pool.query(\n      `INSERT INTO organizations (id, name, email) VALUES ($1, $2, $3)`,\n      [orgId, 'Acme Corp', 'contact@acme.com']\n    );\n\n    // User\n    const userId = uuidv4();\n    await pool.query(\n      `INSERT INTO users (id, email, password) VALUES ($1, $2, $3)`,\n      [userId, 'admin@acme.com', 'hashedpassword']\n    );\n\n    // OrganizationUser link\n    await pool.query(\n      `INSERT INTO organization_users (id, organization_id, user_id, role) VALUES ($1, $2, $3, $4)`,\n      [uuidv4(), orgId, userId, 'admin']\n    );\n\n    // Carrier\n    const carrierId = uuidv4();\n    await pool.query(\n      `INSERT INTO carriers (id, name, api_key) VALUES ($1, $2, $3)`,\n      [carrierId, 'FastShip', 'carrier-api-key']\n    );\n\n    // Shipment\n    const shipmentId = uuidv4();\n    await pool.query(\n      `INSERT INTO shipments (id, organization_id, carrier_id, tracking_number) VALUES ($1, $2, $3, $4)`,\n      [shipmentId, orgId, carrierId, 'TRACK123456']\n    );\n\n    await pool.query('COMMIT');\n    console.log(' Sample data seeded');\n  } catch (err) {\n    await pool.query('ROLLBACK');\n    console.error(' Seeding failed', err);\n    throw err;\n  }\n};\n\nmodule.exports = { seedDatabase };",
          "description": "Utility to populate the database with minimal development data",
          "exports": [
            "seedDatabase"
          ]
        },
        {
          "path": "src/models/organizationsModels.js",
          "content": "const { createPools } = require('../database/connections');\nconst { createNotFoundError } = require('../utils/errors');\n\nconst createOrganizationsModels = () => {\n  const pool = createPools();\n\n  // CREATE\n  const createRecord = async (data) => {\n    const fields = Object.keys(data);\n    const values = Object.values(data);\n    const placeholders = fields.map((_, i) => `$${i + 1}`).join(', ');\n    const query = `\n      INSERT INTO organizations (${fields.join(', ')})\n      VALUES (${placeholders})\n      RETURNING *\n    `;\n    const result = await pool.query(query, values);\n    return result.rows[0];\n  };\n\n  // READ ALL with pagination, sorting, filters\n  const findAllRecords = async (filters = {}, options = {}) => {\n    const { page = 1, limit = 10, sortBy = 'created_at', sortOrder = 'DESC' } = options;\n    const offset = (page - 1) * limit;\n    const whereClauses = ['deleted_at IS NULL'];\n    const values = [];\n    let idx = 1;\n    for (const [key, value] of Object.entries(filters)) {\n      if (value !== undefined) {\n        whereClauses.push(`${key} = $${idx}`);\n        values.push(value);\n        idx++;\n      }\n    }\n    const where = `WHERE ${whereClauses.join(' AND ')}`;\n    const countQuery = `SELECT COUNT(*) as total FROM organizations ${where}`;\n    const countResult = await pool.query(countQuery, values);\n    const total = parseInt(countResult.rows[0].total, 10);\n    const query = `\n      SELECT * FROM organizations\n      ${where}\n      ORDER BY ${sortBy} ${sortOrder}\n      LIMIT $${idx} OFFSET $${idx + 1}\n    `;\n    const result = await pool.query(query, [...values, limit, offset]);\n    return {\n      data: result.rows,\n      pagination: { page, limit, total, totalPages: Math.ceil(total / limit) }\n    };\n  };\n\n  // READ BY ID\n  const findByIdRecord = async (id) => {\n    const query = `SELECT * FROM organizations WHERE id = $1 AND deleted_at IS NULL`;\n    const result = await pool.query(query, [id]);\n    if (result.rows.length === 0) {\n      throw createNotFoundError('Organization not found');\n    }\n    return result.rows[0];\n  };\n\n  // UPDATE BY ID\n  const updateByIdRecord = async (id, data) => {\n    const fields = Object.keys(data);\n    const values = Object.values(data);\n    const setClause = fields.map((f, i) => `${f} = $${i + 2}`).join(', ');\n    const query = `\n      UPDATE organizations\n      SET ${setClause}, updated_at = CURRENT_TIMESTAMP\n      WHERE id = $1 AND deleted_at IS NULL\n      RETURNING *\n    `;\n    const result = await pool.query(query, [id, ...values]);\n    if (result.rows.length === 0) {\n      throw createNotFoundError('Organization not found');\n    }\n    return result.rows[0];\n  };\n\n  // SOFT DELETE BY ID\n  const deleteByIdRecord = async (id) => {\n    const query = `\n      UPDATE organizations\n      SET deleted_at = CURRENT_TIMESTAMP\n      WHERE id = $1 AND deleted_at IS NULL\n      RETURNING *\n    `;\n    const result = await pool.query(query, [id]);\n    if (result.rows.length === 0) {\n      throw createNotFoundError('Organization not found');\n    }\n    return result.rows[0];\n  };\n\n  // COUNT\n  const countRecords = async (filters = {}) => {\n    const whereClauses = ['deleted_at IS NULL'];\n    const values = [];\n    let idx = 1;\n    for (const [key, value] of Object.entries(filters)) {\n      if (value !== undefined) {\n        whereClauses.push(`${key} = $${idx}`);\n        values.push(value);\n        idx++;\n      }\n    }\n    const query = `SELECT COUNT(*) as total FROM organizations WHERE ${whereClauses.join(' AND ')}`;\n    const result = await pool.query(query, values);\n    return parseInt(result.rows[0].total, 10);\n  };\n\n  return {\n    createRecord,\n    findAllRecords,\n    findByIdRecord,\n    updateByIdRecord,\n    deleteByIdRecord,\n    countRecords\n  };\n};\n\nmodule.exports = { createOrganizationsModels };",
          "description": "Model factory for organizations with full CRUD and count",
          "exports": [
            "createOrganizationsModels"
          ]
        },
        {
          "path": "src/models/organizationUsersModels.js",
          "content": "const { createPools } = require('../database/connections');\nconst { createNotFoundError } = require('../utils/errors');\n\nconst createOrganizationUsersModels = () => {\n  const pool = createPools();\n\n  const createRecord = async (data) => {\n    const fields = Object.keys(data);\n    const values = Object.values(data);\n    const placeholders = fields.map((_, i) => `$${i + 1}`).join(', ');\n    const query = `\n      INSERT INTO organization_users (${fields.join(', ')})\n      VALUES (${placeholders})\n      RETURNING *\n    `;\n    const result = await pool.query(query, values);\n    return result.rows[0];\n  };\n\n  const findAllRecords = async (filters = {}, options = {}) => {\n    const { page = 1, limit = 10, sortBy = 'created_at', sortOrder = 'DESC' } = options;\n    const offset = (page - 1) * limit;\n    const whereClauses = ['deleted_at IS NULL'];\n    const values = [];\n    let idx = 1;\n    for (const [k, v] of Object.entries(filters)) {\n      if (v !== undefined) {\n        whereClauses.push(`${k} = $${idx}`);\n        values.push(v);\n        idx++;\n      }\n    }\n    const where = `WHERE ${whereClauses.join(' AND ')}`;\n    const countQuery = `SELECT COUNT(*) as total FROM organization_users ${where}`;\n    const countResult = await pool.query(countQuery, values);\n    const total = parseInt(countResult.rows[0].total, 10);\n    const query = `\n      SELECT * FROM organization_users\n      ${where}\n      ORDER BY ${sortBy} ${sortOrder}\n      LIMIT $${idx} OFFSET $${idx + 1}\n    `;\n    const result = await pool.query(query, [...values, limit, offset]);\n    return {\n      data: result.rows,\n      pagination: { page, limit, total, totalPages: Math.ceil(total / limit) }\n    };\n  };\n\n  const findByIdRecord = async (id) => {\n    const query = `SELECT * FROM organization_users WHERE id = $1 AND deleted_at IS NULL`;\n    const result = await pool.query(query, [id]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Organization user not found');\n    }\n    return result.rows[0];\n  };\n\n  const updateByIdRecord = async (id, data) => {\n    const fields = Object.keys(data);\n    const values = Object.values(data);\n    const setClause = fields.map((f, i) => `${f} = $${i + 2}`).join(', ');\n    const query = `\n      UPDATE organization_users\n      SET ${setClause}, updated_at = CURRENT_TIMESTAMP\n      WHERE id = $1 AND deleted_at IS NULL\n      RETURNING *\n    `;\n    const result = await pool.query(query, [id, ...values]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Organization user not found');\n    }\n    return result.rows[0];\n  };\n\n  const deleteByIdRecord = async (id) => {\n    const query = `\n      UPDATE organization_users\n      SET deleted_at = CURRENT_TIMESTAMP\n      WHERE id = $1 AND deleted_at IS NULL\n      RETURNING *\n    `;\n    const result = await pool.query(query, [id]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Organization user not found');\n    }\n    return result.rows[0];\n  };\n\n  const countRecords = async (filters = {}) => {\n    const whereClauses = ['deleted_at IS NULL'];\n    const values = [];\n    let idx = 1;\n    for (const [k, v] of Object.entries(filters)) {\n      if (v !== undefined) {\n        whereClauses.push(`${k} = $${idx}`);\n        values.push(v);\n        idx++;\n      }\n    }\n    const query = `SELECT COUNT(*) as total FROM organization_users WHERE ${whereClauses.join(' AND ')}`;\n    const result = await pool.query(query, values);\n    return parseInt(result.rows[0].total, 10);\n  };\n\n  return {\n    createRecord,\n    findAllRecords,\n    findByIdRecord,\n    updateByIdRecord,\n    deleteByIdRecord,\n    countRecords\n  };\n};\n\nmodule.exports = { createOrganizationUsersModels };",
          "description": "Model factory for organization_users with full CRUD and count",
          "exports": [
            "createOrganizationUsersModels"
          ]
        },
        {
          "path": "src/models/usersModels.js",
          "content": "const { createPools } = require('../database/connections');\nconst { createNotFoundError } = require('../utils/errors');\n\nconst createUsersModels = () => {\n  const pool = createPools();\n\n  const createRecord = async (data) => {\n    const fields = Object.keys(data);\n    const values = Object.values(data);\n    const placeholders = fields.map((_, i) => `$${i + 1}`).join(', ');\n    const query = `\n      INSERT INTO users (${fields.join(', ')})\n      VALUES (${placeholders})\n      RETURNING *\n    `;\n    const result = await pool.query(query, values);\n    return result.rows[0];\n  };\n\n  const findAllRecords = async (filters = {}, options = {}) => {\n    const { page = 1, limit = 10, sortBy = 'created_at', sortOrder = 'DESC' } = options;\n    const offset = (page - 1) * limit;\n    const whereClauses = ['deleted_at IS NULL'];\n    const values = [];\n    let idx = 1;\n    for (const [k, v] of Object.entries(filters)) {\n      if (v !== undefined) {\n        whereClauses.push(`${k} = $${idx}`);\n        values.push(v);\n        idx++;\n      }\n    }\n    const where = `WHERE ${whereClauses.join(' AND ')}`;\n    const countQuery = `SELECT COUNT(*) as total FROM users ${where}`;\n    const countResult = await pool.query(countQuery, values);\n    const total = parseInt(countResult.rows[0].total, 10);\n    const query = `\n      SELECT * FROM users\n      ${where}\n      ORDER BY ${sortBy} ${sortOrder}\n      LIMIT $${idx} OFFSET $${idx + 1}\n    `;\n    const result = await pool.query(query, [...values, limit, offset]);\n    return {\n      data: result.rows,\n      pagination: { page, limit, total, totalPages: Math.ceil(total / limit) }\n    };\n  };\n\n  const findByIdRecord = async (id) => {\n    const query = `SELECT * FROM users WHERE id = $1 AND deleted_at IS NULL`;\n    const result = await pool.query(query, [id]);\n    if (!result.rows.length) {\n      throw createNotFoundError('User not found');\n    }\n    return result.rows[0];\n  };\n\n  const updateByIdRecord = async (id, data) => {\n    const fields = Object.keys(data);\n    const values = Object.values(data);\n    const setClause = fields.map((f, i) => `${f} = $${i + 2}`).join(', ');\n    const query = `\n      UPDATE users\n      SET ${setClause}, updated_at = CURRENT_TIMESTAMP\n      WHERE id = $1 AND deleted_at IS NULL\n      RETURNING *\n    `;\n    const result = await pool.query(query, [id, ...values]);\n    if (!result.rows.length) {\n      throw createNotFoundError('User not found');\n    }\n    return result.rows[0];\n  };\n\n  const deleteByIdRecord = async (id) => {\n    const query = `\n      UPDATE users\n      SET deleted_at = CURRENT_TIMESTAMP\n      WHERE id = $1 AND deleted_at IS NULL\n      RETURNING *\n    `;\n    const result = await pool.query(query, [id]);\n    if (!result.rows.length) {\n      throw createNotFoundError('User not found');\n    }\n    return result.rows[0];\n  };\n\n  const countRecords = async (filters = {}) => {\n    const whereClauses = ['deleted_at IS NULL'];\n    const values = [];\n    let idx = 1;\n    for (const [k, v] of Object.entries(filters)) {\n      if (v !== undefined) {\n        whereClauses.push(`${k} = $${idx}`);\n        values.push(v);\n        idx++;\n      }\n    }\n    const query = `SELECT COUNT(*) as total FROM users WHERE ${whereClauses.join(' AND ')}`;\n    const result = await pool.query(query, values);\n    return parseInt(result.rows[0].total, 10);\n  };\n\n  return {\n    createRecord,\n    findAllRecords,\n    findByIdRecord,\n    updateByIdRecord,\n    deleteByIdRecord,\n    countRecords\n  };\n};\n\nmodule.exports = { createUsersModels };",
          "description": "Model factory for users with full CRUD and count",
          "exports": [
            "createUsersModels"
          ]
        },
        {
          "path": "src/models/shipmentsModels.js",
          "content": "const { createPools } = require('../database/connections');\nconst { createNotFoundError } = require('../utils/errors');\n\nconst createShipmentsModels = () => {\n  const pool = createPools();\n\n  const createRecord = async (data) => {\n    const fields = Object.keys(data);\n    const values = Object.values(data);\n    const placeholders = fields.map((_, i) => `$${i + 1}`).join(', ');\n    const query = `\n      INSERT INTO shipments (${fields.join(', ')})\n      VALUES (${placeholders})\n      RETURNING *\n    `;\n    const result = await pool.query(query, values);\n    return result.rows[0];\n  };\n\n  const findAllRecords = async (filters = {}, options = {}) => {\n    const { page = 1, limit = 10, sortBy = 'created_at', sortOrder = 'DESC' } = options;\n    const offset = (page - 1) * limit;\n    const whereClauses = ['deleted_at IS NULL'];\n    const values = [];\n    let idx = 1;\n    for (const [k, v] of Object.entries(filters)) {\n      if (v !== undefined) {\n        whereClauses.push(`${k} = $${idx}`);\n        values.push(v);\n        idx++;\n      }\n    }\n    const where = `WHERE ${whereClauses.join(' AND ')}`;\n    const countQuery = `SELECT COUNT(*) as total FROM shipments ${where}`;\n    const countResult = await pool.query(countQuery, values);\n    const total = parseInt(countResult.rows[0].total, 10);\n    const query = `\n      SELECT * FROM shipments\n      ${where}\n      ORDER BY ${sortBy} ${sortOrder}\n      LIMIT $${idx} OFFSET $${idx + 1}\n    `;\n    const result = await pool.query(query, [...values, limit, offset]);\n    return {\n      data: result.rows,\n      pagination: { page, limit, total, totalPages: Math.ceil(total / limit) }\n    };\n  };\n\n  const findByIdRecord = async (id) => {\n    const query = `SELECT * FROM shipments WHERE id = $1 AND deleted_at IS NULL`;\n    const result = await pool.query(query, [id]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Shipment not found');\n    }\n    return result.rows[0];\n  };\n\n  const updateByIdRecord = async (id, data) => {\n    const fields = Object.keys(data);\n    const values = Object.values(data);\n    const setClause = fields.map((f, i) => `${f} = $${i + 2}`).join(', ');\n    const query = `\n      UPDATE shipments\n      SET ${setClause}, updated_at = CURRENT_TIMESTAMP\n      WHERE id = $1 AND deleted_at IS NULL\n      RETURNING *\n    `;\n    const result = await pool.query(query, [id, ...values]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Shipment not found');\n    }\n    return result.rows[0];\n  };\n\n  const deleteByIdRecord = async (id) => {\n    const query = `\n      UPDATE shipments\n      SET deleted_at = CURRENT_TIMESTAMP\n      WHERE id = $1 AND deleted_at IS NULL\n      RETURNING *\n    `;\n    const result = await pool.query(query, [id]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Shipment not found');\n    }\n    return result.rows[0];\n  };\n\n  const countRecords = async (filters = {}) => {\n    const whereClauses = ['deleted_at IS NULL'];\n    const values = [];\n    let idx = 1;\n    for (const [k, v] of Object.entries(filters)) {\n      if (v !== undefined) {\n        whereClauses.push(`${k} = $${idx}`);\n        values.push(v);\n        idx++;\n      }\n    }\n    const query = `SELECT COUNT(*) as total FROM shipments WHERE ${whereClauses.join(' AND ')}`;\n    const result = await pool.query(query, values);\n    return parseInt(result.rows[0].total, 10);\n  };\n\n  return {\n    createRecord,\n    findAllRecords,\n    findByIdRecord,\n    updateByIdRecord,\n    deleteByIdRecord,\n    countRecords\n  };\n};\n\nmodule.exports = { createShipmentsModels };",
          "description": "Model factory for shipments with full CRUD and count",
          "exports": [
            "createShipmentsModels"
          ]
        },
        {
          "path": "src/models/carriersModels.js",
          "content": "const { createPools } = require('../database/connections');\nconst { createNotFoundError } = require('../utils/errors');\n\nconst createCarriersModels = () => {\n  const pool = createPools();\n\n  const createRecord = async (data) => {\n    const fields = Object.keys(data);\n    const values = Object.values(data);\n    const placeholders = fields.map((_, i) => `$${i + 1}`).join(', ');\n    const query = `\n      INSERT INTO carriers (${fields.join(', ')})\n      VALUES (${placeholders})\n      RETURNING *\n    `;\n    const result = await pool.query(query, values);\n    return result.rows[0];\n  };\n\n  const findAllRecords = async (filters = {}, options = {}) => {\n    const { page = 1, limit = 10, sortBy = 'created_at', sortOrder = 'DESC' } = options;\n    const offset = (page - 1) * limit;\n    const whereClauses = ['deleted_at IS NULL'];\n    const values = [];\n    let idx = 1;\n    for (const [k, v] of Object.entries(filters)) {\n      if (v !== undefined) {\n        whereClauses.push(`${k} = $${idx}`);\n        values.push(v);\n        idx++;\n      }\n    }\n    const where = `WHERE ${whereClauses.join(' AND ')}`;\n    const countQuery = `SELECT COUNT(*) as total FROM carriers ${where}`;\n    const countResult = await pool.query(countQuery, values);\n    const total = parseInt(countResult.rows[0].total, 10);\n    const query = `\n      SELECT * FROM carriers\n      ${where}\n      ORDER BY ${sortBy} ${sortOrder}\n      LIMIT $${idx} OFFSET $${idx + 1}\n    `;\n    const result = await pool.query(query, [...values, limit, offset]);\n    return {\n      data: result.rows,\n      pagination: { page, limit, total, totalPages: Math.ceil(total / limit) }\n    };\n  };\n\n  const findByIdRecord = async (id) => {\n    const query = `SELECT * FROM carriers WHERE id = $1 AND deleted_at IS NULL`;\n    const result = await pool.query(query, [id]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Carrier not found');\n    }\n    return result.rows[0];\n  };\n\n  const updateByIdRecord = async (id, data) => {\n    const fields = Object.keys(data);\n    const values = Object.values(data);\n    const setClause = fields.map((f, i) => `${f} = $${i + 2}`).join(', ');\n    const query = `\n      UPDATE carriers\n      SET ${setClause}, updated_at = CURRENT_TIMESTAMP\n      WHERE id = $1 AND deleted_at IS NULL\n      RETURNING *\n    `;\n    const result = await pool.query(query, [id, ...values]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Carrier not found');\n    }\n    return result.rows[0];\n  };\n\n  const deleteByIdRecord = async (id) => {\n    const query = `\n      UPDATE carriers\n      SET deleted_at = CURRENT_TIMESTAMP\n      WHERE id = $1 AND deleted_at IS NULL\n      RETURNING *\n    `;\n    const result = await pool.query(query, [id]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Carrier not found');\n    }\n    return result.rows[0];\n  };\n\n  const countRecords = async (filters = {}) => {\n    const whereClauses = ['deleted_at IS NULL'];\n    const values = [];\n    let idx = 1;\n    for (const [k, v] of Object.entries(filters)) {\n      if (v !== undefined) {\n        whereClauses.push(`${k} = $${idx}`);\n        values.push(v);\n        idx++;\n      }\n    }\n    const query = `SELECT COUNT(*) as total FROM carriers WHERE ${whereClauses.join(' AND ')}`;\n    const result = await pool.query(query, values);\n    return parseInt(result.rows[0].total, 10);\n  };\n\n  return {\n    createRecord,\n    findAllRecords,\n    findByIdRecord,\n    updateByIdRecord,\n    deleteByIdRecord,\n    countRecords\n  };\n};\n\nmodule.exports = { createCarriersModels };",
          "description": "Model factory for carriers with full CRUD and count",
          "exports": [
            "createCarriersModels"
          ]
        },
        {
          "path": "src/models/settingsModels.js",
          "content": "const { createPools } = require('../database/connections');\nconst { createNotFoundError } = require('../utils/errors');\n\nconst createSettingsModels = () => {\n  const pool = createPools();\n\n  const createRecord = async (data) => {\n    const fields = Object.keys(data);\n    const values = Object.values(data);\n    const placeholders = fields.map((_, i) => `$${i + 1}`).join(', ');\n    const query = `\n      INSERT INTO settings (${fields.join(', ')})\n      VALUES (${placeholders})\n      RETURNING *\n    `;\n    const result = await pool.query(query, values);\n    return result.rows[0];\n  };\n\n  const findAllRecords = async (filters = {}, options = {}) => {\n    const { page = 1, limit = 10, sortBy = 'created_at', sortOrder = 'DESC' } = options;\n    const offset = (page - 1) * limit;\n    const whereClauses = ['deleted_at IS NULL'];\n    const values = [];\n    let idx = 1;\n    for (const [k, v] of Object.entries(filters)) {\n      if (v !== undefined) {\n        whereClauses.push(`${k} = $${idx}`);\n        values.push(v);\n        idx++;\n      }\n    }\n    const where = `WHERE ${whereClauses.join(' AND ')}`;\n    const countQuery = `SELECT COUNT(*) as total FROM settings ${where}`;\n    const countResult = await pool.query(countQuery, values);\n    const total = parseInt(countResult.rows[0].total, 10);\n    const query = `\n      SELECT * FROM settings\n      ${where}\n      ORDER BY ${sortBy} ${sortOrder}\n      LIMIT $${idx} OFFSET $${idx + 1}\n    `;\n    const result = await pool.query(query, [...values, limit, offset]);\n    return {\n      data: result.rows,\n      pagination: { page, limit, total, totalPages: Math.ceil(total / limit) }\n    };\n  };\n\n  const findByIdRecord = async (id) => {\n    const query = `SELECT * FROM settings WHERE id = $1 AND deleted_at IS NULL`;\n    const result = await pool.query(query, [id]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Setting not found');\n    }\n    return result.rows[0];\n  };\n\n  const updateByIdRecord = async (id, data) => {\n    const fields = Object.keys(data);\n    const values = Object.values(data);\n    const setClause = fields.map((f, i) => `${f} = $${i + 2}`).join(', ');\n    const query = `\n      UPDATE settings\n      SET ${setClause}, updated_at = CURRENT_TIMESTAMP\n      WHERE id = $1 AND deleted_at IS NULL\n      RETURNING *\n    `;\n    const result = await pool.query(query, [id, ...values]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Setting not found');\n    }\n    return result.rows[0];\n  };\n\n  const deleteByIdRecord = async (id) => {\n    const query = `\n      UPDATE settings\n      SET deleted_at = CURRENT_TIMESTAMP\n      WHERE id = $1 AND deleted_at IS NULL\n      RETURNING *\n    `;\n    const result = await pool.query(query, [id]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Setting not found');\n    }\n    return result.rows[0];\n  };\n\n  const countRecords = async (filters = {}) => {\n    const whereClauses = ['deleted_at IS NULL'];\n    const values = [];\n    let idx = 1;\n    for (const [k, v] of Object.entries(filters)) {\n      if (v !== undefined) {\n        whereClauses.push(`${k} = $${idx}`);\n        values.push(v);\n        idx++;\n      }\n    }\n    const query = `SELECT COUNT(*) as total FROM settings WHERE ${whereClauses.join(' AND ')}`;\n    const result = await pool.query(query, values);\n    return parseInt(result.rows[0].total, 10);\n  };\n\n  return {\n    createRecord,\n    findAllRecords,\n    findByIdRecord,\n    updateByIdRecord,\n    deleteByIdRecord,\n    countRecords\n  };\n};\n\nmodule.exports = { createSettingsModels };",
          "description": "Model factory for settings with full CRUD and count",
          "exports": [
            "createSettingsModels"
          ]
        },
        {
          "path": "src/models/shipmentStatusModels.js",
          "content": "const { createPools } = require('../database/connections');\nconst { createNotFoundError } = require('../utils/errors');\n\nconst createShipmentStatusModels = () => {\n  const pool = createPools();\n\n  const createRecord = async (data) => {\n    const fields = Object.keys(data);\n    const values = Object.values(data);\n    const placeholders = fields.map((_, i) => `$${i + 1}`).join(', ');\n    const query = `\n      INSERT INTO shipment_status (${fields.join(', ')})\n      VALUES (${placeholders})\n      RETURNING *\n    `;\n    const result = await pool.query(query, values);\n    return result.rows[0];\n  };\n\n  const findAllRecords = async (filters = {}, options = {}) => {\n    const { page = 1, limit = 10, sortBy = 'created_at', sortOrder = 'DESC' } = options;\n    const offset = (page - 1) * limit;\n    const whereClauses = ['deleted_at IS NULL'];\n    const values = [];\n    let idx = 1;\n    for (const [k, v] of Object.entries(filters)) {\n      if (v !== undefined) {\n        whereClauses.push(`${k} = $${idx}`);\n        values.push(v);\n        idx++;\n      }\n    }\n    const where = `WHERE ${whereClauses.join(' AND ')}`;\n    const countQuery = `SELECT COUNT(*) as total FROM shipment_status ${where}`;\n    const countResult = await pool.query(countQuery, values);\n    const total = parseInt(countResult.rows[0].total, 10);\n    const query = `\n      SELECT * FROM shipment_status\n      ${where}\n      ORDER BY ${sortBy} ${sortOrder}\n      LIMIT $${idx} OFFSET $${idx + 1}\n    `;\n    const result = await pool.query(query, [...values, limit, offset]);\n    return {\n      data: result.rows,\n      pagination: { page, limit, total, totalPages: Math.ceil(total / limit) }\n    };\n  };\n\n  const findByIdRecord = async (id) => {\n    const query = `SELECT * FROM shipment_status WHERE id = $1 AND deleted_at IS NULL`;\n    const result = await pool.query(query, [id]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Shipment status not found');\n    }\n    return result.rows[0];\n  };\n\n  const updateByIdRecord = async (id, data) => {\n    const fields = Object.keys(data);\n    const values = Object.values(data);\n    const setClause = fields.map((f, i) => `${f} = $${i + 2}`).join(', ');\n    const query = `\n      UPDATE shipment_status\n      SET ${setClause}, updated_at = CURRENT_TIMESTAMP\n      WHERE id = $1 AND deleted_at IS NULL\n      RETURNING *\n    `;\n    const result = await pool.query(query, [id, ...values]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Shipment status not found');\n    }\n    return result.rows[0];\n  };\n\n  const deleteByIdRecord = async (id) => {\n    const query = `\n      UPDATE shipment_status\n      SET deleted_at = CURRENT_TIMESTAMP\n      WHERE id = $1 AND deleted_at IS NULL\n      RETURNING *\n    `;\n    const result = await pool.query(query, [id]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Shipment status not found');\n    }\n    return result.rows[0];\n  };\n\n  const countRecords = async (filters = {}) => {\n    const whereClauses = ['deleted_at IS NULL'];\n    const values = [];\n    let idx = 1;\n    for (const [k, v] of Object.entries(filters)) {\n      if (v !== undefined) {\n        whereClauses.push(`${k} = $${idx}`);\n        values.push(v);\n        idx++;\n      }\n    }\n    const query = `SELECT COUNT(*) as total FROM shipment_status WHERE ${whereClauses.join(' AND ')}`;\n    const result = await pool.query(query, values);\n    return parseInt(result.rows[0].total, 10);\n  };\n\n  return {\n    createRecord,\n    findAllRecords,\n    findByIdRecord,\n    updateByIdRecord,\n    deleteByIdRecord,\n    countRecords\n  };\n};\n\nmodule.exports = { createShipmentStatusModels };",
          "description": "Model factory for shipment_status with full CRUD and count",
          "exports": [
            "createShipmentStatusModels"
          ]
        },
        {
          "path": "src/models/shipmentLocationsModels.js",
          "content": "const { createPools } = require('../database/connections');\nconst { createNotFoundError } = require('../utils/errors');\n\nconst createShipmentLocationsModels = () => {\n  const pool = createPools();\n\n  const createRecord = async (data) => {\n    const fields = Object.keys(data);\n    const values = Object.values(data);\n    const placeholders = fields.map((_, i) => `$${i + 1}`).join(', ');\n    const query = `\n      INSERT INTO shipment_locations (${fields.join(', ')})\n      VALUES (${placeholders})\n      RETURNING *\n    `;\n    const result = await pool.query(query, values);\n    return result.rows[0];\n  };\n\n  const findAllRecords = async (filters = {}, options = {}) => {\n    const { page = 1, limit = 10, sortBy = 'created_at', sortOrder = 'DESC' } = options;\n    const offset = (page - 1) * limit;\n    const whereClauses = ['deleted_at IS NULL'];\n    const values = [];\n    let idx = 1;\n    for (const [k, v] of Object.entries(filters)) {\n      if (v !== undefined) {\n        whereClauses.push(`${k} = $${idx}`);\n        values.push(v);\n        idx++;\n      }\n    }\n    const where = `WHERE ${whereClauses.join(' AND ')}`;\n    const countQuery = `SELECT COUNT(*) as total FROM shipment_locations ${where}`;\n    const countResult = await pool.query(countQuery, values);\n    const total = parseInt(countResult.rows[0].total, 10);\n    const query = `\n      SELECT * FROM shipment_locations\n      ${where}\n      ORDER BY ${sortBy} ${sortOrder}\n      LIMIT $${idx} OFFSET $${idx + 1}\n    `;\n    const result = await pool.query(query, [...values, limit, offset]);\n    return {\n      data: result.rows,\n      pagination: { page, limit, total, totalPages: Math.ceil(total / limit) }\n    };\n  };\n\n  const findByIdRecord = async (id) => {\n    const query = `SELECT * FROM shipment_locations WHERE id = $1 AND deleted_at IS NULL`;\n    const result = await pool.query(query, [id]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Shipment location not found');\n    }\n    return result.rows[0];\n  };\n\n  const updateByIdRecord = async (id, data) => {\n    const fields = Object.keys(data);\n    const values = Object.values(data);\n    const setClause = fields.map((f, i) => `${f} = $${i + 2}`).join(', ');\n    const query = `\n      UPDATE shipment_locations\n      SET ${setClause}, updated_at = CURRENT_TIMESTAMP\n      WHERE id = $1 AND deleted_at IS NULL\n      RETURNING *\n    `;\n    const result = await pool.query(query, [id, ...values]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Shipment location not found');\n    }\n    return result.rows[0];\n  };\n\n  const deleteByIdRecord = async (id) => {\n    const query = `\n      UPDATE shipment_locations\n      SET deleted_at = CURRENT_TIMESTAMP\n      WHERE id = $1 AND deleted_at IS NULL\n      RETURNING *\n    `;\n    const result = await pool.query(query, [id]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Shipment location not found');\n    }\n    return result.rows[0];\n  };\n\n  const countRecords = async (filters = {}) => {\n    const whereClauses = ['deleted_at IS NULL'];\n    const values = [];\n    let idx = 1;\n    for (const [k, v] of Object.entries(filters)) {\n      if (v !== undefined) {\n        whereClauses.push(`${k} = $${idx}`);\n        values.push(v);\n        idx++;\n      }\n    }\n    const query = `SELECT COUNT(*) as total FROM shipment_locations WHERE ${whereClauses.join(' AND ')}`;\n    const result = await pool.query(query, values);\n    return parseInt(result.rows[0].total, 10);\n  };\n\n  return {\n    createRecord,\n    findAllRecords,\n    findByIdRecord,\n    updateByIdRecord,\n    deleteByIdRecord,\n    countRecords\n  };\n};\n\nmodule.exports = { createShipmentLocationsModels };",
          "description": "Model factory for shipment_locations with full CRUD and count",
          "exports": [
            "createShipmentLocationsModels"
          ]
        },
        {
          "path": "src/models/shipmentAlertsModels.js",
          "content": "const { createPools } = require('../database/connections');\nconst { createNotFoundError } = require('../utils/errors');\n\nconst createShipmentAlertsModels = () => {\n  const pool = createPools();\n\n  const createRecord = async (data) => {\n    const fields = Object.keys(data);\n    const values = Object.values(data);\n    const placeholders = fields.map((_, i) => `$${i + 1}`).join(', ');\n    const query = `\n      INSERT INTO shipment_alerts (${fields.join(', ')})\n      VALUES (${placeholders})\n      RETURNING *\n    `;\n    const result = await pool.query(query, values);\n    return result.rows[0];\n  };\n\n  const findAllRecords = async (filters = {}, options = {}) => {\n    const { page = 1, limit = 10, sortBy = 'created_at', sortOrder = 'DESC' } = options;\n    const offset = (page - 1) * limit;\n    const whereClauses = ['deleted_at IS NULL'];\n    const values = [];\n    let idx = 1;\n    for (const [k, v] of Object.entries(filters)) {\n      if (v !== undefined) {\n        whereClauses.push(`${k} = $${idx}`);\n        values.push(v);\n        idx++;\n      }\n    }\n    const where = `WHERE ${whereClauses.join(' AND ')}`;\n    const countQuery = `SELECT COUNT(*) as total FROM shipment_alerts ${where}`;\n    const countResult = await pool.query(countQuery, values);\n    const total = parseInt(countResult.rows[0].total, 10);\n    const query = `\n      SELECT * FROM shipment_alerts\n      ${where}\n      ORDER BY ${sortBy} ${sortOrder}\n      LIMIT $${idx} OFFSET $${idx + 1}\n    `;\n    const result = await pool.query(query, [...values, limit, offset]);\n    return {\n      data: result.rows,\n      pagination: { page, limit, total, totalPages: Math.ceil(total / limit) }\n    };\n  };\n\n  const findByIdRecord = async (id) => {\n    const query = `SELECT * FROM shipment_alerts WHERE id = $1 AND deleted_at IS NULL`;\n    const result = await pool.query(query, [id]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Shipment alert not found');\n    }\n    return result.rows[0];\n  };\n\n  const updateByIdRecord = async (id, data) => {\n    const fields = Object.keys(data);\n    const values = Object.values(data);\n    const setClause = fields.map((f, i) => `${f} = $${i + 2}`).join(', ');\n    const query = `\n      UPDATE shipment_alerts\n      SET ${setClause}, updated_at = CURRENT_TIMESTAMP\n      WHERE id = $1 AND deleted_at IS NULL\n      RETURNING *\n    `;\n    const result = await pool.query(query, [id, ...values]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Shipment alert not found');\n    }\n    return result.rows[0];\n  };\n\n  const deleteByIdRecord = async (id) => {\n    const query = `\n      UPDATE shipment_alerts\n      SET deleted_at = CURRENT_TIMESTAMP\n      WHERE id = $1 AND deleted_at IS NULL\n      RETURNING *\n    `;\n    const result = await pool.query(query, [id]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Shipment alert not found');\n    }\n    return result.rows[0];\n  };\n\n  const countRecords = async (filters = {}) => {\n    const whereClauses = ['deleted_at IS NULL'];\n    const values = [];\n    let idx = 1;\n    for (const [k, v] of Object.entries(filters)) {\n      if (v !== undefined) {\n        whereClauses.push(`${k} = $${idx}`);\n        values.push(v);\n        idx++;\n      }\n    }\n    const query = `SELECT COUNT(*) as total FROM shipment_alerts WHERE ${whereClauses.join(' AND ')}`;\n    const result = await pool.query(query, values);\n    return parseInt(result.rows[0].total, 10);\n  };\n\n  return {\n    createRecord,\n    findAllRecords,\n    findByIdRecord,\n    updateByIdRecord,\n    deleteByIdRecord,\n    countRecords\n  };\n};\n\nmodule.exports = { createShipmentAlertsModels };",
          "description": "Model factory for shipment_alerts with full CRUD and count",
          "exports": [
            "createShipmentAlertsModels"
          ]
        },
        {
          "path": "src/models/auditLogsModels.js",
          "content": "const { createPools } = require('../database/connections');\nconst { createNotFoundError } = require('../utils/errors');\n\nconst createAuditLogsModels = () => {\n  const pool = createPools();\n\n  const createRecord = async (data) => {\n    const fields = Object.keys(data);\n    const values = Object.values(data);\n    const placeholders = fields.map((_, i) => `$${i + 1}`).join(', ');\n    const query = `\n      INSERT INTO audit_logs (${fields.join(', ')})\n      VALUES (${placeholders})\n      RETURNING *\n    `;\n    const result = await pool.query(query, values);\n    return result.rows[0];\n  };\n\n  const findAllRecords = async (filters = {}, options = {}) => {\n    const { page = 1, limit = 10, sortBy = 'created_at', sortOrder = 'DESC' } = options;\n    const offset = (page - 1) * limit;\n    const whereClauses = ['deleted_at IS NULL'];\n    const values = [];\n    let idx = 1;\n    for (const [k, v] of Object.entries(filters)) {\n      if (v !== undefined) {\n        whereClauses.push(`${k} = $${idx}`);\n        values.push(v);\n        idx++;\n      }\n    }\n    const where = `WHERE ${whereClauses.join(' AND ')}`;\n    const countQuery = `SELECT COUNT(*) as total FROM audit_logs ${where}`;\n    const countResult = await pool.query(countQuery, values);\n    const total = parseInt(countResult.rows[0].total, 10);\n    const query = `\n      SELECT * FROM audit_logs\n      ${where}\n      ORDER BY ${sortBy} ${sortOrder}\n      LIMIT $${idx} OFFSET $${idx + 1}\n    `;\n    const result = await pool.query(query, [...values, limit, offset]);\n    return {\n      data: result.rows,\n      pagination: { page, limit, total, totalPages: Math.ceil(total / limit) }\n    };\n  };\n\n  const findByIdRecord = async (id) => {\n    const query = `SELECT * FROM audit_logs WHERE id = $1 AND deleted_at IS NULL`;\n    const result = await pool.query(query, [id]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Audit log not found');\n    }\n    return result.rows[0];\n  };\n\n  const updateByIdRecord = async (id, data) => {\n    const fields = Object.keys(data);\n    const values = Object.values(data);\n    const setClause = fields.map((f, i) => `${f} = $${i + 2}`).join(', ');\n    const query = `\n      UPDATE audit_logs\n      SET ${setClause}, updated_at = CURRENT_TIMESTAMP\n      WHERE id = $1 AND deleted_at IS NULL\n      RETURNING *\n    `;\n    const result = await pool.query(query, [id, ...values]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Audit log not found');\n    }\n    return result.rows[0];\n  };\n\n  const deleteByIdRecord = async (id) => {\n    const query = `\n      UPDATE audit_logs\n      SET deleted_at = CURRENT_TIMESTAMP\n      WHERE id = $1 AND deleted_at IS NULL\n      RETURNING *\n    `;\n    const result = await pool.query(query, [id]);\n    if (!result.rows.length) {\n      throw createNotFoundError('Audit log not found');\n    }\n    return result.rows[0];\n  };\n\n  const countRecords = async (filters = {}) => {\n    const whereClauses = ['deleted_at IS NULL'];\n    const values = [];\n    let idx = 1;\n    for (const [k, v] of Object.entries(filters)) {\n      if (v !== undefined) {\n        whereClauses.push(`${k} = $${idx}`);\n        values.push(v);\n        idx++;\n      }\n    }\n    const query = `SELECT COUNT(*) as total FROM audit_logs WHERE ${whereClauses.join(' AND ')}`;\n    const result = await pool.query(query, values);\n    return parseInt(result.rows[0].total, 10);\n  };\n\n  return {\n    createRecord,\n    findAllRecords,\n    findByIdRecord,\n    updateByIdRecord,\n    deleteByIdRecord,\n    countRecords\n  };\n};\n\nmodule.exports = { createAuditLogsModels };",
          "description": "Model factory for audit_logs with full CRUD and count",
          "exports": [
            "createAuditLogsModels"
          ]
        },
        {
          "path": "src/models/index.js",
          "content": "const { createOrganizationsModels } = require('./organizationsModels');\nconst { createOrganizationUsersModels } = require('./organizationUsersModels');\nconst { createUsersModels } = require('./usersModels');\nconst { createShipmentsModels } = require('./shipmentsModels');\nconst { createCarriersModels } = require('./carriersModels');\nconst { createShipmentStatusModels } = require('./shipmentStatusModels');\nconst { createShipmentLocationsModels } = require('./shipmentLocationsModels');\nconst { createShipmentAlertsModels } = require('./shipmentAlertsModels');\nconst { createSettingsModels } = require('./settingsModels');\nconst { createAuditLogsModels } = require('./auditLogsModels');\n\nmodule.exports = {\n  createOrganizationsModels,\n  createOrganizationUsersModels,\n  createUsersModels,\n  createShipmentsModels,\n  createCarriersModels,\n  createShipmentStatusModels,\n  createShipmentLocationsModels,\n  createShipmentAlertsModels,\n  createSettingsModels,\n  createAuditLogsModels\n};",
          "description": "Re-export all model factories",
          "exports": [
            "createOrganizationsModels",
            "createOrganizationUsersModels",
            "createUsersModels",
            "createShipmentsModels",
            "createCarriersModels",
            "createShipmentStatusModels",
            "createShipmentLocationsModels",
            "createShipmentAlertsModels",
            "createSettingsModels",
            "createAuditLogsModels"
          ]
        },
        {
          "path": "src/middleware/errorHandler.js",
          "content": "const { createLogger } = require('../utils/logger');\nconst { sendError } = require('../utils/responses');\n\nconst logger = createLogger();\n\n// Error handler middleware (4 parameters)\nconst errorHandler = (err, req, res, next) => {\n  logger.error('Error occurred', {\n    error: err.message,\n    stack: err.stack,\n    path: req.path,\n    method: req.method,\n    statusCode: err.statusCode || 500\n  });\n\n  const statusCode = err.statusCode || 500;\n  return sendError(res, err, statusCode);\n};\n\n// 404 Not Found handler (2 parameters - NO next!)\nconst notFoundHandler = (req, res) => {\n  const error = {\n    message: `Route not found: ${req.method} ${req.path}`,\n    code: 'NOT_FOUND'\n  };\n  \n  logger.warn('Route not found', {\n    method: req.method,\n    path: req.path,\n    query: req.query,\n    ip: req.ip || req.connection.remoteAddress\n  });\n\n  return res.status(404).json({\n    success: false,\n    error: {\n      message: error.message,\n      code: error.code\n    },\n    timestamp: new Date().toISOString()\n  });\n};\n\nmodule.exports = {\n  errorHandler,\n  notFoundHandler\n};",
          "description": "Error handling middleware with 4parameter errorHandler and 2parameter notFoundHandler, reexported as named exports.",
          "exports": [
            "errorHandler",
            "notFoundHandler"
          ]
        },
        {
          "path": "src/middleware/requestLogger.js",
          "content": "const { createLogger } = require('../utils/logger');\n\nconst logger = createLogger();\n\n// Request logging middleware\nconst requestLogger = (req, res, next) => {\n  const start = Date.now();\n\n  // Log request\n  logger.info('Incoming request', {\n    method: req.method,\n    path: req.path,\n    query: req.query,\n    ip: req.ip || req.connection.remoteAddress,\n    userAgent: req.get('user-agent')\n  });\n\n  // Log response on finish\n  res.on('finish', () => {\n    const duration = Date.now() - start;\n    logger.info('Request completed', {\n      method: req.method,\n      path: req.path,\n      statusCode: res.statusCode,\n      duration: `${duration}ms`\n    });\n  });\n\n  next();\n};\n\nmodule.exports = { requestLogger };",
          "description": "Middleware that logs incoming requests and their completion details.",
          "exports": [
            "requestLogger"
          ]
        },
        {
          "path": "src/middleware/validator.js",
          "content": "const { createValidationError } = require('../utils/errors');\nconst { sendError } = require('../utils/responses');\n\n// Validate request body\nconst validateBody = (schema) => {\n  return (req, res, next) => {\n    try {\n      // Simple validation - check required fields\n      if (schema.required) {\n        const missing = schema.required.filter(field => !req.body[field]);\n        if (missing.length > 0) {\n          throw createValidationError('Missing required fields', { missing });\n        }\n      }\n\n      // Type validation\n      if (schema.fields) {\n        Object.keys(schema.fields).forEach(field => {\n          const value = req.body[field];\n          const expectedType = schema.fields[field];\n\n          if (value !== undefined && typeof value !== expectedType) {\n            throw createValidationError(\n              `Invalid type for field '${field}'`,\n              { field, expected: expectedType, received: typeof value }\n            );\n          }\n        });\n      }\n\n      next();\n    } catch (error) {\n      return sendError(res, error, error.statusCode || 400);\n    }\n  };\n};\n\n// Validate query parameters\nconst validateQuery = (schema) => {\n  return (req, res, next) => {\n    try {\n      if (schema.allowed) {\n        const invalidParams = Object.keys(req.query).filter(\n          key => !schema.allowed.includes(key)\n        );\n        if (invalidParams.length > 0) {\n          throw createValidationError('Invalid query parameters', { invalidParams });\n        }\n      }\n      next();\n    } catch (error) {\n      return sendError(res, error, error.statusCode || 400);\n    }\n  };\n};\n\n// Validate route parameters\nconst validateParams = (schema) => {\n  return (req, res, next) => {\n    try {\n      if (schema.required) {\n        const missing = schema.required.filter(param => !req.params[param]);\n        if (missing.length > 0) {\n          throw createValidationError('Missing required parameters', { missing });\n        }\n      }\n      next();\n    } catch (error) {\n      return sendError(res, error, error.statusCode || 400);\n    }\n  };\n};\n\nmodule.exports = {\n  validateBody,\n  validateQuery,\n  validateParams\n};",
          "description": "Validator middleware providing body, query, and params validation utilities.",
          "exports": [
            "validateBody",
            "validateQuery",
            "validateParams"
          ]
        },
        {
          "path": "src/middleware/index.js",
          "content": "const { errorHandler, notFoundHandler } = require('./errorHandler');\nconst { requestLogger } = require('./requestLogger');\nconst { validateBody, validateQuery, validateParams } = require('./validator');\n\nmodule.exports = {\n  errorHandler,\n  notFoundHandler,\n  requestLogger,\n  validateBody,\n  validateQuery,\n  validateParams\n};",
          "description": "Aggregates and reexports all middleware functions.",
          "exports": [
            "errorHandler",
            "notFoundHandler",
            "requestLogger",
            "validateBody",
            "validateQuery",
            "validateParams"
          ]
        },
        {
          "path": "src/services/index.js",
          "content": "const { createOrganizationsServices } = require('./organizationsServices');\nconst { createOrganizationUsersServices } = require('./organizationUsersServices');\nconst { createUsersServices } = require('./usersServices');\nconst { createShipmentsServices } = require('./shipmentsServices');\nconst { createCarriersServices } = require('./carriersServices');\nconst { createShipmentStatusServices } = require('./shipmentStatusServices');\nconst { createShipmentLocationsServices } = require('./shipmentLocationsServices');\nconst { createShipmentAlertsServices } = require('./shipmentAlertsServices');\nconst { createSettingsServices } = require('./settingsServices');\nconst { createAuditLogsServices } = require('./auditLogsServices');\n\nmodule.exports = {\n  createOrganizationsServices,\n  createOrganizationUsersServices,\n  createUsersServices,\n  createShipmentsServices,\n  createCarriersServices,\n  createShipmentStatusServices,\n  createShipmentLocationsServices,\n  createShipmentAlertsServices,\n  createSettingsServices,\n  createAuditLogsServices\n};",
          "description": "Re-exports all service factories",
          "exports": [
            "createOrganizationsServices",
            "createOrganizationUsersServices",
            "createUsersServices",
            "createShipmentsServices",
            "createCarriersServices",
            "createShipmentStatusServices",
            "createShipmentLocationsServices",
            "createShipmentAlertsServices",
            "createSettingsServices",
            "createAuditLogsServices"
          ]
        },
        {
          "path": "src/services/organizationsServices.js",
          "content": "const { createOrganizationsModels } = require('../models/organizationsModels');\n\nconst createOrganizationsServices = () => {\n  const organizationsModel = createOrganizationsModels();\n\n  const getAllRecords = async (filters, options) => {\n    try {\n      return await organizationsModel.findAllRecords(filters, options);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const getRecords = async (id) => {\n    try {\n      return await organizationsModel.findByIdRecord(id);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const createRecords = async (data) => {\n    try {\n      return await organizationsModel.createRecord(data);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const updateRecords = async (id, data) => {\n    try {\n      return await organizationsModel.updateByIdRecord(id, data);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const removeRecords = async (id) => {\n    try {\n      return await organizationsModel.deleteByIdRecord(id);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  return {\n    getAllRecords,\n    getRecords,\n    createRecords,\n    updateRecords,\n    removeRecords\n  };\n};\n\nmodule.exports = { createOrganizationsServices };",
          "description": "Organizations service factory with CRUD methods",
          "exports": [
            "createOrganizationsServices"
          ]
        },
        {
          "path": "src/services/organizationUsersServices.js",
          "content": "const { createOrganizationUsersModels } = require('../models/organizationUsersModels');\n\nconst createOrganizationUsersServices = () => {\n  const organizationUsersModel = createOrganizationUsersModels();\n\n  const getAllRecords = async (filters, options) => {\n    try {\n      return await organizationUsersModel.findAllRecords(filters, options);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const getRecords = async (id) => {\n    try {\n      return await organizationUsersModel.findByIdRecord(id);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const createRecords = async (data) => {\n    try {\n      return await organizationUsersModel.createRecord(data);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const updateRecords = async (id, data) => {\n    try {\n      return await organizationUsersModel.updateByIdRecord(id, data);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const removeRecords = async (id) => {\n    try {\n      return await organizationUsersModel.deleteByIdRecord(id);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  return {\n    getAllRecords,\n    getRecords,\n    createRecords,\n    updateRecords,\n    removeRecords\n  };\n};\n\nmodule.exports = { createOrganizationUsersServices };",
          "description": "Organization users service factory",
          "exports": [
            "createOrganizationUsersServices"
          ]
        },
        {
          "path": "src/services/usersServices.js",
          "content": "const { createUsersModels } = require('../models/usersModels');\n\nconst createUsersServices = () => {\n  const usersModel = createUsersModels();\n\n  const getAllRecords = async (filters, options) => {\n    try {\n      return await usersModel.findAllRecords(filters, options);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const getRecords = async (id) => {\n    try {\n      return await usersModel.findByIdRecord(id);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const createRecords = async (data) => {\n    try {\n      return await usersModel.createRecord(data);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const updateRecords = async (id, data) => {\n    try {\n      return await usersModel.updateByIdRecord(id, data);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const removeRecords = async (id) => {\n    try {\n      return await usersModel.deleteByIdRecord(id);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  return {\n    getAllRecords,\n    getRecords,\n    createRecords,\n    updateRecords,\n    removeRecords\n  };\n};\n\nmodule.exports = { createUsersServices };",
          "description": "Users service factory",
          "exports": [
            "createUsersServices"
          ]
        },
        {
          "path": "src/services/shipmentsServices.js",
          "content": "const { createShipmentsModels } = require('../models/shipmentsModels');\n\nconst createShipmentsServices = () => {\n  const shipmentsModel = createShipmentsModels();\n\n  const getAllRecords = async (filters, options) => {\n    try {\n      return await shipmentsModel.findAllRecords(filters, options);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const getRecords = async (id) => {\n    try {\n      return await shipmentsModel.findByIdRecord(id);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const createRecords = async (data) => {\n    try {\n      return await shipmentsModel.createRecord(data);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const updateRecords = async (id, data) => {\n    try {\n      return await shipmentsModel.updateByIdRecord(id, data);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const removeRecords = async (id) => {\n    try {\n      return await shipmentsModel.deleteByIdRecord(id);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  return {\n    getAllRecords,\n    getRecords,\n    createRecords,\n    updateRecords,\n    removeRecords\n  };\n};\n\nmodule.exports = { createShipmentsServices };",
          "description": "Shipments service factory",
          "exports": [
            "createShipmentsServices"
          ]
        },
        {
          "path": "src/services/carriersServices.js",
          "content": "const { createCarriersModels } = require('../models/carriersModels');\n\nconst createCarriersServices = () => {\n  const carriersModel = createCarriersModels();\n\n  const getAllRecords = async (filters, options) => {\n    try {\n      return await carriersModel.findAllRecords(filters, options);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const getRecords = async (id) => {\n    try {\n      return await carriersModel.findByIdRecord(id);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const createRecords = async (data) => {\n    try {\n      return await carriersModel.createRecord(data);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const updateRecords = async (id, data) => {\n    try {\n      return await carriersModel.updateByIdRecord(id, data);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const removeRecords = async (id) => {\n    try {\n      return await carriersModel.deleteByIdRecord(id);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  return {\n    getAllRecords,\n    getRecords,\n    createRecords,\n    updateRecords,\n    removeRecords\n  };\n};\n\nmodule.exports = { createCarriersServices };",
          "description": "Carriers service factory",
          "exports": [
            "createCarriersServices"
          ]
        },
        {
          "path": "src/services/shipmentStatusServices.js",
          "content": "const { createShipmentStatusModels } = require('../models/shipmentStatusModels');\n\nconst createShipmentStatusServices = () => {\n  const shipmentStatusModel = createShipmentStatusModels();\n\n  const getAllRecords = async (filters, options) => {\n    try {\n      return await shipmentStatusModel.findAllRecords(filters, options);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const getRecords = async (id) => {\n    try {\n      return await shipmentStatusModel.findByIdRecord(id);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const createRecords = async (data) => {\n    try {\n      return await shipmentStatusModel.createRecord(data);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const updateRecords = async (id, data) => {\n    try {\n      return await shipmentStatusModel.updateByIdRecord(id, data);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const removeRecords = async (id) => {\n    try {\n      return await shipmentStatusModel.deleteByIdRecord(id);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  return {\n    getAllRecords,\n    getRecords,\n    createRecords,\n    updateRecords,\n    removeRecords\n  };\n};\n\nmodule.exports = { createShipmentStatusServices };",
          "description": "Shipment status service factory",
          "exports": [
            "createShipmentStatusServices"
          ]
        },
        {
          "path": "src/services/shipmentLocationsServices.js",
          "content": "const { createShipmentLocationsModels } = require('../models/shipmentLocationsModels');\n\nconst createShipmentLocationsServices = () => {\n  const shipmentLocationsModel = createShipmentLocationsModels();\n\n  const getAllRecords = async (filters, options) => {\n    try {\n      return await shipmentLocationsModel.findAllRecords(filters, options);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const getRecords = async (id) => {\n    try {\n      return await shipmentLocationsModel.findByIdRecord(id);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const createRecords = async (data) => {\n    try {\n      return await shipmentLocationsModel.createRecord(data);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const updateRecords = async (id, data) => {\n    try {\n      return await shipmentLocationsModel.updateByIdRecord(id, data);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const removeRecords = async (id) => {\n    try {\n      return await shipmentLocationsModel.deleteByIdRecord(id);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  return {\n    getAllRecords,\n    getRecords,\n    createRecords,\n    updateRecords,\n    removeRecords\n  };\n};\n\nmodule.exports = { createShipmentLocationsServices };",
          "description": "Shipment locations service factory",
          "exports": [
            "createShipmentLocationsServices"
          ]
        },
        {
          "path": "src/services/shipmentAlertsServices.js",
          "content": "const { createShipmentAlertsModels } = require('../models/shipmentAlertsModels');\n\nconst createShipmentAlertsServices = () => {\n  const shipmentAlertsModel = createShipmentAlertsModels();\n\n  const getAllRecords = async (filters, options) => {\n    try {\n      return await shipmentAlertsModel.findAllRecords(filters, options);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const getRecords = async (id) => {\n    try {\n      return await shipmentAlertsModel.findByIdRecord(id);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const createRecords = async (data) => {\n    try {\n      return await shipmentAlertsModel.createRecord(data);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const updateRecords = async (id, data) => {\n    try {\n      return await shipmentAlertsModel.updateByIdRecord(id, data);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const removeRecords = async (id) => {\n    try {\n      return await shipmentAlertsModel.deleteByIdRecord(id);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  return {\n    getAllRecords,\n    getRecords,\n    createRecords,\n    updateRecords,\n    removeRecords\n  };\n};\n\nmodule.exports = { createShipmentAlertsServices };",
          "description": "Shipment alerts service factory",
          "exports": [
            "createShipmentAlertsServices"
          ]
        },
        {
          "path": "src/services/settingsServices.js",
          "content": "const { createSettingsModels } = require('../models/settingsModels');\n\nconst createSettingsServices = () => {\n  const settingsModel = createSettingsModels();\n\n  const getAllRecords = async (filters, options) => {\n    try {\n      return await settingsModel.findAllRecords(filters, options);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const getRecords = async (id) => {\n    try {\n      return await settingsModel.findByIdRecord(id);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const createRecords = async (data) => {\n    try {\n      return await settingsModel.createRecord(data);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const updateRecords = async (id, data) => {\n    try {\n      return await settingsModel.updateByIdRecord(id, data);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const removeRecords = async (id) => {\n    try {\n      return await settingsModel.deleteByIdRecord(id);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  return {\n    getAllRecords,\n    getRecords,\n    createRecords,\n    updateRecords,\n    removeRecords\n  };\n};\n\nmodule.exports = { createSettingsServices };",
          "description": "Settings service factory",
          "exports": [
            "createSettingsServices"
          ]
        },
        {
          "path": "src/services/auditLogsServices.js",
          "content": "const { createAuditLogsModels } = require('../models/auditLogsModels');\n\nconst createAuditLogsServices = () => {\n  const auditLogsModel = createAuditLogsModels();\n\n  const getAllRecords = async (filters, options) => {\n    try {\n      return await auditLogsModel.findAllRecords(filters, options);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const getRecords = async (id) => {\n    try {\n      return await auditLogsModel.findByIdRecord(id);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const createRecords = async (data) => {\n    try {\n      return await auditLogsModel.createRecord(data);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const updateRecords = async (id, data) => {\n    try {\n      return await auditLogsModel.updateByIdRecord(id, data);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  const removeRecords = async (id) => {\n    try {\n      return await auditLogsModel.deleteByIdRecord(id);\n    } catch (error) {\n      throw error;\n    }\n  };\n\n  return {\n    getAllRecords,\n    getRecords,\n    createRecords,\n    updateRecords,\n    removeRecords\n  };\n};\n\nmodule.exports = { createAuditLogsServices };",
          "description": "Audit logs service factory",
          "exports": [
            "createAuditLogsServices"
          ]
        },
        {
          "path": "src/services/userServices.js",
          "content": "const { createUsersModels } = require('../models/usersModels');\nconst { createNotFoundError, createError } = require('../utils/errors');\n\nconst createUserServices = () => {\n  const usersModel = createUsersModels();\n\n  const getAllRecords = async (filters = {}, options = {}) => {\n    try {\n      const records = await usersModel.findAllRecords(filters, options);\n      return records;\n    } catch (err) {\n      throw createError('Failed to fetch users', err.status || 500, err.code);\n    }\n  };\n\n  const getRecords = async (id) => {\n    try {\n      const record = await usersModel.findByIdRecord(id);\n      if (!record) {\n        throw createNotFoundError(`User with id ${id} not found`);\n      }\n      return record;\n    } catch (err) {\n      if (err.status === 404) throw err;\n      throw createError('Failed to fetch user', err.status || 500, err.code);\n    }\n  };\n\n  const createRecords = async (data) => {\n    try {\n      const newRecord = await usersModel.createRecord(data);\n      return newRecord;\n    } catch (err) {\n      throw createError('Failed to create user', err.status || 500, err.code);\n    }\n  };\n\n  const updateRecords = async (id, data) => {\n    try {\n      const updated = await usersModel.updateByIdRecord(id, data);\n      if (!updated) {\n        throw createNotFoundError(`User with id ${id} not found`);\n      }\n      return updated;\n    } catch (err) {\n      if (err.status === 404) throw err;\n      throw createError('Failed to update user', err.status || 500, err.code);\n    }\n  };\n\n  const removeRecords = async (id) => {\n    try {\n      const removed = await usersModel.deleteByIdRecord(id);\n      if (!removed) {\n        throw createNotFoundError(`User with id ${id} not found`);\n      }\n      return removed;\n    } catch (err) {\n      if (err.status === 404) throw err;\n      throw createError('Failed to delete user', err.status || 500, err.code);\n    }\n  };\n\n  return {\n    getAllRecords,\n    getRecords,\n    createRecords,\n    updateRecords,\n    removeRecords,\n  };\n};\n\nmodule.exports = { createUserServices };",
          "description": "User service factory with full CRUD implementations using users model",
          "exports": [
            "createUserServices"
          ]
        },
        {
          "path": "src/services/organizationServices.js",
          "content": "const { createOrganizationsModels } = require('../models/organizationsModels');\nconst { createNotFoundError, createError } = require('../utils/errors');\n\nconst createOrganizationServices = () => {\n  const orgModel = createOrganizationsModels();\n\n  const getAllRecords = async (filters = {}, options = {}) => {\n    try {\n      return await orgModel.findAllRecords(filters, options);\n    } catch (err) {\n      throw createError('Failed to fetch organizations', err.status || 500, err.code);\n    }\n  };\n\n  const getRecords = async (id) => {\n    try {\n      const record = await orgModel.findByIdRecord(id);\n      if (!record) {\n        throw createNotFoundError(`Organization with id ${id} not found`);\n      }\n      return record;\n    } catch (err) {\n      if (err.status === 404) throw err;\n      throw createError('Failed to fetch organization', err.status || 500, err.code);\n    }\n  };\n\n  const createRecords = async (data) => {\n    try {\n      return await orgModel.createRecord(data);\n    } catch (err) {\n      throw createError('Failed to create organization', err.status || 500, err.code);\n    }\n  };\n\n  const updateRecords = async (id, data) => {\n    try {\n      const updated = await orgModel.updateByIdRecord(id, data);\n      if (!updated) {\n        throw createNotFoundError(`Organization with id ${id} not found`);\n      }\n      return updated;\n    } catch (err) {\n      if (err.status === 404) throw err;\n      throw createError('Failed to update organization', err.status || 500, err.code);\n    }\n  };\n\n  const removeRecords = async (id) => {\n    try {\n      const removed = await orgModel.deleteByIdRecord(id);\n      if (!removed) {\n        throw createNotFoundError(`Organization with id ${id} not found`);\n      }\n      return removed;\n    } catch (err) {\n      if (err.status === 404) throw err;\n      throw createError('Failed to delete organization', err.status || 500, err.code);\n    }\n  };\n\n  return {\n    getAllRecords,\n    getRecords,\n    createRecords,\n    updateRecords,\n    removeRecords,\n  };\n};\n\nmodule.exports = { createOrganizationServices };",
          "description": "Organization service factory with full CRUD implementations",
          "exports": [
            "createOrganizationServices"
          ]
        },
        {
          "path": "src/services/shipmentServices.js",
          "content": "const { createShipmentsModels } = require('../models/shipmentsModels');\nconst { createNotFoundError, createError } = require('../utils/errors');\n\nconst createShipmentServices = () => {\n  const shipmentModel = createShipmentsModels();\n\n  const getAllRecords = async (filters = {}, options = {}) => {\n    try {\n      return await shipmentModel.findAllRecords(filters, options);\n    } catch (err) {\n      throw createError('Failed to fetch shipments', err.status || 500, err.code);\n    }\n  };\n\n  const getRecords = async (id) => {\n    try {\n      const record = await shipmentModel.findByIdRecord(id);\n      if (!record) {\n        throw createNotFoundError(`Shipment with id ${id} not found`);\n      }\n      return record;\n    } catch (err) {\n      if (err.status === 404) throw err;\n      throw createError('Failed to fetch shipment', err.status || 500, err.code);\n    }\n  };\n\n  const createRecords = async (data) => {\n    try {\n      return await shipmentModel.createRecord(data);\n    } catch (err) {\n      throw createError('Failed to create shipment', err.status || 500, err.code);\n    }\n  };\n\n  const updateRecords = async (id, data) => {\n    try {\n      const updated = await shipmentModel.updateByIdRecord(id, data);\n      if (!updated) {\n        throw createNotFoundError(`Shipment with id ${id} not found`);\n      }\n      return updated;\n    } catch (err) {\n      if (err.status === 404) throw err;\n      throw createError('Failed to update shipment', err.status || 500, err.code);\n    }\n  };\n\n  const removeRecords = async (id) => {\n    try {\n      const removed = await shipmentModel.deleteByIdRecord(id);\n      if (!removed) {\n        throw createNotFoundError(`Shipment with id ${id} not found`);\n      }\n      return removed;\n    } catch (err) {\n      if (err.status === 404) throw err;\n      throw createError('Failed to delete shipment', err.status || 500, err.code);\n    }\n  };\n\n  return {\n    getAllRecords,\n    getRecords,\n    createRecords,\n    updateRecords,\n    removeRecords,\n  };\n};\n\nmodule.exports = { createShipmentServices };",
          "description": "Shipment service factory with full CRUD implementations",
          "exports": [
            "createShipmentServices"
          ]
        },
        {
          "path": "src/services/carrierServices.js",
          "content": "const { createCarriersModels } = require('../models/carriersModels');\nconst { createNotFoundError, createError } = require('../utils/errors');\n\nconst createCarrierServices = () => {\n  const carrierModel = createCarriersModels();\n\n  const getAllRecords = async (filters = {}, options = {}) => {\n    try {\n      return await carrierModel.findAllRecords(filters, options);\n    } catch (err) {\n      throw createError('Failed to fetch carriers', err.status || 500, err.code);\n    }\n  };\n\n  const getRecords = async (id) => {\n    try {\n      const record = await carrierModel.findByIdRecord(id);\n      if (!record) {\n        throw createNotFoundError(`Carrier with id ${id} not found`);\n      }\n      return record;\n    } catch (err) {\n      if (err.status === 404) throw err;\n      throw createError('Failed to fetch carrier', err.status || 500, err.code);\n    }\n  };\n\n  const createRecords = async (data) => {\n    try {\n      return await carrierModel.createRecord(data);\n    } catch (err) {\n      throw createError('Failed to create carrier', err.status || 500, err.code);\n    }\n  };\n\n  const updateRecords = async (id, data) => {\n    try {\n      const updated = await carrierModel.updateByIdRecord(id, data);\n      if (!updated) {\n        throw createNotFoundError(`Carrier with id ${id} not found`);\n      }\n      return updated;\n    } catch (err) {\n      if (err.status === 404) throw err;\n      throw createError('Failed to update carrier', err.status || 500, err.code);\n    }\n  };\n\n  const removeRecords = async (id) => {\n    try {\n      const removed = await carrierModel.deleteByIdRecord(id);\n      if (!removed) {\n        throw createNotFoundError(`Carrier with id ${id} not found`);\n      }\n      return removed;\n    } catch (err) {\n      if (err.status === 404) throw err;\n      throw createError('Failed to delete carrier', err.status || 500, err.code);\n    }\n  };\n\n  return {\n    getAllRecords,\n    getRecords,\n    createRecords,\n    updateRecords,\n    removeRecords,\n  };\n};\n\nmodule.exports = { createCarrierServices };",
          "description": "Carrier service factory with full CRUD implementations",
          "exports": [
            "createCarrierServices"
          ]
        },
        {
          "path": "src/services/authenticationServices.js",
          "content": "const { createError } = require('../utils/errors');\n\nconst createAuthenticationServices = () => {\n  // Placeholder authentication logic  can be expanded with Cognito integration\n  const getAllRecords = async () => {\n    try {\n      // No persistent storage for authentication records in this stub\n      return [];\n    } catch (err) {\n      throw createError('Failed to fetch authentication records', err.status || 500, err.code);\n    }\n  };\n\n  const getRecords = async (id) => {\n    try {\n      // Stub  normally would retrieve a user session or token info\n      return { id, message: 'Authentication record stub' };\n    } catch (err) {\n      throw createError('Failed to fetch authentication record', err.status || 500, err.code);\n    }\n  };\n\n  const createRecords = async (data) => {\n    try {\n      // Stub  normally would create a session/token\n      return { ...data, createdAt: new Date().toISOString() };\n    } catch (err) {\n      throw createError('Failed to create authentication record', err.status || 500, err.code);\n    }\n  };\n\n  const updateRecords = async (id, data) => {\n    try {\n      // Stub  normally would update session info\n      return { id, ...data };\n    } catch (err) {\n      throw createError('Failed to update authentication record', err.status || 500, err.code);\n    }\n  };\n\n  const removeRecords = async (id) => {\n    try {\n      // Stub  normally would revoke token\n      return { id, revoked: true };\n    } catch (err) {\n      throw createError('Failed to delete authentication record', err.status || 500, err.code);\n    }\n  };\n\n  return {\n    getAllRecords,\n    getRecords,\n    createRecords,\n    updateRecords,\n    removeRecords,\n  };\n};\n\nmodule.exports = { createAuthenticationServices };",
          "description": "Authentication service factory with stubbed methods",
          "exports": [
            "createAuthenticationServices"
          ]
        },
        {
          "path": "src/services/errorServices.js",
          "content": "const { createError } = require('../utils/errors');\n\nconst createErrorServices = () => {\n  const getAllRecords = async () => {\n    try {\n      // No persistent error records; return empty array\n      return [];\n    } catch (err) {\n      throw createError('Failed to fetch error records', err.status || 500, err.code);\n    }\n  };\n\n  const getRecords = async (id) => {\n    try {\n      return { id, message: 'Error record stub' };\n    } catch (err) {\n      throw createError('Failed to fetch error record', err.status || 500, err.code);\n    }\n  };\n\n  const createRecords = async (data) => {\n    try {\n      return { ...data, loggedAt: new Date().toISOString() };\n    } catch (err) {\n      throw createError('Failed to create error record', err.status || 500, err.code);\n    }\n  };\n\n  const updateRecords = async (id, data) => {\n    try {\n      return { id, ...data };\n    } catch (err) {\n      throw createError('Failed to update error record', err.status || 500, err.code);\n    }\n  };\n\n  const removeRecords = async (id) => {\n    try {\n      return { id, removed: true };\n    } catch (err) {\n      throw createError('Failed to delete error record', err.status || 500, err.code);\n    }\n  };\n\n  return {\n    getAllRecords,\n    getRecords,\n    createRecords,\n    updateRecords,\n    removeRecords,\n  };\n};\n\nmodule.exports = { createErrorServices };",
          "description": "Error service factory with stubbed CRUD methods",
          "exports": [
            "createErrorServices"
          ]
        },
        {
          "path": "src/services/emailserviceadapterServices.js",
          "content": "const { createError } = require('../utils/errors');\n\nconst createEmailserviceadapterServices = () => {\n  // Stub implementation  replace with real email provider integration\n  const getAllRecords = async () => {\n    try {\n      return [];\n    } catch (err) {\n      throw createError('Failed to fetch email service records', err.status || 500, err.code);\n    }\n  };\n\n  const getRecords = async (id) => {\n    try {\n      return { id, status: 'sent' };\n    } catch (err) {\n      throw createError('Failed to fetch email service record', err.status || 500, err.code);\n    }\n  };\n\n  const createRecords = async (data) => {\n    try {\n      // Simulate sending email\n      return { ...data, sentAt: new Date().toISOString(), status: 'sent' };\n    } catch (err) {\n      throw createError('Failed to send email', err.status || 500, err.code);\n    }\n  };\n\n  const updateRecords = async (id, data) => {\n    try {\n      // Typically emails aren't updated; return stub\n      return { id, ...data };\n    } catch (err) {\n      throw createError('Failed to update email record', err.status || 500, err.code);\n    }\n  };\n\n  const removeRecords = async (id) => {\n    try {\n      // Simulate deletion of email log\n      return { id, deleted: true };\n    } catch (err) {\n      throw createError('Failed to delete email record', err.status || 500, err.code);\n    }\n  };\n\n  return {\n    getAllRecords,\n    getRecords,\n    createRecords,\n    updateRecords,\n    removeRecords,\n  };\n};\n\nmodule.exports = { createEmailserviceadapterServices };",
          "description": "Email service adapter factory with stubbed email operations",
          "exports": [
            "createEmailserviceadapterServices"
          ]
        },
        {
          "path": "src/handlers/organizationsHandlers.js",
          "content": "const { createOrganizationsServices } = require('../services/organizationsServices');\nconst { sendSuccess, sendCreated, sendNoContent, sendError } = require('../utils/responses');\n\nconst organizationsService = createOrganizationsServices();\n\nasync function handleGetAllOrganizationsRecords(req, res, next) {\n  try {\n    const records = await organizationsService.getAllRecords();\n    sendSuccess(res, records, 'Organizations retrieved successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleGetOrganizationsRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    const record = await organizationsService.getRecords(id);\n    sendSuccess(res, record, 'Organization retrieved successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleCreateOrganizationsRecords(req, res, next) {\n  try {\n    const data = req.body;\n    const created = await organizationsService.createRecords(data);\n    sendCreated(res, created, 'Organization created successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleUpdateOrganizationsRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    const data = req.body;\n    const updated = await organizationsService.updateRecords(id, data);\n    sendSuccess(res, updated, 'Organization updated successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleDeleteOrganizationsRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    await organizationsService.removeRecords(id);\n    sendNoContent(res);\n  } catch (error) {\n    next(error);\n  }\n}\n\nmodule.exports = {\n  handleGetAllOrganizationsRecords,\n  handleGetOrganizationsRecords,\n  handleCreateOrganizationsRecords,\n  handleUpdateOrganizationsRecords,\n  handleDeleteOrganizationsRecords\n};",
          "description": "Handlers for organization CRUD operations",
          "exports": [
            "handleGetAllOrganizationsRecords",
            "handleGetOrganizationsRecords",
            "handleCreateOrganizationsRecords",
            "handleUpdateOrganizationsRecords",
            "handleDeleteOrganizationsRecords"
          ]
        },
        {
          "path": "src/handlers/organizationUsersHandlers.js",
          "content": "const { createOrganizationUsersServices } = require('../services/organizationUsersServices');\nconst { sendSuccess, sendCreated, sendNoContent, sendError } = require('../utils/responses');\n\nconst organizationUsersService = createOrganizationUsersServices();\n\nasync function handleGetAllOrganizationUsersRecords(req, res, next) {\n  try {\n    const records = await organizationUsersService.getAllRecords();\n    sendSuccess(res, records, 'Organization users retrieved successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleGetOrganizationUsersRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    const record = await organizationUsersService.getRecords(id);\n    sendSuccess(res, record, 'Organization user retrieved successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleCreateOrganizationUsersRecords(req, res, next) {\n  try {\n    const data = req.body;\n    const created = await organizationUsersService.createRecords(data);\n    sendCreated(res, created, 'Organization user created successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleUpdateOrganizationUsersRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    const data = req.body;\n    const updated = await organizationUsersService.updateRecords(id, data);\n    sendSuccess(res, updated, 'Organization user updated successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleDeleteOrganizationUsersRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    await organizationUsersService.removeRecords(id);\n    sendNoContent(res);\n  } catch (error) {\n    next(error);\n  }\n}\n\nmodule.exports = {\n  handleGetAllOrganizationUsersRecords,\n  handleGetOrganizationUsersRecords,\n  handleCreateOrganizationUsersRecords,\n  handleUpdateOrganizationUsersRecords,\n  handleDeleteOrganizationUsersRecords\n};",
          "description": "Handlers for organization user CRUD operations",
          "exports": [
            "handleGetAllOrganizationUsersRecords",
            "handleGetOrganizationUsersRecords",
            "handleCreateOrganizationUsersRecords",
            "handleUpdateOrganizationUsersRecords",
            "handleDeleteOrganizationUsersRecords"
          ]
        },
        {
          "path": "src/handlers/usersHandlers.js",
          "content": "const { createUsersServices } = require('../services/usersServices');\nconst { sendSuccess, sendCreated, sendNoContent, sendError } = require('../utils/responses');\n\nconst usersService = createUsersServices();\n\nasync function handleGetAllUsersRecords(req, res, next) {\n  try {\n    const records = await usersService.getAllRecords();\n    sendSuccess(res, records, 'Users retrieved successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleGetUsersRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    const record = await usersService.getRecords(id);\n    sendSuccess(res, record, 'User retrieved successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleCreateUsersRecords(req, res, next) {\n  try {\n    const data = req.body;\n    const created = await usersService.createRecords(data);\n    sendCreated(res, created, 'User created successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleUpdateUsersRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    const data = req.body;\n    const updated = await usersService.updateRecords(id, data);\n    sendSuccess(res, updated, 'User updated successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleDeleteUsersRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    await usersService.removeRecords(id);\n    sendNoContent(res);\n  } catch (error) {\n    next(error);\n  }\n}\n\nmodule.exports = {\n  handleGetAllUsersRecords,\n  handleGetUsersRecords,\n  handleCreateUsersRecords,\n  handleUpdateUsersRecords,\n  handleDeleteUsersRecords\n};",
          "description": "Handlers for user CRUD operations",
          "exports": [
            "handleGetAllUsersRecords",
            "handleGetUsersRecords",
            "handleCreateUsersRecords",
            "handleUpdateUsersRecords",
            "handleDeleteUsersRecords"
          ]
        },
        {
          "path": "src/handlers/shipmentsHandlers.js",
          "content": "const { createShipmentsServices } = require('../services/shipmentsServices');\nconst { sendSuccess, sendCreated, sendNoContent, sendError } = require('../utils/responses');\n\nconst shipmentsService = createShipmentsServices();\n\nasync function handleGetAllShipmentsRecords(req, res, next) {\n  try {\n    const records = await shipmentsService.getAllRecords();\n    sendSuccess(res, records, 'Shipments retrieved successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleGetShipmentsRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    const record = await shipmentsService.getRecords(id);\n    sendSuccess(res, record, 'Shipment retrieved successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleCreateShipmentsRecords(req, res, next) {\n  try {\n    const data = req.body;\n    const created = await shipmentsService.createRecords(data);\n    sendCreated(res, created, 'Shipment created successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleUpdateShipmentsRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    const data = req.body;\n    const updated = await shipmentsService.updateRecords(id, data);\n    sendSuccess(res, updated, 'Shipment updated successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleDeleteShipmentsRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    await shipmentsService.removeRecords(id);\n    sendNoContent(res);\n  } catch (error) {\n    next(error);\n  }\n}\n\nmodule.exports = {\n  handleGetAllShipmentsRecords,\n  handleGetShipmentsRecords,\n  handleCreateShipmentsRecords,\n  handleUpdateShipmentsRecords,\n  handleDeleteShipmentsRecords\n};",
          "description": "Handlers for shipment CRUD operations",
          "exports": [
            "handleGetAllShipmentsRecords",
            "handleGetShipmentsRecords",
            "handleCreateShipmentsRecords",
            "handleUpdateShipmentsRecords",
            "handleDeleteShipmentsRecords"
          ]
        },
        {
          "path": "src/handlers/carriersHandlers.js",
          "content": "const { createCarriersServices } = require('../services/carriersServices');\nconst { sendSuccess, sendCreated, sendNoContent, sendError } = require('../utils/responses');\n\nconst carriersService = createCarriersServices();\n\nasync function handleGetAllCarriersRecords(req, res, next) {\n  try {\n    const records = await carriersService.getAllRecords();\n    sendSuccess(res, records, 'Carriers retrieved successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleGetCarriersRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    const record = await carriersService.getRecords(id);\n    sendSuccess(res, record, 'Carrier retrieved successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleCreateCarriersRecords(req, res, next) {\n  try {\n    const data = req.body;\n    const created = await carriersService.createRecords(data);\n    sendCreated(res, created, 'Carrier created successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleUpdateCarriersRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    const data = req.body;\n    const updated = await carriersService.updateRecords(id, data);\n    sendSuccess(res, updated, 'Carrier updated successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleDeleteCarriersRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    await carriersService.removeRecords(id);\n    sendNoContent(res);\n  } catch (error) {\n    next(error);\n  }\n}\n\nmodule.exports = {\n  handleGetAllCarriersRecords,\n  handleGetCarriersRecords,\n  handleCreateCarriersRecords,\n  handleUpdateCarriersRecords,\n  handleDeleteCarriersRecords\n};",
          "description": "Handlers for carrier CRUD operations",
          "exports": [
            "handleGetAllCarriersRecords",
            "handleGetCarriersRecords",
            "handleCreateCarriersRecords",
            "handleUpdateCarriersRecords",
            "handleDeleteCarriersRecords"
          ]
        },
        {
          "path": "src/handlers/shipmentStatusHandlers.js",
          "content": "const { createShipmentStatusServices } = require('../services/shipmentStatusServices');\nconst { sendSuccess, sendCreated, sendNoContent, sendError } = require('../utils/responses');\n\nconst shipmentStatusService = createShipmentStatusServices();\n\nasync function handleGetAllShipmentStatusRecords(req, res, next) {\n  try {\n    const records = await shipmentStatusService.getAllRecords();\n    sendSuccess(res, records, 'Shipment status records retrieved successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleGetShipmentStatusRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    const record = await shipmentStatusService.getRecords(id);\n    sendSuccess(res, record, 'Shipment status record retrieved successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleCreateShipmentStatusRecords(req, res, next) {\n  try {\n    const data = req.body;\n    const created = await shipmentStatusService.createRecords(data);\n    sendCreated(res, created, 'Shipment status record created successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleUpdateShipmentStatusRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    const data = req.body;\n    const updated = await shipmentStatusService.updateRecords(id, data);\n    sendSuccess(res, updated, 'Shipment status record updated successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleDeleteShipmentStatusRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    await shipmentStatusService.removeRecords(id);\n    sendNoContent(res);\n  } catch (error) {\n    next(error);\n  }\n}\n\nmodule.exports = {\n  handleGetAllShipmentStatusRecords,\n  handleGetShipmentStatusRecords,\n  handleCreateShipmentStatusRecords,\n  handleUpdateShipmentStatusRecords,\n  handleDeleteShipmentStatusRecords\n};",
          "description": "Handlers for shipment status CRUD operations",
          "exports": [
            "handleGetAllShipmentStatusRecords",
            "handleGetShipmentStatusRecords",
            "handleCreateShipmentStatusRecords",
            "handleUpdateShipmentStatusRecords",
            "handleDeleteShipmentStatusRecords"
          ]
        },
        {
          "path": "src/handlers/shipmentLocationsHandlers.js",
          "content": "const { createShipmentLocationsServices } = require('../services/shipmentLocationsServices');\nconst { sendSuccess, sendCreated, sendNoContent, sendError } = require('../utils/responses');\n\nconst shipmentLocationsService = createShipmentLocationsServices();\n\nasync function handleGetAllShipmentLocationsRecords(req, res, next) {\n  try {\n    const records = await shipmentLocationsService.getAllRecords();\n    sendSuccess(res, records, 'Shipment locations retrieved successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleGetShipmentLocationsRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    const record = await shipmentLocationsService.getRecords(id);\n    sendSuccess(res, record, 'Shipment location retrieved successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleCreateShipmentLocationsRecords(req, res, next) {\n  try {\n    const data = req.body;\n    const created = await shipmentLocationsService.createRecords(data);\n    sendCreated(res, created, 'Shipment location created successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleUpdateShipmentLocationsRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    const data = req.body;\n    const updated = await shipmentLocationsService.updateRecords(id, data);\n    sendSuccess(res, updated, 'Shipment location updated successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleDeleteShipmentLocationsRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    await shipmentLocationsService.removeRecords(id);\n    sendNoContent(res);\n  } catch (error) {\n    next(error);\n  }\n}\n\nmodule.exports = {\n  handleGetAllShipmentLocationsRecords,\n  handleGetShipmentLocationsRecords,\n  handleCreateShipmentLocationsRecords,\n  handleUpdateShipmentLocationsRecords,\n  handleDeleteShipmentLocationsRecords\n};",
          "description": "Handlers for shipment locations CRUD operations",
          "exports": [
            "handleGetAllShipmentLocationsRecords",
            "handleGetShipmentLocationsRecords",
            "handleCreateShipmentLocationsRecords",
            "handleUpdateShipmentLocationsRecords",
            "handleDeleteShipmentLocationsRecords"
          ]
        },
        {
          "path": "src/handlers/shipmentAlertsHandlers.js",
          "content": "const { createShipmentAlertsServices } = require('../services/shipmentAlertsServices');\nconst { sendSuccess, sendCreated, sendNoContent, sendError } = require('../utils/responses');\n\nconst shipmentAlertsService = createShipmentAlertsServices();\n\nasync function handleGetAllShipmentAlertsRecords(req, res, next) {\n  try {\n    const records = await shipmentAlertsService.getAllRecords();\n    sendSuccess(res, records, 'Shipment alerts retrieved successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleGetShipmentAlertsRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    const record = await shipmentAlertsService.getRecords(id);\n    sendSuccess(res, record, 'Shipment alert retrieved successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleCreateShipmentAlertsRecords(req, res, next) {\n  try {\n    const data = req.body;\n    const created = await shipmentAlertsService.createRecords(data);\n    sendCreated(res, created, 'Shipment alert created successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleUpdateShipmentAlertsRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    const data = req.body;\n    const updated = await shipmentAlertsService.updateRecords(id, data);\n    sendSuccess(res, updated, 'Shipment alert updated successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleDeleteShipmentAlertsRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    await shipmentAlertsService.removeRecords(id);\n    sendNoContent(res);\n  } catch (error) {\n    next(error);\n  }\n}\n\nmodule.exports = {\n  handleGetAllShipmentAlertsRecords,\n  handleGetShipmentAlertsRecords,\n  handleCreateShipmentAlertsRecords,\n  handleUpdateShipmentAlertsRecords,\n  handleDeleteShipmentAlertsRecords\n};",
          "description": "Handlers for shipment alerts CRUD operations",
          "exports": [
            "handleGetAllShipmentAlertsRecords",
            "handleGetShipmentAlertsRecords",
            "handleCreateShipmentAlertsRecords",
            "handleUpdateShipmentAlertsRecords",
            "handleDeleteShipmentAlertsRecords"
          ]
        },
        {
          "path": "src/handlers/settingsHandlers.js",
          "content": "const { createSettingsServices } = require('../services/settingsServices');\nconst { sendSuccess, sendCreated, sendNoContent, sendError } = require('../utils/responses');\n\nconst settingsService = createSettingsServices();\n\nasync function handleGetAllSettingsRecords(req, res, next) {\n  try {\n    const records = await settingsService.getAllRecords();\n    sendSuccess(res, records, 'Settings retrieved successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleGetSettingsRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    const record = await settingsService.getRecords(id);\n    sendSuccess(res, record, 'Setting retrieved successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleCreateSettingsRecords(req, res, next) {\n  try {\n    const data = req.body;\n    const created = await settingsService.createRecords(data);\n    sendCreated(res, created, 'Setting created successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleUpdateSettingsRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    const data = req.body;\n    const updated = await settingsService.updateRecords(id, data);\n    sendSuccess(res, updated, 'Setting updated successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleDeleteSettingsRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    await settingsService.removeRecords(id);\n    sendNoContent(res);\n  } catch (error) {\n    next(error);\n  }\n}\n\nmodule.exports = {\n  handleGetAllSettingsRecords,\n  handleGetSettingsRecords,\n  handleCreateSettingsRecords,\n  handleUpdateSettingsRecords,\n  handleDeleteSettingsRecords\n};",
          "description": "Handlers for settings CRUD operations",
          "exports": [
            "handleGetAllSettingsRecords",
            "handleGetSettingsRecords",
            "handleCreateSettingsRecords",
            "handleUpdateSettingsRecords",
            "handleDeleteSettingsRecords"
          ]
        },
        {
          "path": "src/handlers/auditLogsHandlers.js",
          "content": "const { createAuditLogsServices } = require('../services/auditLogsServices');\nconst { sendSuccess, sendCreated, sendNoContent, sendError } = require('../utils/responses');\n\nconst auditLogsService = createAuditLogsServices();\n\nasync function handleGetAllAuditLogsRecords(req, res, next) {\n  try {\n    const records = await auditLogsService.getAllRecords();\n    sendSuccess(res, records, 'Audit logs retrieved successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleGetAuditLogsRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    const record = await auditLogsService.getRecords(id);\n    sendSuccess(res, record, 'Audit log retrieved successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleCreateAuditLogsRecords(req, res, next) {\n  try {\n    const data = req.body;\n    const created = await auditLogsService.createRecords(data);\n    sendCreated(res, created, 'Audit log created successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleUpdateAuditLogsRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    const data = req.body;\n    const updated = await auditLogsService.updateRecords(id, data);\n    sendSuccess(res, updated, 'Audit log updated successfully');\n  } catch (error) {\n    next(error);\n  }\n}\n\nasync function handleDeleteAuditLogsRecords(req, res, next) {\n  try {\n    const { id } = req.params;\n    await auditLogsService.removeRecords(id);\n    sendNoContent(res);\n  } catch (error) {\n    next(error);\n  }\n}\n\nmodule.exports = {\n  handleGetAllAuditLogsRecords,\n  handleGetAuditLogsRecords,\n  handleCreateAuditLogsRecords,\n  handleUpdateAuditLogsRecords,\n  handleDeleteAuditLogsRecords\n};",
          "description": "Handlers for audit logs CRUD operations",
          "exports": [
            "handleGetAllAuditLogsRecords",
            "handleGetAuditLogsRecords",
            "handleCreateAuditLogsRecords",
            "handleUpdateAuditLogsRecords",
            "handleDeleteAuditLogsRecords"
          ]
        },
        {
          "path": "src/handlers/index.js",
          "content": "const { handleGetAllOrganizationsRecords, handleGetOrganizationsRecords, handleCreateOrganizationsRecords, handleUpdateOrganizationsRecords, handleDeleteOrganizationsRecords } = require('./organizationsHandlers');\nconst { handleGetAllOrganizationUsersRecords, handleGetOrganizationUsersRecords, handleCreateOrganizationUsersRecords, handleUpdateOrganizationUsersRecords, handleDeleteOrganizationUsersRecords } = require('./organizationUsersHandlers');\nconst { handleGetAllUsersRecords, handleGetUsersRecords, handleCreateUsersRecords, handleUpdateUsersRecords, handleDeleteUsersRecords } = require('./usersHandlers');\nconst { handleGetAllShipmentsRecords, handleGetShipmentsRecords, handleCreateShipmentsRecords, handleUpdateShipmentsRecords, handleDeleteShipmentsRecords } = require('./shipmentsHandlers');\nconst { handleGetAllCarriersRecords, handleGetCarriersRecords, handleCreateCarriersRecords, handleUpdateCarriersRecords, handleDeleteCarriersRecords } = require('./carriersHandlers');\nconst { handleGetAllShipmentStatusRecords, handleGetShipmentStatusRecords, handleCreateShipmentStatusRecords, handleUpdateShipmentStatusRecords, handleDeleteShipmentStatusRecords } = require('./shipmentStatusHandlers');\nconst { handleGetAllShipmentLocationsRecords, handleGetShipmentLocationsRecords, handleCreateShipmentLocationsRecords, handleUpdateShipmentLocationsRecords, handleDeleteShipmentLocationsRecords } = require('./shipmentLocationsHandlers');\nconst { handleGetAllShipmentAlertsRecords, handleGetShipmentAlertsRecords, handleCreateShipmentAlertsRecords, handleUpdateShipmentAlertsRecords, handleDeleteShipmentAlertsRecords } = require('./shipmentAlertsHandlers');\nconst { handleGetAllSettingsRecords, handleGetSettingsRecords, handleCreateSettingsRecords, handleUpdateSettingsRecords, handleDeleteSettingsRecords } = require('./settingsHandlers');\nconst { handleGetAllAuditLogsRecords, handleGetAuditLogsRecords, handleCreateAuditLogsRecords, handleUpdateAuditLogsRecords, handleDeleteAuditLogsRecords } = require('./auditLogsHandlers');\n\nmodule.exports = {\n  handleGetAllOrganizationsRecords,\n  handleGetOrganizationsRecords,\n  handleCreateOrganizationsRecords,\n  handleUpdateOrganizationsRecords,\n  handleDeleteOrganizationsRecords,\n  handleGetAllOrganizationUsersRecords,\n  handleGetOrganizationUsersRecords,\n  handleCreateOrganizationUsersRecords,\n  handleUpdateOrganizationUsersRecords,\n  handleDeleteOrganizationUsersRecords,\n  handleGetAllUsersRecords,\n  handleGetUsersRecords,\n  handleCreateUsersRecords,\n  handleUpdateUsersRecords,\n  handleDeleteUsersRecords,\n  handleGetAllShipmentsRecords,\n  handleGetShipmentsRecords,\n  handleCreateShipmentsRecords,\n  handleUpdateShipmentsRecords,\n  handleDeleteShipmentsRecords,\n  handleGetAllCarriersRecords,\n  handleGetCarriersRecords,\n  handleCreateCarriersRecords,\n  handleUpdateCarriersRecords,\n  handleDeleteCarriersRecords,\n  handleGetAllShipmentStatusRecords,\n  handleGetShipmentStatusRecords,\n  handleCreateShipmentStatusRecords,\n  handleUpdateShipmentStatusRecords,\n  handleDeleteShipmentStatusRecords,\n  handleGetAllShipmentLocationsRecords,\n  handleGetShipmentLocationsRecords,\n  handleCreateShipmentLocationsRecords,\n  handleUpdateShipmentLocationsRecords,\n  handleDeleteShipmentLocationsRecords,\n  handleGetAllShipmentAlertsRecords,\n  handleGetShipmentAlertsRecords,\n  handleCreateShipmentAlertsRecords,\n  handleUpdateShipmentAlertsRecords,\n  handleDeleteShipmentAlertsRecords,\n  handleGetAllSettingsRecords,\n  handleGetSettingsRecords,\n  handleCreateSettingsRecords,\n  handleUpdateSettingsRecords,\n  handleDeleteSettingsRecords,\n  handleGetAllAuditLogsRecords,\n  handleGetAuditLogsRecords,\n  handleCreateAuditLogsRecords,\n  handleUpdateAuditLogsRecords,\n  handleDeleteAuditLogsRecords\n};",
          "description": "Re-export all handler functions",
          "exports": [
            "handleGetAllOrganizationsRecords",
            "handleGetOrganizationsRecords",
            "handleCreateOrganizationsRecords",
            "handleUpdateOrganizationsRecords",
            "handleDeleteOrganizationsRecords",
            "handleGetAllOrganizationUsersRecords",
            "handleGetOrganizationUsersRecords",
            "handleCreateOrganizationUsersRecords",
            "handleUpdateOrganizationUsersRecords",
            "handleDeleteOrganizationUsersRecords",
            "handleGetAllUsersRecords",
            "handleGetUsersRecords",
            "handleCreateUsersRecords",
            "handleUpdateUsersRecords",
            "handleDeleteUsersRecords",
            "handleGetAllShipmentsRecords",
            "handleGetShipmentsRecords",
            "handleCreateShipmentsRecords",
            "handleUpdateShipmentsRecords",
            "handleDeleteShipmentsRecords",
            "handleGetAllCarriersRecords",
            "handleGetCarriersRecords",
            "handleCreateCarriersRecords",
            "handleUpdateCarriersRecords",
            "handleDeleteCarriersRecords",
            "handleGetAllShipmentStatusRecords",
            "handleGetShipmentStatusRecords",
            "handleCreateShipmentStatusRecords",
            "handleUpdateShipmentStatusRecords",
            "handleDeleteShipmentStatusRecords",
            "handleGetAllShipmentLocationsRecords",
            "handleGetShipmentLocationsRecords",
            "handleCreateShipmentLocationsRecords",
            "handleUpdateShipmentLocationsRecords",
            "handleDeleteShipmentLocationsRecords",
            "handleGetAllShipmentAlertsRecords",
            "handleGetShipmentAlertsRecords",
            "handleCreateShipmentAlertsRecords",
            "handleUpdateShipmentAlertsRecords",
            "handleDeleteShipmentAlertsRecords",
            "handleGetAllSettingsRecords",
            "handleGetSettingsRecords",
            "handleCreateSettingsRecords",
            "handleUpdateSettingsRecords",
            "handleDeleteSettingsRecords",
            "handleGetAllAuditLogsRecords",
            "handleGetAuditLogsRecords",
            "handleCreateAuditLogsRecords",
            "handleUpdateAuditLogsRecords",
            "handleDeleteAuditLogsRecords"
          ]
        },
        {
          "path": "src/handlers/userHandlers.js",
          "content": "const { createUserServices } = require('../services/userServices');\nconst { sendSuccess, sendCreated, sendNoContent, sendError } = require('../utils/responses');\n\nconst userService = createUserServices();\n\n// Handles POST /login and POST /register\nconst handleCreateUserRecords = async (req, res, next) => {\n  try {\n    const data = req.body;\n    const result = await userService.createRecords(data);\n    sendCreated(res, result, 'User record created successfully');\n  } catch (error) {\n    next(error);\n  }\n};\n\n// Handles GET / (list) and GET /:user_id (single)\nconst handleGetAllUserRecords = async (req, res, next) => {\n  try {\n    const { user_id } = req.params;\n    if (user_id) {\n      const result = await userService.getRecords(user_id);\n      sendSuccess(res, result, 'User record retrieved successfully');\n    } else {\n      const filters = req.query;\n      const result = await userService.getAllRecords(filters);\n      sendSuccess(res, result, 'User records retrieved successfully');\n    }\n  } catch (error) {\n    next(error);\n  }\n};\n\n// Handles PUT /:user_id and DELETE /:user_id\nconst handleHandleUserRecords = async (req, res, next) => {\n  try {\n    const { user_id } = req.params;\n    if (!user_id) {\n      return sendError(res, new Error('User ID is required'), 400);\n    }\n    if (req.method === 'PUT') {\n      const data = req.body;\n      const result = await userService.updateRecords(user_id, data);\n      sendSuccess(res, result, 'User record updated successfully');\n    } else if (req.method === 'DELETE') {\n      await userService.removeRecords(user_id);\n      sendNoContent(res);\n    } else {\n      sendError(res, new Error('Unsupported method'), 405);\n    }\n  } catch (error) {\n    next(error);\n  }\n};\n\nmodule.exports = { handleCreateUserRecords, handleCreateUserRecords, handleGetAllUserRecords, handleGetAllUserRecords, handleHandleUserRecords, handleHandleUserRecords };",
          "description": "User handlers implementing login, register, list, get by id, update and delete using user services.",
          "exports": [
            "handleCreateUserRecords",
            "handleGetAllUserRecords",
            "handleHandleUserRecords"
          ]
        },
        {
          "path": "src/handlers/organizationHandlers.js",
          "content": "const { createOrganizationServices } = require('../services/organizationServices');\nconst { sendSuccess, sendCreated, sendNoContent, sendError } = require('../utils/responses');\n\nconst organizationService = createOrganizationServices();\n\n// POST / (create organization)\nconst handleCreateOrganizationRecords = async (req, res, next) => {\n  try {\n    const data = req.body;\n    const result = await organizationService.createRecords(data);\n    sendCreated(res, result, 'Organization created successfully');\n  } catch (error) {\n    next(error);\n  }\n};\n\n// GET / (list) and GET /:organization_id (single)\nconst handleGetAllOrganizationRecords = async (req, res, next) => {\n  try {\n    const { organization_id } = req.params;\n    if (organization_id) {\n      const result = await organizationService.getRecords(organization_id);\n      sendSuccess(res, result, 'Organization retrieved successfully');\n    } else {\n      const filters = req.query;\n      const result = await organizationService.getAllRecords(filters);\n      sendSuccess(res, result, 'Organizations retrieved successfully');\n    }\n  } catch (error) {\n    next(error);\n  }\n};\n\n// PUT /:organization_id and DELETE /:organization_id\nconst handleHandleOrganizationRecords = async (req, res, next) => {\n  try {\n    const { organization_id } = req.params;\n    if (!organization_id) {\n      return sendError(res, new Error('Organization ID is required'), 400);\n    }\n    if (req.method === 'PUT') {\n      const data = req.body;\n      const result = await organizationService.updateRecords(organization_id, data);\n      sendSuccess(res, result, 'Organization updated successfully');\n    } else if (req.method === 'DELETE') {\n      await organizationService.removeRecords(organization_id);\n      sendNoContent(res);\n    } else {\n      sendError(res, new Error('Unsupported method'), 405);\n    }\n  } catch (error) {\n    next(error);\n  }\n};\n\nmodule.exports = { handleGetAllOrganizationRecords, handleGetAllOrganizationRecords, handleCreateOrganizationRecords, handleHandleOrganizationRecords, handleHandleOrganizationRecords };",
          "description": "Organization handlers for CRUD operations using organization services.",
          "exports": [
            "handleGetAllOrganizationRecords",
            "handleCreateOrganizationRecords",
            "handleHandleOrganizationRecords"
          ]
        },
        {
          "path": "src/handlers/shipmentHandlers.js",
          "content": "const { createShipmentServices } = require('../services/shipmentServices');\nconst { sendSuccess, sendCreated, sendNoContent, sendError } = require('../utils/responses');\n\nconst shipmentService = createShipmentServices();\n\n// POST / (create shipment)\nconst handleCreateShipmentRecords = async (req, res, next) => {\n  try {\n    const data = req.body;\n    const result = await shipmentService.createRecords(data);\n    sendCreated(res, result, 'Shipment created successfully');\n  } catch (error) {\n    next(error);\n  }\n};\n\n// GET / (list) and GET /:shipment_id (single)\nconst handleGetAllShipmentRecords = async (req, res, next) => {\n  try {\n    const { shipment_id } = req.params;\n    if (shipment_id) {\n      const result = await shipmentService.getRecords(shipment_id);\n      sendSuccess(res, result, 'Shipment retrieved successfully');\n    } else {\n      const filters = req.query;\n      const result = await shipmentService.getAllRecords(filters);\n      sendSuccess(res, result, 'Shipments retrieved successfully');\n    }\n  } catch (error) {\n    next(error);\n  }\n};\n\n// PUT /:shipment_id and DELETE /:shipment_id\nconst handleHandleShipmentRecords = async (req, res, next) => {\n  try {\n    const { shipment_id } = req.params;\n    if (!shipment_id) {\n      return sendError(res, new Error('Shipment ID is required'), 400);\n    }\n    if (req.method === 'PUT') {\n      const data = req.body;\n      const result = await shipmentService.updateRecords(shipment_id, data);\n      sendSuccess(res, result, 'Shipment updated successfully');\n    } else if (req.method === 'DELETE') {\n      await shipmentService.removeRecords(shipment_id);\n      sendNoContent(res);\n    } else {\n      sendError(res, new Error('Unsupported method'), 405);\n    }\n  } catch (error) {\n    next(error);\n  }\n};\n\nmodule.exports = { handleGetAllShipmentRecords, handleGetAllShipmentRecords, handleCreateShipmentRecords, handleHandleShipmentRecords, handleHandleShipmentRecords };",
          "description": "Shipment handlers for CRUD operations using shipment services.",
          "exports": [
            "handleGetAllShipmentRecords",
            "handleCreateShipmentRecords",
            "handleHandleShipmentRecords"
          ]
        },
        {
          "path": "src/handlers/carrierHandlers.js",
          "content": "const { createCarrierServices } = require('../services/carrierServices');\nconst { sendSuccess, sendCreated, sendNoContent, sendError } = require('../utils/responses');\n\nconst carrierService = createCarrierServices();\n\n// POST / (create carrier)\nconst handleCreateCarrierRecords = async (req, res, next) => {\n  try {\n    const data = req.body;\n    const result = await carrierService.createRecords(data);\n    sendCreated(res, result, 'Carrier created successfully');\n  } catch (error) {\n    next(error);\n  }\n};\n\n// GET / (list) and GET /:carrier_id (single)\nconst handleGetAllCarrierRecords = async (req, res, next) => {\n  try {\n    const { carrier_id } = req.params;\n    if (carrier_id) {\n      const result = await carrierService.getRecords(carrier_id);\n      sendSuccess(res, result, 'Carrier retrieved successfully');\n    } else {\n      const filters = req.query;\n      const result = await carrierService.getAllRecords(filters);\n      sendSuccess(res, result, 'Carriers retrieved successfully');\n    }\n  } catch (error) {\n    next(error);\n  }\n};\n\n// PUT /:carrier_id and DELETE /:carrier_id\nconst handleHandleCarrierRecords = async (req, res, next) => {\n  try {\n    const { carrier_id } = req.params;\n    if (!carrier_id) {\n      return sendError(res, new Error('Carrier ID is required'), 400);\n    }\n    if (req.method === 'PUT') {\n      const data = req.body;\n      const result = await carrierService.updateRecords(carrier_id, data);\n      sendSuccess(res, result, 'Carrier updated successfully');\n    } else if (req.method === 'DELETE') {\n      await carrierService.removeRecords(carrier_id);\n      sendNoContent(res);\n    } else {\n      sendError(res, new Error('Unsupported method'), 405);\n    }\n  } catch (error) {\n    next(error);\n  }\n};\n\nmodule.exports = { handleGetAllCarrierRecords, handleGetAllCarrierRecords, handleCreateCarrierRecords, handleHandleCarrierRecords, handleHandleCarrierRecords };",
          "description": "Carrier handlers for CRUD operations using carrier services.",
          "exports": [
            "handleGetAllCarrierRecords",
            "handleCreateCarrierRecords",
            "handleHandleCarrierRecords"
          ]
        },
        {
          "path": "src/handlers/authenticationHandlers.js",
          "content": "const { createAuthenticationServices } = require('../services/authenticationServices');\nconst { sendSuccess, sendError } = require('../utils/responses');\n\nconst authService = createAuthenticationServices();\n\n// GET / (retrieve authentication related records  placeholder implementation)\nconst handleGetAllAuthenticationRecords = async (req, res, next) => {\n  try {\n    const result = await authService.getAllRecords();\n    sendSuccess(res, result, 'Authentication records retrieved successfully');\n  } catch (error) {\n    next(error);\n  }\n};\n\nmodule.exports = { handleGetAllAuthenticationRecords };",
          "description": "Authentication handler exposing a GET endpoint using authentication services.",
          "exports": [
            "handleGetAllAuthenticationRecords"
          ]
        },
        {
          "path": "src/handlers/errorHandlers.js",
          "content": "const { createErrorServices } = require('../services/errorServices');\nconst { sendSuccess, sendError } = require('../utils/responses');\n\nconst errorService = createErrorServices();\n\n// GET / (retrieve error related records  placeholder implementation)\nconst handleGetAllErrorRecords = async (req, res, next) => {\n  try {\n    const result = await errorService.getAllRecords();\n    sendSuccess(res, result, 'Error records retrieved successfully');\n  } catch (err) {\n    next(err);\n  }\n};\n\nmodule.exports = { handleGetAllErrorRecords };",
          "description": "Error handler exposing a GET endpoint using error services.",
          "exports": [
            "handleGetAllErrorRecords"
          ]
        },
        {
          "path": "src/handlers/emailserviceadapterHandlers.js",
          "content": "const { createEmailserviceadapterServices } = require('../services/emailserviceadapterServices');\nconst { sendSuccess, sendError } = require('../utils/responses');\n\nconst emailAdapterService = createEmailserviceadapterServices();\n\n// GET / (retrieve email service adapter records  placeholder implementation)\nconst handleGetAllEmailserviceadapterRecords = async (req, res, next) => {\n  try {\n    const result = await emailAdapterService.getAllRecords();\n    sendSuccess(res, result, 'Email service adapter records retrieved successfully');\n  } catch (err) {\n    next(err);\n  }\n};\n\nmodule.exports = { handleGetAllEmailserviceadapterRecords };",
          "description": "Email service adapter handler exposing a GET endpoint using its service.",
          "exports": [
            "handleGetAllEmailserviceadapterRecords"
          ]
        },
        {
          "path": "src/routes/index.js",
          "content": "const express = require('express');\nconst router = express.Router();\n\nconst { router: organizationsRouter } = require('./organizationsRoutes');\nconst { router: organizationUsersRouter } = require('./organizationUsersRoutes');\nconst { router: usersRouter } = require('./usersRoutes');\nconst { router: shipmentsRouter } = require('./shipmentsRoutes');\nconst { router: carriersRouter } = require('./carriersRoutes');\nconst { router: shipmentStatusRouter } = require('./shipmentStatusRoutes');\nconst { router: shipmentLocationsRouter } = require('./shipmentLocationsRoutes');\nconst { router: shipmentAlertsRouter } = require('./shipmentAlertsRoutes');\nconst { router: settingsRouter } = require('./settingsRoutes');\nconst { router: auditLogsRouter } = require('./auditLogsRoutes');\n\n// Health check\nrouter.get('/health', (req, res) => {\n  res.json({ status: 'ok', timestamp: new Date().toISOString() });\n});\n\n// Mount routes\nrouter.use('/organizations', organizationsRouter);\nrouter.use('/organizationUsers', organizationUsersRouter);\nrouter.use('/users', usersRouter);\nrouter.use('/shipments', shipmentsRouter);\nrouter.use('/carriers', carriersRouter);\nrouter.use('/shipmentStatus', shipmentStatusRouter);\nrouter.use('/shipmentLocations', shipmentLocationsRouter);\nrouter.use('/shipmentAlerts', shipmentAlertsRouter);\nrouter.use('/settings', settingsRouter);\nrouter.use('/auditLogs', auditLogsRouter);\n\nmodule.exports = { router };",
          "description": "Main router that mounts all entity routers and provides a health check endpoint.",
          "exports": [
            "router"
          ]
        },
        {
          "path": "src/routes/organizationsRoutes.js",
          "content": "const express = require('express');\nconst router = express.Router();\n\nconst { handleGetAllOrganizationsRecords, handleGetOrganizationsRecords, handleCreateOrganizationsRecords, handleUpdateOrganizationsRecords, handleDeleteOrganizationsRecords } = require('../handlers/organizationsHandlers');\n\n// Get all organizations\nrouter.get('/', handleGetAllOrganizationsRecords);\n\n// Get organization by ID\nrouter.get('/:id', handleGetOrganizationsRecords);\n\n// Create a new organization\nrouter.post('/', handleCreateOrganizationsRecords);\n\n// Update an organization\nrouter.put('/:id', handleUpdateOrganizationsRecords);\n\n// Delete an organization\nrouter.delete('/:id', handleDeleteOrganizationsRecords);\n\nmodule.exports = { router };",
          "description": "Express router for organization CRUD endpoints.",
          "exports": [
            "router"
          ]
        },
        {
          "path": "src/routes/organizationUsersRoutes.js",
          "content": "const express = require('express');\nconst router = express.Router();\n\nconst { handleGetAllOrganizationUsersRecords, handleGetOrganizationUsersRecords, handleCreateOrganizationUsersRecords, handleUpdateOrganizationUsersRecords, handleDeleteOrganizationUsersRecords } = require('../handlers/organizationUsersHandlers');\n\nrouter.get('/', handleGetAllOrganizationUsersRecords);\nrouter.get('/:id', handleGetOrganizationUsersRecords);\nrouter.post('/', handleCreateOrganizationUsersRecords);\nrouter.put('/:id', handleUpdateOrganizationUsersRecords);\nrouter.delete('/:id', handleDeleteOrganizationUsersRecords);\n\nmodule.exports = { router };",
          "description": "Express router for organization user CRUD endpoints.",
          "exports": [
            "router"
          ]
        },
        {
          "path": "src/routes/usersRoutes.js",
          "content": "const express = require('express');\nconst router = express.Router();\n\nconst { handleGetAllUsersRecords, handleGetUsersRecords, handleCreateUsersRecords, handleUpdateUsersRecords, handleDeleteUsersRecords } = require('../handlers/usersHandlers');\n\nrouter.get('/', handleGetAllUsersRecords);\nrouter.get('/:id', handleGetUsersRecords);\nrouter.post('/', handleCreateUsersRecords);\nrouter.put('/:id', handleUpdateUsersRecords);\nrouter.delete('/:id', handleDeleteUsersRecords);\n\nmodule.exports = { router };",
          "description": "Express router for user CRUD endpoints.",
          "exports": [
            "router"
          ]
        },
        {
          "path": "src/routes/shipmentsRoutes.js",
          "content": "const express = require('express');\nconst router = express.Router();\n\nconst { handleGetAllShipmentsRecords, handleGetShipmentsRecords, handleCreateShipmentsRecords, handleUpdateShipmentsRecords, handleDeleteShipmentsRecords } = require('../handlers/shipmentsHandlers');\n\nrouter.get('/', handleGetAllShipmentsRecords);\nrouter.get('/:id', handleGetShipmentsRecords);\nrouter.post('/', handleCreateShipmentsRecords);\nrouter.put('/:id', handleUpdateShipmentsRecords);\nrouter.delete('/:id', handleDeleteShipmentsRecords);\n\nmodule.exports = { router };",
          "description": "Express router for shipment CRUD endpoints.",
          "exports": [
            "router"
          ]
        },
        {
          "path": "src/routes/carriersRoutes.js",
          "content": "const express = require('express');\nconst router = express.Router();\n\nconst { handleGetAllCarriersRecords, handleGetCarriersRecords, handleCreateCarriersRecords, handleUpdateCarriersRecords, handleDeleteCarriersRecords } = require('../handlers/carriersHandlers');\n\nrouter.get('/', handleGetAllCarriersRecords);\nrouter.get('/:id', handleGetCarriersRecords);\nrouter.post('/', handleCreateCarriersRecords);\nrouter.put('/:id', handleUpdateCarriersRecords);\nrouter.delete('/:id', handleDeleteCarriersRecords);\n\nmodule.exports = { router };",
          "description": "Express router for carrier CRUD endpoints.",
          "exports": [
            "router"
          ]
        },
        {
          "path": "src/routes/shipmentStatusRoutes.js",
          "content": "const express = require('express');\nconst router = express.Router();\n\nconst { handleGetAllShipmentStatusRecords, handleGetShipmentStatusRecords, handleCreateShipmentStatusRecords, handleUpdateShipmentStatusRecords, handleDeleteShipmentStatusRecords } = require('../handlers/shipmentStatusHandlers');\n\nrouter.get('/', handleGetAllShipmentStatusRecords);\nrouter.get('/:id', handleGetShipmentStatusRecords);\nrouter.post('/', handleCreateShipmentStatusRecords);\nrouter.put('/:id', handleUpdateShipmentStatusRecords);\nrouter.delete('/:id', handleDeleteShipmentStatusRecords);\n\nmodule.exports = { router };",
          "description": "Express router for shipment status CRUD endpoints.",
          "exports": [
            "router"
          ]
        },
        {
          "path": "src/routes/shipmentLocationsRoutes.js",
          "content": "const express = require('express');\nconst router = express.Router();\n\nconst { handleGetAllShipmentLocationsRecords, handleGetShipmentLocationsRecords, handleCreateShipmentLocationsRecords, handleUpdateShipmentLocationsRecords, handleDeleteShipmentLocationsRecords } = require('../handlers/shipmentLocationsHandlers');\n\nrouter.get('/', handleGetAllShipmentLocationsRecords);\nrouter.get('/:id', handleGetShipmentLocationsRecords);\nrouter.post('/', handleCreateShipmentLocationsRecords);\nrouter.put('/:id', handleUpdateShipmentLocationsRecords);\nrouter.delete('/:id', handleDeleteShipmentLocationsRecords);\n\nmodule.exports = { router };",
          "description": "Express router for shipment locations CRUD endpoints.",
          "exports": [
            "router"
          ]
        },
        {
          "path": "src/routes/shipmentAlertsRoutes.js",
          "content": "const express = require('express');\nconst router = express.Router();\n\nconst { handleGetAllShipmentAlertsRecords, handleGetShipmentAlertsRecords, handleCreateShipmentAlertsRecords, handleUpdateShipmentAlertsRecords, handleDeleteShipmentAlertsRecords } = require('../handlers/shipmentAlertsHandlers');\n\nrouter.get('/', handleGetAllShipmentAlertsRecords);\nrouter.get('/:id', handleGetShipmentAlertsRecords);\nrouter.post('/', handleCreateShipmentAlertsRecords);\nrouter.put('/:id', handleUpdateShipmentAlertsRecords);\nrouter.delete('/:id', handleDeleteShipmentAlertsRecords);\n\nmodule.exports = { router };",
          "description": "Express router for shipment alerts CRUD endpoints.",
          "exports": [
            "router"
          ]
        },
        {
          "path": "src/routes/settingsRoutes.js",
          "content": "const express = require('express');\nconst router = express.Router();\n\nconst { handleGetAllSettingsRecords, handleGetSettingsRecords, handleCreateSettingsRecords, handleUpdateSettingsRecords, handleDeleteSettingsRecords } = require('../handlers/settingsHandlers');\n\nrouter.get('/', handleGetAllSettingsRecords);\nrouter.get('/:id', handleGetSettingsRecords);\nrouter.post('/', handleCreateSettingsRecords);\nrouter.put('/:id', handleUpdateSettingsRecords);\nrouter.delete('/:id', handleDeleteSettingsRecords);\n\nmodule.exports = { router };",
          "description": "Express router for settings CRUD endpoints.",
          "exports": [
            "router"
          ]
        },
        {
          "path": "src/routes/auditLogsRoutes.js",
          "content": "const express = require('express');\nconst router = express.Router();\n\nconst { handleGetAllAuditLogsRecords, handleGetAuditLogsRecords, handleCreateAuditLogsRecords, handleUpdateAuditLogsRecords, handleDeleteAuditLogsRecords } = require('../handlers/auditLogsHandlers');\n\nrouter.get('/', handleGetAllAuditLogsRecords);\nrouter.get('/:id', handleGetAuditLogsRecords);\nrouter.post('/', handleCreateAuditLogsRecords);\nrouter.put('/:id', handleUpdateAuditLogsRecords);\nrouter.delete('/:id', handleDeleteAuditLogsRecords);\n\nmodule.exports = { router };",
          "description": "Express router for audit logs CRUD endpoints.",
          "exports": [
            "router"
          ]
        },
        {
          "path": "src/routes/userRoutes.js",
          "content": "const express = require('express');\nconst router = express.Router();\n\nconst { handleCreateUserRecords, handleGetAllUserRecords, handleHandleUserRecords } = require('../handlers/userHandlers');\n\nrouter.post('/login', handleCreateUserRecords);\nrouter.post('/register', handleCreateUserRecords);\nrouter.get('/', handleGetAllUserRecords);\nrouter.get('/{user_id}', handleGetAllUserRecords);\nrouter.put('/{user_id}', handleHandleUserRecords);\nrouter.delete('/{user_id}', handleHandleUserRecords);\n\nmodule.exports = { router };",
          "description": "Defines user authentication and CRUD routes, importing handlers from userHandlers.",
          "exports": [
            "router"
          ]
        },
        {
          "path": "src/routes/organizationRoutes.js",
          "content": "const express = require('express');\nconst router = express.Router();\n\nconst { handleGetAllOrganizationRecords, handleCreateOrganizationRecords, handleHandleOrganizationRecords } = require('../handlers/organizationHandlers');\n\nrouter.get('/', handleGetAllOrganizationRecords);\nrouter.get('/{organization_id}', handleGetAllOrganizationRecords);\nrouter.post('/', handleCreateOrganizationRecords);\nrouter.put('/{organization_id}', handleHandleOrganizationRecords);\nrouter.delete('/{organization_id}', handleHandleOrganizationRecords);\n\nmodule.exports = { router };",
          "description": "Defines organization CRUD routes, importing handlers from organizationHandlers.",
          "exports": [
            "router"
          ]
        },
        {
          "path": "src/routes/shipmentRoutes.js",
          "content": "const express = require('express');\nconst router = express.Router();\n\nconst { handleGetAllShipmentRecords, handleCreateShipmentRecords, handleHandleShipmentRecords } = require('../handlers/shipmentHandlers');\n\nrouter.get('/', handleGetAllShipmentRecords);\nrouter.get('/{shipment_id}', handleGetAllShipmentRecords);\nrouter.post('/', handleCreateShipmentRecords);\nrouter.put('/{shipment_id}', handleHandleShipmentRecords);\nrouter.delete('/{shipment_id}', handleHandleShipmentRecords);\n\nmodule.exports = { router };",
          "description": "Defines shipment CRUD routes, importing handlers from shipmentHandlers.",
          "exports": [
            "router"
          ]
        },
        {
          "path": "src/routes/carrierRoutes.js",
          "content": "const express = require('express');\nconst router = express.Router();\n\nconst { handleGetAllCarrierRecords, handleCreateCarrierRecords, handleHandleCarrierRecords } = require('../handlers/carrierHandlers');\n\nrouter.get('/', handleGetAllCarrierRecords);\nrouter.get('/{carrier_id}', handleGetAllCarrierRecords);\nrouter.post('/', handleCreateCarrierRecords);\nrouter.put('/{carrier_id}', handleHandleCarrierRecords);\nrouter.delete('/{carrier_id}', handleHandleCarrierRecords);\n\nmodule.exports = { router };",
          "description": "Defines carrier CRUD routes, importing handlers from carrierHandlers.",
          "exports": [
            "router"
          ]
        },
        {
          "path": "src/routes/authenticationRoutes.js",
          "content": "const express = require('express');\nconst router = express.Router();\n\nconst { handleGetAllAuthenticationRecords } = require('../handlers/authenticationHandlers');\n\nrouter.get('/', handleGetAllAuthenticationRecords);\n\nmodule.exports = { router };",
          "description": "Defines authentication route, importing handler from authenticationHandlers.",
          "exports": [
            "router"
          ]
        },
        {
          "path": "src/routes/errorRoutes.js",
          "content": "const express = require('express');\nconst router = express.Router();\n\nconst { handleGetAllErrorRecords } = require('../handlers/errorHandlers');\n\nrouter.get('/', handleGetAllErrorRecords);\n\nmodule.exports = { router };",
          "description": "Defines error handling route, importing handler from errorHandlers.",
          "exports": [
            "router"
          ]
        },
        {
          "path": "src/routes/emailserviceadapterRoutes.js",
          "content": "const express = require('express');\nconst router = express.Router();\n\nconst { handleGetAllEmailserviceadapterRecords } = require('../handlers/emailserviceadapterHandlers');\n\nrouter.get('/', handleGetAllEmailserviceadapterRecords);\n\nmodule.exports = { router };",
          "description": "Defines email service adapter route, importing handler from emailserviceadapterHandlers.",
          "exports": [
            "router"
          ]
        },
        {
          "path": "terraform/main.tf",
          "content": "# =============================================================================\n# Build Multitenant B2b - AWS ECS Terraform Configuration\n# =============================================================================\n\nterraform {\n  required_version = \">= 1.0\"\n  \n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n\n  # Uncomment to use S3 backend for state management\n  # backend \"s3\" {\n  #   bucket         = \"build-multitenant-b2b-terraform-state\"\n  #   key            = \"infrastructure/terraform.tfstate\"\n  #   region         = \"us-east-1\"\n  #   encrypt        = true\n  #   dynamodb_table = \"build-multitenant-b2b-terraform-locks\"\n  # }\n}\n\nprovider \"aws\" {\n  region = var.aws_region\n\n  default_tags {\n    tags = {\n      Project     = \"Build Multitenant B2b\"\n      Environment = var.environment\n      ManagedBy   = \"Terraform\"\n      Application = \"build-multitenant-b2b\"\n    }\n  }\n}\n\n# =============================================================================\n# Data Sources\n# =============================================================================\n\ndata \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\ndata \"aws_caller_identity\" \"current\" {}\n\n# =============================================================================\n# VPC Module\n# =============================================================================\n\nmodule \"vpc\" {\n  source = \"./modules/vpc\"\n\n  project_name        = var.project_name\n  environment         = var.environment\n  vpc_cidr            = var.vpc_cidr\n  availability_zones  = data.aws_availability_zones.available.names\n  public_subnet_cidrs = var.public_subnet_cidrs\n  private_subnet_cidrs = var.private_subnet_cidrs\n}\n\n# =============================================================================\n# Security Groups\n# =============================================================================\n\nmodule \"security_groups\" {\n  source = \"./modules/security\"\n\n  project_name = var.project_name\n  environment  = var.environment\n  vpc_id       = module.vpc.vpc_id\n}\n\n# =============================================================================\n# RDS PostgreSQL Database\n# =============================================================================\n\nmodule \"rds\" {\n  source = \"./modules/rds\"\n\n  project_name           = var.project_name\n  environment            = var.environment\n  vpc_id                 = module.vpc.vpc_id\n  private_subnet_ids     = module.vpc.private_subnet_ids\n  db_security_group_id   = module.security_groups.db_security_group_id\n  db_name                = var.db_name\n  db_username            = var.db_username\n  db_password            = var.db_password\n  db_instance_class      = var.db_instance_class\n  db_allocated_storage   = var.db_allocated_storage\n}\n\n# =============================================================================\n# ECR Repository\n# =============================================================================\n\nmodule \"ecr\" {\n  source = \"./modules/ecr\"\n\n  project_name = var.project_name\n  environment  = var.environment\n}\n\n# =============================================================================\n# ECS Cluster\n# =============================================================================\n\nmodule \"ecs\" {\n  source = \"./modules/ecs\"\n\n  project_name             = var.project_name\n  environment              = var.environment\n  vpc_id                   = module.vpc.vpc_id\n  public_subnet_ids        = module.vpc.public_subnet_ids\n  private_subnet_ids       = module.vpc.private_subnet_ids\n  ecs_security_group_id    = module.security_groups.ecs_security_group_id\n  alb_security_group_id    = module.security_groups.alb_security_group_id\n  ecr_repository_url       = module.ecr.repository_url\n  \n  # Database configuration\n  db_host                  = module.rds.db_endpoint\n  db_port                  = module.rds.db_port\n  db_name                  = var.db_name\n  db_username              = var.db_username\n  db_password              = var.db_password\n  \n  # Application configuration\n  app_port                 = var.app_port\n  app_cpu                  = var.app_cpu\n  app_memory               = var.app_memory\n  desired_count            = var.desired_count\n  \n  \n  # Health check\n  health_check_path        = var.health_check_path\n}\n\n# =============================================================================\n# CloudWatch Log Groups\n# =============================================================================\n\nresource \"aws_cloudwatch_log_group\" \"app\" {\n  name              = \"/ecs/${var.project_name}-${var.environment}\"\n  retention_in_days = 7\n\n  tags = {\n    Name = \"${var.project_name}-${var.environment}-logs\"\n  }\n}",
          "description": "Main Terraform configuration file"
        },
        {
          "path": "terraform/variables.tf",
          "content": "# =============================================================================\n# Build Multitenant B2b - Terraform Variables\n# =============================================================================\n\nvariable \"aws_region\" {\n  description = \"AWS region for resources\"\n  type        = string\n  default     = \"us-east-1\"\n}\n\nvariable \"project_name\" {\n  description = \"Project name\"\n  type        = string\n  default     = \"build-multitenant-b2b\"\n}\n\nvariable \"environment\" {\n  description = \"Environment (dev, staging, prod)\"\n  type        = string\n  default     = \"dev\"\n}\n\n# =============================================================================\n# VPC Configuration\n# =============================================================================\n\nvariable \"vpc_cidr\" {\n  description = \"CIDR block for VPC\"\n  type        = string\n  default     = \"10.0.0.0/16\"\n}\n\nvariable \"public_subnet_cidrs\" {\n  description = \"CIDR blocks for public subnets\"\n  type        = list(string)\n  default     = [\"10.0.1.0/24\", \"10.0.2.0/24\"]\n}\n\nvariable \"private_subnet_cidrs\" {\n  description = \"CIDR blocks for private subnets\"\n  type        = list(string)\n  default     = [\"10.0.11.0/24\", \"10.0.12.0/24\"]\n}\n\n# =============================================================================\n# Database Configuration\n# =============================================================================\n\nvariable \"db_name\" {\n  description = \"Database name\"\n  type        = string\n  default     = \"build_multitenant_b2b\"\n}\n\nvariable \"db_username\" {\n  description = \"Database master username\"\n  type        = string\n  default     = \"postgres\"\n  sensitive   = true\n}\n\nvariable \"db_password\" {\n  description = \"Database master password\"\n  type        = string\n  sensitive   = true\n}\n\nvariable \"db_instance_class\" {\n  description = \"RDS instance class\"\n  type        = string\n  default     = \"db.t3.micro\"\n}\n\nvariable \"db_allocated_storage\" {\n  description = \"Allocated storage in GB\"\n  type        = number\n  default     = 20\n}\n\n# =============================================================================\n# Application Configuration\n# =============================================================================\n\nvariable \"app_port\" {\n  description = \"Application port\"\n  type        = number\n  default     = 3000\n}\n\nvariable \"app_cpu\" {\n  description = \"Fargate CPU units\"\n  type        = number\n  default     = 256\n}\n\nvariable \"app_memory\" {\n  description = \"Fargate memory in MB\"\n  type        = number\n  default     = 512\n}\n\nvariable \"desired_count\" {\n  description = \"Desired number of tasks\"\n  type        = number\n  default     = 2\n}\n\nvariable \"health_check_path\" {\n  description = \"Health check endpoint path\"\n  type        = string\n  default     = \"/health\"\n}\n\n",
          "description": "Terraform variables definition"
        },
        {
          "path": "terraform/outputs.tf",
          "content": "# =============================================================================\n# Build Multitenant B2b - Terraform Outputs\n# =============================================================================\n\noutput \"vpc_id\" {\n  description = \"VPC ID\"\n  value       = module.vpc.vpc_id\n}\n\noutput \"ecr_repository_url\" {\n  description = \"ECR repository URL\"\n  value       = module.ecr.repository_url\n}\n\noutput \"alb_dns_name\" {\n  description = \"Application Load Balancer DNS name\"\n  value       = module.ecs.alb_dns_name\n}\n\noutput \"alb_url\" {\n  description = \"Application Load Balancer URL\"\n  value       = \"http://${module.ecs.alb_dns_name}\"\n}\n\noutput \"db_endpoint\" {\n  description = \"RDS database endpoint\"\n  value       = module.rds.db_endpoint\n  sensitive   = true\n}\n\noutput \"db_port\" {\n  description = \"RDS database port\"\n  value       = module.rds.db_port\n}\n\noutput \"ecs_cluster_name\" {\n  description = \"ECS cluster name\"\n  value       = module.ecs.cluster_name\n}\n\noutput \"ecs_service_name\" {\n  description = \"ECS service name\"\n  value       = module.ecs.service_name\n}\n\noutput \"cloudwatch_log_group\" {\n  description = \"CloudWatch log group name\"\n  value       = aws_cloudwatch_log_group.app.name\n}",
          "description": "Terraform outputs"
        },
        {
          "path": "terraform/modules/vpc/main.tf",
          "content": "# =============================================================================\n# VPC Module\n# =============================================================================\n\nresource \"aws_vpc\" \"vpc_main\" {\n  cidr_block           = var.vpc_cidr\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  tags = {\n    Name = \"${var.project_name}-${var.environment}-vpc\"\n  }\n}\n\n# =============================================================================\n# Internet Gateway\n# =============================================================================\n\nresource \"aws_internet_gateway\" \"igw_main\" {\n  vpc_id = aws_vpc.vpc_main.id\n\n  tags = {\n    Name = \"${var.project_name}-${var.environment}-igw\"\n  }\n}\n\n# =============================================================================\n# Public Subnets\n# =============================================================================\n\nresource \"aws_subnet\" \"subnet_public\" {\n  count                   = length(var.public_subnet_cidrs)\n  vpc_id                  = aws_vpc.vpc_main.id\n  cidr_block              = var.public_subnet_cidrs[count.index]\n  availability_zone       = var.availability_zones[count.index]\n  map_public_ip_on_launch = true\n\n  tags = {\n    Name = \"${var.project_name}-${var.environment}-public-${count.index + 1}\"\n    Type = \"Public\"\n  }\n}\n\n# =============================================================================\n# Private Subnets\n# =============================================================================\n\nresource \"aws_subnet\" \"subnet_private\" {\n  count             = length(var.private_subnet_cidrs)\n  vpc_id            = aws_vpc.vpc_main.id\n  cidr_block        = var.private_subnet_cidrs[count.index]\n  availability_zone = var.availability_zones[count.index]\n\n  tags = {\n    Name = \"${var.project_name}-${var.environment}-private-${count.index + 1}\"\n    Type = \"Private\"\n  }\n}\n\n# =============================================================================\n# NAT Gateway\n# =============================================================================\n\nresource \"aws_eip\" \"nat_eip\" {\n  count  = length(var.public_subnet_cidrs)\n  domain = \"vpc\"\n\n  tags = {\n    Name = \"${var.project_name}-${var.environment}-nat-eip-${count.index + 1}\"\n  }\n\n  depends_on = [aws_internet_gateway.igw_main]\n}\n\nresource \"aws_nat_gateway\" \"nat_gw\" {\n  count         = length(var.public_subnet_cidrs)\n  allocation_id = aws_eip.nat_eip[count.index].id\n  subnet_id     = aws_subnet.subnet_public[count.index].id\n\n  tags = {\n    Name = \"${var.project_name}-${var.environment}-nat-${count.index + 1}\"\n  }\n\n  depends_on = [aws_internet_gateway.igw_main]\n}\n\n# =============================================================================\n# Route Tables\n# =============================================================================\n\nresource \"aws_route_table\" \"rt_public\" {\n  vpc_id = aws_vpc.vpc_main.id\n\n  route {\n    cidr_block = \"0.0.0.0/0\"\n    gateway_id = aws_internet_gateway.igw_main.id\n  }\n\n  tags = {\n    Name = \"${var.project_name}-${var.environment}-public-rt\"\n  }\n}\n\nresource \"aws_route_table\" \"rt_private\" {\n  count  = length(var.private_subnet_cidrs)\n  vpc_id = aws_vpc.vpc_main.id\n\n  route {\n    cidr_block     = \"0.0.0.0/0\"\n    nat_gateway_id = aws_nat_gateway.nat_gw[count.index].id\n  }\n\n  tags = {\n    Name = \"${var.project_name}-${var.environment}-private-rt-${count.index + 1}\"\n  }\n}\n\n# =============================================================================\n# Route Table Associations\n# =============================================================================\n\nresource \"aws_route_table_association\" \"rta_public\" {\n  count          = length(var.public_subnet_cidrs)\n  subnet_id      = aws_subnet.subnet_public[count.index].id\n  route_table_id = aws_route_table.rt_public.id\n}\n\nresource \"aws_route_table_association\" \"rta_private\" {\n  count          = length(var.private_subnet_cidrs)\n  subnet_id      = aws_subnet.subnet_private[count.index].id\n  route_table_id = aws_route_table.rt_private[count.index].id\n}\n\n# =============================================================================\n# Module Variables\n# =============================================================================\n\nvariable \"project_name\" {\n  type = string\n}\n\nvariable \"environment\" {\n  type = string\n}\n\nvariable \"vpc_cidr\" {\n  type = string\n}\n\nvariable \"availability_zones\" {\n  type = list(string)\n}\n\nvariable \"public_subnet_cidrs\" {\n  type = list(string)\n}\n\nvariable \"private_subnet_cidrs\" {\n  type = list(string)\n}\n\n# =============================================================================\n# Module Outputs\n# =============================================================================\n\noutput \"vpc_id\" {\n  value = aws_vpc.vpc_main.id\n}\n\noutput \"public_subnet_ids\" {\n  value = aws_subnet.subnet_public[*].id\n}\n\noutput \"private_subnet_ids\" {\n  value = aws_subnet.subnet_private[*].id\n}",
          "description": "VPC module for networking infrastructure"
        },
        {
          "path": "terraform/modules/security/main.tf",
          "content": "# =============================================================================\n# Security Groups Module\n# =============================================================================\n\n# =============================================================================\n# ALB Security Group\n# =============================================================================\n\nresource \"aws_security_group\" \"sg_alb\" {\n  name        = \"${var.project_name}-${var.environment}-alb-sg\"\n  description = \"Security group for Application Load Balancer\"\n  vpc_id      = var.vpc_id\n\n  ingress {\n    description = \"HTTP from anywhere\"\n    from_port   = 80\n    to_port     = 80\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  ingress {\n    description = \"HTTPS from anywhere\"\n    from_port   = 443\n    to_port     = 443\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  egress {\n    description = \"Allow all outbound traffic\"\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name = \"${var.project_name}-${var.environment}-alb-sg\"\n  }\n}\n\n# =============================================================================\n# ECS Tasks Security Group\n# =============================================================================\n\nresource \"aws_security_group\" \"sg_ecs_tasks\" {\n  name        = \"${var.project_name}-${var.environment}-ecs-tasks-sg\"\n  description = \"Security group for ECS tasks\"\n  vpc_id      = var.vpc_id\n\n  ingress {\n    description     = \"Allow traffic from ALB\"\n    from_port       = 3000\n    to_port         = 3000\n    protocol        = \"tcp\"\n    security_groups = [aws_security_group.sg_alb.id]\n  }\n\n  egress {\n    description = \"Allow all outbound traffic\"\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name = \"${var.project_name}-${var.environment}-ecs-tasks-sg\"\n  }\n}\n\n# =============================================================================\n# RDS Security Group\n# =============================================================================\n\nresource \"aws_security_group\" \"sg_rds\" {\n  name        = \"${var.project_name}-${var.environment}-rds-sg\"\n  description = \"Security group for RDS PostgreSQL\"\n  vpc_id      = var.vpc_id\n\n  ingress {\n    description     = \"PostgreSQL from ECS tasks\"\n    from_port       = 5432\n    to_port         = 5432\n    protocol        = \"tcp\"\n    security_groups = [aws_security_group.sg_ecs_tasks.id]\n  }\n\n  egress {\n    description = \"Allow all outbound traffic\"\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name = \"${var.project_name}-${var.environment}-rds-sg\"\n  }\n}\n\n# =============================================================================\n# Module Variables\n# =============================================================================\n\nvariable \"project_name\" {\n  type = string\n}\n\nvariable \"environment\" {\n  type = string\n}\n\nvariable \"vpc_id\" {\n  type = string\n}\n\n# =============================================================================\n# Module Outputs\n# =============================================================================\n\noutput \"alb_security_group_id\" {\n  value = aws_security_group.sg_alb.id\n}\n\noutput \"ecs_security_group_id\" {\n  value = aws_security_group.sg_ecs_tasks.id\n}\n\noutput \"db_security_group_id\" {\n  value = aws_security_group.sg_rds.id\n}",
          "description": "Security groups module"
        },
        {
          "path": "terraform/modules/rds/main.tf",
          "content": "# =============================================================================\n# RDS PostgreSQL Module\n# =============================================================================\n\nresource \"aws_db_subnet_group\" \"rds_subnet_group\" {\n  name       = \"${var.project_name}-${var.environment}-db-subnet-group\"\n  subnet_ids = var.private_subnet_ids\n\n  tags = {\n    Name = \"${var.project_name}-${var.environment}-db-subnet-group\"\n  }\n}\n\nresource \"aws_db_instance\" \"rds_postgres\" {\n  identifier     = \"${var.project_name}-${var.environment}-db\"\n  engine         = \"postgres\"\n  engine_version = \"15\"\n  \n  instance_class    = var.db_instance_class\n  allocated_storage = var.db_allocated_storage\n  storage_type      = \"gp3\"\n  storage_encrypted = true\n  \n  db_name  = var.db_name\n  username = var.db_username\n  password = var.db_password\n  port     = 5432\n  \n  db_subnet_group_name   = aws_db_subnet_group.rds_subnet_group.name\n  vpc_security_group_ids = [var.db_security_group_id]\n  \n  backup_retention_period = 1\n  backup_window          = \"03:00-04:00\"\n  maintenance_window     = \"mon:04:00-mon:05:00\"\n  \n  skip_final_snapshot       = true\n  final_snapshot_identifier = \"${var.project_name}-${var.environment}-final-snapshot\"\n  \n  enabled_cloudwatch_logs_exports = [\"postgresql\", \"upgrade\"]\n  \n  auto_minor_version_upgrade = true\n  deletion_protection        = false\n  \n  tags = {\n    Name = \"${var.project_name}-${var.environment}-db\"\n  }\n}\n\n# =============================================================================\n# Module Variables\n# =============================================================================\n\nvariable \"project_name\" {\n  type = string\n}\n\nvariable \"environment\" {\n  type = string\n}\n\nvariable \"vpc_id\" {\n  type = string\n}\n\nvariable \"private_subnet_ids\" {\n  type = list(string)\n}\n\nvariable \"db_security_group_id\" {\n  type = string\n}\n\nvariable \"db_name\" {\n  type = string\n}\n\nvariable \"db_username\" {\n  type      = string\n  sensitive = true\n}\n\nvariable \"db_password\" {\n  type      = string\n  sensitive = true\n}\n\nvariable \"db_instance_class\" {\n  type = string\n}\n\nvariable \"db_allocated_storage\" {\n  type = number\n}\n\n# =============================================================================\n# Module Outputs\n# =============================================================================\n\noutput \"db_endpoint\" {\n  value = aws_db_instance.rds_postgres.endpoint\n}\n\noutput \"db_address\" {\n  value = aws_db_instance.rds_postgres.address\n}\n\noutput \"db_port\" {\n  value = aws_db_instance.rds_postgres.port\n}\n\noutput \"db_name\" {\n  value = aws_db_instance.rds_postgres.db_name\n}",
          "description": "RDS PostgreSQL module"
        },
        {
          "path": "terraform/modules/ecr/main.tf",
          "content": "# =============================================================================\n# ECR Repository Module\n# =============================================================================\n\nresource \"aws_ecr_repository\" \"ecr_repo\" {\n  name                 = \"${var.project_name}-${var.environment}\"\n  image_tag_mutability = \"MUTABLE\"\n\n  image_scanning_configuration {\n    scan_on_push = true\n  }\n\n  encryption_configuration {\n    encryption_type = \"AES256\"\n  }\n\n  tags = {\n    Name = \"${var.project_name}-${var.environment}-ecr\"\n  }\n}\n\nresource \"aws_ecr_lifecycle_policy\" \"ecr_lifecycle\" {\n  repository = aws_ecr_repository.ecr_repo.name\n\n  policy = jsonencode({\n    rules = [\n      {\n        rulePriority = 1\n        description  = \"Keep last 10 images\"\n        selection = {\n          tagStatus     = \"any\"\n          countType     = \"imageCountMoreThan\"\n          countNumber   = 10\n        }\n        action = {\n          type = \"expire\"\n        }\n      }\n    ]\n  })\n}\n\n# =============================================================================\n# Module Variables\n# =============================================================================\n\nvariable \"project_name\" {\n  type = string\n}\n\nvariable \"environment\" {\n  type = string\n}\n\n# =============================================================================\n# Module Outputs\n# =============================================================================\n\noutput \"repository_url\" {\n  value = aws_ecr_repository.ecr_repo.repository_url\n}\n\noutput \"repository_arn\" {\n  value = aws_ecr_repository.ecr_repo.arn\n}\n\noutput \"repository_name\" {\n  value = aws_ecr_repository.ecr_repo.name\n}",
          "description": "ECR repository module"
        },
        {
          "path": "terraform/modules/ecs/main.tf",
          "content": "# =============================================================================\n# ECS Cluster and Service Module\n# =============================================================================\n\n# =============================================================================\n# ECS Cluster\n# =============================================================================\n\nresource \"aws_ecs_cluster\" \"ecs_cluster_main\" {\n  name = \"${var.project_name}-${var.environment}-cluster\"\n\n  setting {\n    name  = \"containerInsights\"\n    value = \"enabled\"\n  }\n\n  tags = {\n    Name = \"${var.project_name}-${var.environment}-cluster\"\n  }\n}\n\n# =============================================================================\n# IAM Roles\n# =============================================================================\n\nresource \"aws_iam_role\" \"iam_ecs_task_execution\" {\n  name = \"${var.project_name}-${var.environment}-ecs-task-execution-role\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = \"sts:AssumeRole\"\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"ecs-tasks.amazonaws.com\"\n        }\n      }\n    ]\n  })\n}\n\nresource \"aws_iam_role_policy_attachment\" \"iam_ecs_task_execution_attach\" {\n  role       = aws_iam_role.iam_ecs_task_execution.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\"\n}\n\nresource \"aws_iam_role\" \"iam_ecs_task\" {\n  name = \"${var.project_name}-${var.environment}-ecs-task-role\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = \"sts:AssumeRole\"\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"ecs-tasks.amazonaws.com\"\n        }\n      }\n    ]\n  })\n}\n\n# =============================================================================\n# Application Load Balancer\n# =============================================================================\n\nresource \"aws_lb\" \"alb_main\" {\n  name               = \"${var.project_name}-${var.environment}-alb\"\n  internal           = false\n  load_balancer_type = \"application\"\n  security_groups    = [var.alb_security_group_id]\n  subnets            = var.public_subnet_ids\n\n  enable_deletion_protection = false\n  enable_http2              = true\n\n  tags = {\n    Name = \"${var.project_name}-${var.environment}-alb\"\n  }\n}\n\nresource \"aws_lb_target_group\" \"alb_target_group\" {\n  name        = \"${var.project_name}-${var.environment}-tg\"\n  port        = var.app_port\n  protocol    = \"HTTP\"\n  vpc_id      = var.vpc_id\n  target_type = \"ip\"\n\n  health_check {\n    enabled             = true\n    healthy_threshold   = 2\n    unhealthy_threshold = 3\n    timeout             = 5\n    interval            = 30\n    path                = var.health_check_path\n    protocol            = \"HTTP\"\n    matcher             = \"200\"\n  }\n\n  deregistration_delay = 30\n\n  tags = {\n    Name = \"${var.project_name}-${var.environment}-tg\"\n  }\n}\n\nresource \"aws_lb_listener\" \"alb_listener\" {\n  load_balancer_arn = aws_lb.alb_main.arn\n  port              = 80\n  protocol          = \"HTTP\"\n\n  default_action {\n    type             = \"forward\"\n    target_group_arn = aws_lb_target_group.alb_target_group.arn\n  }\n}\n\n# =============================================================================\n# ECS Task Definition\n# =============================================================================\n\nresource \"aws_ecs_task_definition\" \"ecs_task_def\" {\n  family                   = \"${var.project_name}-${var.environment}\"\n  network_mode             = \"awsvpc\"\n  requires_compatibilities = [\"FARGATE\"]\n  cpu                      = var.app_cpu\n  memory                   = var.app_memory\n  execution_role_arn       = aws_iam_role.iam_ecs_task_execution.arn\n  task_role_arn            = aws_iam_role.iam_ecs_task.arn\n\n  container_definitions = jsonencode([\n    {\n      name      = \"${var.project_name}-${var.environment}\"\n      image     = \"${var.ecr_repository_url}:latest\"\n      essential = true\n\n      portMappings = [\n        {\n          containerPort = var.app_port\n          protocol      = \"tcp\"\n        }\n      ]\n\n      environment = [\n        {\n          name  = \"NODE_ENV\"\n          value = \"production\"\n        },\n        {\n          name  = \"PORT\"\n          value = tostring(var.app_port)\n        },\n        # FIXED: Extract hostname from RDS endpoint (removes :5432)\n        {\n          name  = \"DB_HOST\"\n          value = split(\":\", var.db_host)[0]\n        },\n        {\n          name  = \"DB_PORT\"\n          value = tostring(var.db_port)\n        },\n        {\n          name  = \"DB_NAME\"\n          value = var.db_name\n        },\n        {\n          name  = \"DB_USER\"\n          value = var.db_username\n        },\n        {\n          name  = \"DB_PASSWORD\"\n          value = var.db_password\n        },\n        # ADDED: Full connection string for compatibility\n        {\n          name  = \"DATABASE_URL\"\n          value = \"postgresql://${var.db_username}:${var.db_password}@${split(\":\", var.db_host)[0]}:${var.db_port}/${var.db_name}\"\n        },\n        # ADDED: Connection pool settings\n        {\n          name  = \"DB_POOL_MIN\"\n          value = \"2\"\n        },\n        {\n          name  = \"DB_POOL_MAX\"\n          value = \"10\"\n        },\n        {\n          name  = \"DB_POOL_IDLE\"\n          value = \"10000\"\n        }\n      ]\n\n      logConfiguration = {\n        logDriver = \"awslogs\"\n        options = {\n          \"awslogs-group\"         = \"/ecs/${var.project_name}-${var.environment}\"\n          \"awslogs-region\"        = data.aws_region.current.name\n          \"awslogs-stream-prefix\" = \"ecs\"\n        }\n      }\n\n      healthCheck = {\n        command     = [\"CMD-SHELL\", \"wget --no-verbose --tries=1 --spider http://localhost:${var.app_port}${var.health_check_path} || exit 1\"]\n        interval    = 30\n        timeout     = 5\n        retries     = 3\n        startPeriod = 60\n      }\n    }\n  ])\n\n  tags = {\n    Name = \"${var.project_name}-${var.environment}-task\"\n  }\n}\n\n# =============================================================================\n# ECS Service\n# =============================================================================\n\nresource \"aws_ecs_service\" \"ecs_service_main\" {\n  name            = \"${var.project_name}-${var.environment}-service\"\n  cluster         = aws_ecs_cluster.ecs_cluster_main.id\n  task_definition = aws_ecs_task_definition.ecs_task_def.arn\n  desired_count   = var.desired_count\n  launch_type     = \"FARGATE\"\n\n  network_configuration {\n    security_groups  = [var.ecs_security_group_id]\n    subnets          = var.private_subnet_ids\n    assign_public_ip = false\n  }\n\n  load_balancer {\n    target_group_arn = aws_lb_target_group.alb_target_group.arn\n    container_name   = \"${var.project_name}-${var.environment}\"\n    container_port   = var.app_port\n  }\n\n  deployment_controller {\n    type = \"ECS\"\n  }\n\n  deployment_circuit_breaker {\n    enable   = true\n    rollback = true\n  }\n\n  deployment_maximum_percent         = 200\n  deployment_minimum_healthy_percent = 100\n\n  health_check_grace_period_seconds = 60\n\n  depends_on = [\n    aws_lb_listener.alb_listener,\n    aws_iam_role_policy_attachment.iam_ecs_task_execution_attach\n  ]\n\n  tags = {\n    Name = \"${var.project_name}-${var.environment}-service\"\n  }\n}\n\n# =============================================================================\n# Auto Scaling\n# =============================================================================\n\nresource \"aws_appautoscaling_target\" \"ecs_autoscale_target\" {\n  max_capacity       = 4\n  min_capacity       = var.desired_count\n  resource_id        = \"service/${aws_ecs_cluster.ecs_cluster_main.name}/${aws_ecs_service.ecs_service_main.name}\"\n  scalable_dimension = \"ecs:service:DesiredCount\"\n  service_namespace  = \"ecs\"\n}\n\nresource \"aws_appautoscaling_policy\" \"ecs_cpu_policy\" {\n  name               = \"${var.project_name}-${var.environment}-cpu-scaling\"\n  policy_type        = \"TargetTrackingScaling\"\n  resource_id        = aws_appautoscaling_target.ecs_autoscale_target.resource_id\n  scalable_dimension = aws_appautoscaling_target.ecs_autoscale_target.scalable_dimension\n  service_namespace  = aws_appautoscaling_target.ecs_autoscale_target.service_namespace\n\n  target_tracking_scaling_policy_configuration {\n    predefined_metric_specification {\n      predefined_metric_type = \"ECSServiceAverageCPUUtilization\"\n    }\n    target_value       = 70.0\n    scale_in_cooldown  = 300\n    scale_out_cooldown = 60\n  }\n}\n\nresource \"aws_appautoscaling_policy\" \"ecs_memory_policy\" {\n  name               = \"${var.project_name}-${var.environment}-memory-scaling\"\n  policy_type        = \"TargetTrackingScaling\"\n  resource_id        = aws_appautoscaling_target.ecs_autoscale_target.resource_id\n  scalable_dimension = aws_appautoscaling_target.ecs_autoscale_target.scalable_dimension\n  service_namespace  = aws_appautoscaling_target.ecs_autoscale_target.service_namespace\n\n  target_tracking_scaling_policy_configuration {\n    predefined_metric_specification {\n      predefined_metric_type = \"ECSServiceAverageMemoryUtilization\"\n    }\n    target_value       = 80.0\n    scale_in_cooldown  = 300\n    scale_out_cooldown = 60\n  }\n}\n\n# =============================================================================\n# Data Sources\n# =============================================================================\n\ndata \"aws_region\" \"current\" {}\n\n# =============================================================================\n# Module Variables\n# =============================================================================\n\nvariable \"project_name\" {\n  type = string\n}\n\nvariable \"environment\" {\n  type = string\n}\n\nvariable \"vpc_id\" {\n  type = string\n}\n\nvariable \"public_subnet_ids\" {\n  type = list(string)\n}\n\nvariable \"private_subnet_ids\" {\n  type = list(string)\n}\n\nvariable \"ecs_security_group_id\" {\n  type = string\n}\n\nvariable \"alb_security_group_id\" {\n  type = string\n}\n\nvariable \"ecr_repository_url\" {\n  type = string\n}\n\nvariable \"db_host\" {\n  type = string\n}\n\nvariable \"db_port\" {\n  type = number\n}\n\nvariable \"db_name\" {\n  type = string\n}\n\nvariable \"db_username\" {\n  type      = string\n  sensitive = true\n}\n\nvariable \"db_password\" {\n  type      = string\n  sensitive = true\n}\n\nvariable \"app_port\" {\n  type = number\n}\n\nvariable \"app_cpu\" {\n  type = number\n}\n\nvariable \"app_memory\" {\n  type = number\n}\n\nvariable \"desired_count\" {\n  type = number\n}\n\nvariable \"health_check_path\" {\n  type = string\n}\n\n\n# =============================================================================\n# Module Outputs\n# =============================================================================\n\noutput \"cluster_name\" {\n  value = aws_ecs_cluster.ecs_cluster_main.name\n}\n\noutput \"service_name\" {\n  value = aws_ecs_service.ecs_service_main.name\n}\n\noutput \"alb_dns_name\" {\n  value = aws_lb.alb_main.dns_name\n}\n\noutput \"alb_arn\" {\n  value = aws_lb.alb_main.arn\n}\n\noutput \"target_group_arn\" {\n  value = aws_lb_target_group.alb_target_group.arn\n}",
          "description": "ECS module with fixed database connectivity"
        },
        {
          "path": "terraform/terraform.tfvars",
          "content": "# =============================================================================\n# Build Multitenant B2b - Terraform Variables Example\n# =============================================================================\n# Copy this file to terraform.tfvars and update with your actual values\n\n# Project Configuration\nproject_name = \"build-multitenant-b2b\"\nenvironment  = \"dev\"\naws_region   = \"us-east-1\"\n\n# Database Configuration\ndb_name     = \"build_multitenant_b2b\"\ndb_username = \"postgres\"\ndb_password = \"CHANGE_THIS_SECURE_PASSWORD\"  # Change this!\n\ndb_instance_class    = \"db.t3.micro\"\ndb_allocated_storage = 20\n\n# Application Configuration\napp_port       = 3000\napp_cpu        = 256\napp_memory     = 512\ndesired_count  = 2\n\n\n# Health Check\nhealth_check_path = \"/health\"",
          "description": "Example Terraform variables file"
        },
        {
          "path": "deploy.sh",
          "content": "#!/bin/bash\n# =============================================================================\n# Build Multitenant B2b - Deployment Script\n# =============================================================================\n\nset -e\nset -o pipefail\n\n# Colors\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nBLUE='\\033[0;34m'\nNC='\\033[0m'\n\n# Configuration\nPROJECT_NAME=\"${PROJECT_NAME:-build-multitenant-b2b}\"\nAWS_REGION=\"${AWS_REGION:-us-east-1}\"\nENVIRONMENT=\"${ENVIRONMENT:-dev}\"\n\nerror_exit() {\n    echo -e \"${RED} Error: $1${NC}\" >&2\n    exit 1\n}\n\nsuccess() {\n    echo -e \"${GREEN} $1${NC}\"\n}\n\ninfo() {\n    echo -e \"${BLUE}  $1${NC}\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}  $1${NC}\"\n}\n\necho -e \"${GREEN}========================================${NC}\"\necho -e \"${GREEN} Deploying Build Multitenant B2b${NC}\"\necho -e \"${GREEN}========================================${NC}\"\necho \"\"\n\n# =============================================================================\n# 1. Prerequisites Check\n# =============================================================================\necho -e \"${YELLOW} Step 1: Checking prerequisites...${NC}\"\n\nif ! command -v terraform &> /dev/null; then\n    error_exit \"Terraform not found. Install: https://www.terraform.io/downloads\"\nfi\nsuccess \"Terraform found: $(terraform version | head -n1)\"\n\nif ! command -v aws &> /dev/null; then\n    error_exit \"AWS CLI not found. Install: https://aws.amazon.com/cli/\"\nfi\nsuccess \"AWS CLI found: $(aws --version)\"\n\nif ! command -v docker &> /dev/null; then\n    error_exit \"Docker not found. Install: https://docs.docker.com/get-docker/\"\nfi\nsuccess \"Docker found: $(docker --version)\"\n\nif ! docker info &> /dev/null; then\n    error_exit \"Docker daemon not running. Please start Docker.\"\nfi\nsuccess \"Docker daemon running\"\n\necho \"\"\ninfo \"Verifying AWS credentials...\"\nif ! aws sts get-caller-identity &> /dev/null; then\n    error_exit \"AWS credentials not configured. Run: aws configure\"\nfi\n\nAWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\nAWS_USER=$(aws sts get-caller-identity --query Arn --output text)\nsuccess \"AWS authenticated as: ${AWS_USER}\"\ninfo \"AWS Account ID: ${AWS_ACCOUNT_ID}\"\ninfo \"AWS Region: ${AWS_REGION}\"\necho \"\"\n\n# =============================================================================\n# 2. Check AWS IAM Permissions (FIXED)\n# =============================================================================\necho -e \"${YELLOW} Step 2: Checking AWS IAM permissions...${NC}\"\n\ncheck_service_access() {\n    local service=$1\n    local test_command=$2\n    \n    if eval \"$test_command\" &> /dev/null; then\n        success \"$service access confirmed\"\n        return 0\n    else\n        warn \"$service access check failed (may work anyway)\"\n        return 1\n    fi\n}\n\n# Fixed permission checks - removed --max-results and added || true for graceful failures\ncheck_service_access \"EC2\" \"aws ec2 describe-regions --region $AWS_REGION\"\ncheck_service_access \"ECR\" \"aws ecr describe-repositories --region $AWS_REGION || true\"\ncheck_service_access \"ECS\" \"aws ecs list-clusters --region $AWS_REGION\"\ncheck_service_access \"RDS\" \"aws rds describe-db-instances --region $AWS_REGION || true\"\n\necho \"\"\ninfo \"Permission checks completed. Proceeding with deployment...\"\necho \"\"\n\n# =============================================================================\n# 3. Terraform Infrastructure\n# =============================================================================\necho -e \"${YELLOW}  Step 3: Provisioning infrastructure...${NC}\"\n\nif [ ! -d \"terraform\" ]; then\n    error_exit \"terraform/ directory not found. Are you in the project root?\"\nfi\n\ncd terraform\n\nif [ ! -f \"terraform.tfvars\" ]; then\n    error_exit \"terraform.tfvars not found! Copy terraform.tfvars and configure it.\"\nfi\nsuccess \"terraform.tfvars found\"\n\ninfo \"Initializing Terraform...\"\nif ! terraform init; then\n    error_exit \"Terraform initialization failed\"\nfi\nsuccess \"Terraform initialized\"\n\ninfo \"Validating configuration...\"\nif ! terraform validate; then\n    error_exit \"Terraform validation failed\"\nfi\nsuccess \"Configuration valid\"\n\ninfo \"Creating execution plan...\"\nif ! terraform plan -out=tfplan; then\n    error_exit \"Terraform plan failed\"\nfi\nsuccess \"Execution plan created\"\n\necho \"\"\nwarn \"About to apply infrastructure changes.\"\nread -p \"Continue? (yes/no): \" CONFIRM\nif [ \"$CONFIRM\" != \"yes\" ]; then\n    error_exit \"Deployment cancelled\"\nfi\n\ninfo \"Applying changes (10-15 minutes)...\"\nif ! terraform apply tfplan; then\n    error_exit \"Terraform apply failed\"\nfi\nsuccess \"Infrastructure provisioned\"\n\ninfo \"Retrieving outputs...\"\nECR_REPOSITORY_URL=$(terraform output -raw ecr_repository_url 2>/dev/null) || error_exit \"Failed to get ECR URL\"\nECS_CLUSTER_NAME=$(terraform output -raw ecs_cluster_name 2>/dev/null) || error_exit \"Failed to get cluster name\"\nECS_SERVICE_NAME=$(terraform output -raw ecs_service_name 2>/dev/null) || error_exit \"Failed to get service name\"\nALB_DNS_NAME=$(terraform output -raw alb_dns_name 2>/dev/null) || error_exit \"Failed to get ALB DNS\"\nsuccess \"Outputs retrieved\"\n\ncd ..\necho \"\"\n\n# =============================================================================\n# 4. Docker Build & Push\n# =============================================================================\necho -e \"${YELLOW} Step 4: Building and pushing Docker image...${NC}\"\n\nif [ ! -f \"Dockerfile\" ]; then\n    error_exit \"Dockerfile not found\"\nfi\nsuccess \"Dockerfile found\"\n\ninfo \"Logging into ECR...\"\nif ! aws ecr get-login-password --region $AWS_REGION | \\\n    docker login --username AWS --password-stdin $ECR_REPOSITORY_URL; then\n    error_exit \"ECR login failed\"\nfi\nsuccess \"ECR login successful\"\n\ninfo \"Building Docker image...\"\nif ! docker build -t $PROJECT_NAME:latest .; then\n    error_exit \"Docker build failed\"\nfi\nsuccess \"Image built\"\n\ninfo \"Tagging for ECR...\"\ndocker tag $PROJECT_NAME:latest $ECR_REPOSITORY_URL:latest\nsuccess \"Image tagged\"\n\ninfo \"Pushing to ECR...\"\nif ! docker push $ECR_REPOSITORY_URL:latest; then\n    error_exit \"Push to ECR failed\"\nfi\nsuccess \"Image pushed\"\necho \"\"\n\n# =============================================================================\n# 5. ECS Deployment\n# =============================================================================\necho -e \"${YELLOW} Step 5: Deploying to ECS...${NC}\"\n\ninfo \"Forcing new deployment...\"\nif ! aws ecs update-service \\\n    --cluster $ECS_CLUSTER_NAME \\\n    --service $ECS_SERVICE_NAME \\\n    --force-new-deployment \\\n    --region $AWS_REGION \\\n    > /dev/null; then\n    error_exit \"ECS update failed\"\nfi\nsuccess \"Deployment initiated\"\n\ninfo \"Waiting for stability (5-10 minutes)...\"\ninfo \"Press Ctrl+C to exit (deployment continues)\"\n\nif aws ecs wait services-stable \\\n    --cluster $ECS_CLUSTER_NAME \\\n    --services $ECS_SERVICE_NAME \\\n    --region $AWS_REGION 2>/dev/null; then\n    success \"Service is stable\"\nelse\n    warn \"Stabilization timeout\"\n    info \"Check status: aws ecs describe-services --cluster $ECS_CLUSTER_NAME --services $ECS_SERVICE_NAME\"\nfi\necho \"\"\n\n# =============================================================================\n# 6. Health Check\n# =============================================================================\necho -e \"${YELLOW} Step 6: Health check...${NC}\"\n\ninfo \"Waiting 30s for load balancer...\"\nsleep 30\n\nHEALTH_URL=\"http://${ALB_DNS_NAME}/health\"\ninfo \"Checking: $HEALTH_URL\"\n\nfor i in {1..10}; do\n    if curl -f -s -o /dev/null \"$HEALTH_URL\"; then\n        success \"Health check passed!\"\n        break\n    else\n        warn \"Health check failed (attempt $i/10), retrying...\"\n        sleep 10\n    fi\n    \n    if [ $i -eq 10 ]; then\n        warn \"Health check incomplete\"\n        info \"Check logs: aws logs tail /ecs/${PROJECT_NAME}-${ENVIRONMENT} --follow\"\n    fi\ndone\necho \"\"\n\n# =============================================================================\n# 7. Summary\n# =============================================================================\necho -e \"${GREEN}========================================${NC}\"\necho -e \"${GREEN} Deployment Complete!${NC}\"\necho -e \"${GREEN}========================================${NC}\"\necho \"\"\necho -e \"${BLUE} Summary:${NC}\"\necho \"   Project: ${PROJECT_NAME}\"\necho \"   Environment: ${ENVIRONMENT}\"\necho \"   Region: ${AWS_REGION}\"\necho \"   Account: ${AWS_ACCOUNT_ID}\"\necho \"\"\necho -e \"${BLUE} URLs:${NC}\"\necho \"   App: http://${ALB_DNS_NAME}\"\necho \"   Health: http://${ALB_DNS_NAME}/health\"\necho \"\"\necho -e \"${BLUE} Resources:${NC}\"\necho \"   Cluster: ${ECS_CLUSTER_NAME}\"\necho \"   Service: ${ECS_SERVICE_NAME}\"\necho \"   Registry: ${ECR_REPOSITORY_URL}\"\necho \"\"\necho -e \"${YELLOW} Load balancer may take 2-3 minutes to be fully healthy${NC}\"\necho \"\"\necho -e \"${BLUE} Commands:${NC}\"\necho \"\"\necho \"Service status:\"\necho \"  aws ecs describe-services --cluster $ECS_CLUSTER_NAME --services $ECS_SERVICE_NAME\"\necho \"\"\necho \"View logs:\"\necho \"  aws logs tail /ecs/${PROJECT_NAME}-${ENVIRONMENT} --follow\"\necho \"\"\necho \"List tasks:\"\necho \"  aws ecs list-tasks --cluster $ECS_CLUSTER_NAME --service-name $ECS_SERVICE_NAME\"\necho \"\"\necho \"Test API:\"\necho \"  curl http://${ALB_DNS_NAME}/health\"\necho \"\"",
          "description": "Fixed deployment script with proper permission checks and error handling"
        },
        {
          "path": "terraform/README.md",
          "content": "# Build Multitenant B2b - Terraform Infrastructure\n\nThis directory contains Terraform configurations for deploying Build Multitenant B2b to AWS ECS (Fargate).\n\n##  Infrastructure Components\n\n- **VPC**: Custom VPC with public and private subnets across 2 AZs\n- **RDS**: PostgreSQL database in private subnets\n- **ECR**: Docker container registry\n- **ECS**: Fargate cluster with auto-scaling\n- **ALB**: Application Load Balancer for traffic distribution\n- **Security Groups**: Properly configured network security\n\n##  Quick Start\n\n### Prerequisites\n\n```bash\n# Install Terraform\nbrew install terraform  # macOS\n# or download from https://www.terraform.io/downloads\n\n# Configure AWS credentials\naws configure\n```\n\n### Deployment Steps\n\n1. **Configure Variables**\n   ```bash\n   cd terraform\n   cp terraform.tfvars terraform.tfvars\n   # Edit terraform.tfvars with your values\n   ```\n\n2. **Deploy Everything**\n   ```bash\n   # From project root\n   chmod +x deploy.sh\n   ./deploy.sh\n   ```\n\n   Or manually:\n   ```bash\n   # Initialize Terraform\n   terraform init\n\n   # Review changes\n   terraform plan\n\n   # Apply infrastructure\n   terraform apply\n\n   # Build and push Docker image\n   ECR_URL=$(terraform output -raw ecr_repository_url)\n   aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin $ECR_URL\n   docker build -t myapp .\n   docker tag myapp:latest $ECR_URL:latest\n   docker push $ECR_URL:latest\n\n   # Force ECS deployment\n   aws ecs update-service \\\n     --cluster $(terraform output -raw ecs_cluster_name) \\\n     --service $(terraform output -raw ecs_service_name) \\\n     --force-new-deployment\n   ```\n\n##  File Structure\n\n```\nterraform/\n main.tf                    # Main configuration\n variables.tf               # Variable definitions\n outputs.tf                 # Output values\n terraform.tfvars   \n modules/\n     vpc/                   # VPC networking\n     security/              # Security groups\n     rds/                   # PostgreSQL database\n     ecr/                   # Container registry\n     ecs/                   # ECS cluster & service\n```\n\n##  Important Variables\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| `project_name` | Project identifier | - |\n| `environment` | Environment name | dev |\n| `db_password` | Database password | - |\n| `app_cpu` | Fargate CPU units | 256 |\n| `app_memory` | Fargate memory (MB) | 512 |\n| `desired_count` | Number of tasks | 2 |\n\n##  Outputs\n\nAfter deployment, Terraform provides:\n\n- `alb_url`: Application URL\n- `ecr_repository_url`: Docker registry URL\n- `db_endpoint`: Database connection endpoint\n\n##  Security Considerations\n\n1. **Never commit** `terraform.tfvars` or `.env` files\n2. Use strong passwords for `db_password`\n3. Review security group rules before applying\n4. Enable deletion protection for production RDS instances\n5. Consider using AWS Secrets Manager for sensitive data\n\n##  Cost Estimation\n\nApproximate monthly costs (us-east-1):\n\n- **ECS Fargate** (2 tasks, 0.25 vCPU, 0.5 GB): ~$15-20\n- **RDS db.t3.micro**: ~$15-20\n- **ALB**: ~$16-20\n- **Data Transfer**: Variable\n- **ECR Storage**: Minimal\n\n**Total**: ~$50-70/month for dev environment\n\n##  Updating Infrastructure\n\n```bash\n# Modify .tf files\nterraform plan\nterraform apply\n\n# To update application code only\n./deploy.sh  # Rebuilds and redeploys container\n```\n\n##  Cleanup\n\n```bash\ncd terraform\nterraform destroy\n```\n\n **Warning**: This will delete all resources including the database!\n\n##  Troubleshooting\n\n### Issue: Service won't stabilize\n```bash\n# Check service events\naws ecs describe-services --cluster CLUSTER_NAME --services SERVICE_NAME\n\n# Check task logs\naws logs tail /ecs/PROJECT_NAME-ENV --follow\n```\n\n### Issue: Can't push to ECR\n```bash\n# Re-authenticate\naws ecr get-login-password --region us-east-1 | \\\n  docker login --username AWS --password-stdin ECR_URL\n```\n\n### Issue: Database connection fails\n- Check security group rules\n- Verify RDS is in \"available\" state\n- Confirm environment variables in ECS task definition\n\n##  Resources\n\n- [Terraform AWS Provider](https://registry.terraform.io/providers/hashicorp/aws/latest/docs)\n- [AWS ECS Documentation](https://docs.aws.amazon.com/ecs/)\n- [AWS RDS PostgreSQL](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_PostgreSQL.html)",
          "description": "Comprehensive Terraform documentation"
        },
        {
          "path": "src/index.js",
          "content": "const express = require('express');\nconst cors = require('cors');\nconst helmet = require('helmet');\nconst compression = require('compression');\nconst dotenv = require('dotenv');\n\n// Import middleware\nconst { errorHandler, notFoundHandler, requestLogger } = require('./middleware');\nconst { createLogger } = require('./utils/logger');\n\nconst logger = createLogger();\n\n// ============================================================================\n// TABLE-BASED ROUTES\n// ============================================================================\nconst { router: organizationsRouter } = require('./routes/organizationsRoutes');\nconst { router: organizationUsersRouter } = require('./routes/organizationUsersRoutes');\nconst { router: usersRouter } = require('./routes/usersRoutes');\nconst { router: shipmentsRouter } = require('./routes/shipmentsRoutes');\nconst { router: carriersRouter } = require('./routes/carriersRoutes');\nconst { router: shipmentStatusRouter } = require('./routes/shipmentStatusRoutes');\nconst { router: shipmentLocationsRouter } = require('./routes/shipmentLocationsRoutes');\nconst { router: shipmentAlertsRouter } = require('./routes/shipmentAlertsRoutes');\nconst { router: settingsRouter } = require('./routes/settingsRoutes');\nconst { router: auditLogsRouter } = require('./routes/auditLogsRoutes');\n\n// ============================================================================\n// CUSTOM COMPONENT ROUTES (from LLD/API Map diagrams)\n// ============================================================================\nconst { router: userRouter } = require('./routes/userRoutes');\nconst { router: organizationRouter } = require('./routes/organizationRoutes');\nconst { router: shipmentRouter } = require('./routes/shipmentRoutes');\nconst { router: carrierRouter } = require('./routes/carrierRoutes');\nconst { router: authenticationRouter } = require('./routes/authenticationRoutes');\nconst { router: errorRouter } = require('./routes/errorRoutes');\nconst { router: emailServiceAdapterRouter } = require('./routes/emailserviceadapterRoutes');\n\n\n\ndotenv.config();\n\nconst app = express();\nconst PORT = process.env.PORT || 3000;\n\n// Security middleware\napp.use(helmet());\napp.use(cors({\n  origin: process.env.CORS_ORIGIN?.split(',') || '*',\n  credentials: true\n}));\napp.use(compression());\n\n// Body parsing middleware\napp.use(express.json());\napp.use(express.urlencoded({ extended: true }));\n\n// Request logging middleware\napp.use(requestLogger);\n\n// Health check endpoint\napp.get('/health', (req, res) => {\n  res.json({ \n    status: 'ok', \n    timestamp: new Date().toISOString(),\n    service: 'Build Multitenant B2b',\n    environment: process.env.NODE_ENV || 'development',\n    components: {\n      tables: 10,\n      custom: 7,\n      total: 17\n    }\n  });\n});\n\n// ============================================================================\n// REGISTER TABLE-BASED ROUTES\n// ============================================================================\napp.use('/api/v1/organizations', organizationsRouter); // organizations\napp.use('/api/v1/organizationUsers', organizationUsersRouter); // organizationUsers\napp.use('/api/v1/users', usersRouter); // users\napp.use('/api/v1/shipments', shipmentsRouter); // shipments\napp.use('/api/v1/carriers', carriersRouter); // carriers\napp.use('/api/v1/shipmentStatus', shipmentStatusRouter); // shipmentStatus\napp.use('/api/v1/shipmentLocations', shipmentLocationsRouter); // shipmentLocations\napp.use('/api/v1/shipmentAlerts', shipmentAlertsRouter); // shipmentAlerts\napp.use('/api/v1/settings', settingsRouter); // settings\napp.use('/api/v1/auditLogs', auditLogsRouter); // auditLogs\n\n// ============================================================================\n// REGISTER CUSTOM COMPONENT ROUTES\n// ============================================================================\napp.use('/api/v1/auth', userRouter); // user (custom)\napp.use('/api/v1/organizations', organizationRouter); // organization (custom)\napp.use('/api/v1/shipments', shipmentRouter); // shipment (custom)\napp.use('/api/v1/carriers', carrierRouter); // carrier (custom)\napp.use('/api/v1/authentication', authenticationRouter); // authentication (custom)\napp.use('/api/v1/error', errorRouter); // error (custom)\napp.use('/api/v1/emailServiceAdapter', emailServiceAdapterRouter); // emailServiceAdapter (custom)\n\n\n\n// 404 handler\napp.use(notFoundHandler);\n\n// Error handling middleware (must be last)\napp.use(errorHandler);\n\n// Start server\nif (require.main === module) {\n  app.listen(PORT, () => {\n    logger.info('Server starting', {\n      service: process.env.npm_package_name || 'Build Multitenant B2b',\n      port: PORT,\n      environment: process.env.NODE_ENV || 'development',\n      components: {\n        tables: 10,\n        custom: 7\n      }\n    });\n    \n    console.log('='.repeat(60));\n    console.log(` ${process.env.npm_package_name || 'Build Multitenant B2b'} Server`);\n    console.log('='.repeat(60));\n    console.log(` Port: ${PORT}`);\n    console.log(` Environment: ${process.env.NODE_ENV || 'development'}`);\n    console.log(``);\n    console.log(` Registered Routes:`);\n    console.log(`    /api/v1/organizations (organizations)`);\n    console.log(`    /api/v1/organizationUsers (organizationUsers)`);\n    console.log(`    /api/v1/users (users)`);\n    console.log(`    /api/v1/shipments (shipments)`);\n    console.log(`    /api/v1/carriers (carriers)`);\n    console.log(`    /api/v1/shipmentStatus (shipmentStatus)`);\n    console.log(`    /api/v1/shipmentLocations (shipmentLocations)`);\n    console.log(`    /api/v1/shipmentAlerts (shipmentAlerts)`);\n    console.log(`    /api/v1/settings (settings)`);\n    console.log(`    /api/v1/auditLogs (auditLogs)`);\n    console.log(`    /api/v1/auth (user - custom)`);\n    console.log(`    /api/v1/organizations (organization - custom)`);\n    console.log(`    /api/v1/shipments (shipment - custom)`);\n    console.log(`    /api/v1/carriers (carrier - custom)`);\n    console.log(`    /api/v1/authentication (authentication - custom)`);\n    console.log(`    /api/v1/error (error - custom)`);\n    console.log(`    /api/v1/emailServiceAdapter (emailServiceAdapter - custom)`);\n    console.log('='.repeat(60));\n    console.log(`\\n Server ready at http://localhost:${PORT}`);\n    console.log(` Health check: http://localhost:${PORT}/health\\n`);\n  });\n}\n\nmodule.exports = { app };",
          "description": "Main application entry point with function registry validation",
          "exports": [
            "app"
          ]
        },
        {
          "path": "src/database/migrate.js",
          "content": "const { Pool } = require('pg');\nconst fs = require('fs').promises;\nconst path = require('path');\nrequire('dotenv').config();\n\n//  FIX: SSL Configuration - Disabled for local, enabled for production\nconst getSslConfig = () => {\n  const nodeEnv = process.env.NODE_ENV || 'development';\n  const isLocal = nodeEnv === 'development' || process.env.DB_HOST === 'localhost';\n  \n  if (isLocal) {\n    console.log('    SSL: Disabled (local development)');\n    return false;\n  }\n  \n  console.log('    SSL: Enabled (production/AWS RDS)');\n  return {\n    rejectUnauthorized: false, // AWS RDS\n  };\n};\n\n//  FIX: Consistent database name\nconst DB_NAME = process.env.DB_NAME || 'build_multitenant_b2b';\n\nconst pool = new Pool({\n  host: process.env.DB_HOST || 'localhost',\n  port: parseInt(process.env.DB_PORT || '5432'),\n  user: process.env.DB_USER || 'postgres',\n  password: process.env.DB_PASSWORD || 'postgres',\n  database: DB_NAME,\n  \n  // SSL Configuration\n  ssl: getSslConfig(),\n  \n  // Connection settings\n  connectionTimeoutMillis: 5000,\n  idleTimeoutMillis: 30000,\n  max: 10,\n  \n  // Keep connection alive\n  keepAlive: true,\n  keepAliveInitialDelayMillis: 10000,\n});\n\n// Log configuration\nconsole.log(' Migration utility configuration:');\nconsole.log(`   Environment: ${process.env.NODE_ENV || 'development'}`);\nconsole.log(`   Database: ${DB_NAME}`);\nconsole.log(`   Host: ${process.env.DB_HOST || 'localhost'}`);\n\npool.on('error', (err) => {\n  console.error(' Unexpected database error:', err);\n});\n\nconst createMigrationTable = async () => {\n  const query = `\n    CREATE TABLE IF NOT EXISTS migrations (\n      id SERIAL PRIMARY KEY,\n      name VARCHAR(255) NOT NULL UNIQUE,\n      executed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n    )\n  `;\n  \n  try {\n    await pool.query(query);\n    console.log(' Migration table ready');\n  } catch (error) {\n    console.error(' Failed to create migration table:', error.message);\n    throw error;\n  }\n};\n\nconst getExecutedMigrations = async () => {\n  try {\n    const result = await pool.query('SELECT name FROM migrations ORDER BY id ASC');\n    return result.rows.map(row => row.name);\n  } catch (error) {\n    console.error(' Failed to get executed migrations:', error.message);\n    throw error;\n  }\n};\n\nconst recordMigration = async (name) => {\n  try {\n    await pool.query('INSERT INTO migrations (name) VALUES ($1)', [name]);\n  } catch (error) {\n    console.error(` Failed to record migration ${name}:`, error.message);\n    throw error;\n  }\n};\n\nconst migrateUp = async () => {\n  console.log('\\n Starting database migration...');\n  console.log('='.repeat(60));\n  \n  try {\n    // Test connection\n    await pool.query('SELECT NOW()');\n    console.log(' Database connection successful');\n    \n    await createMigrationTable();\n    \n    const migrationsDir = path.join(__dirname, 'migrations');\n    const files = await fs.readdir(migrationsDir);\n    const sqlFiles = files.filter(f => f.endsWith('.sql')).sort();\n    \n    console.log(` Found ${sqlFiles.length} migration files`);\n    \n    const executed = await getExecutedMigrations();\n    console.log(` Already executed: ${executed.length} migrations`);\n    \n    const pending = sqlFiles.filter(f => !executed.includes(f));\n    console.log(` Pending: ${pending.length} migrations\\n`);\n    \n    if (pending.length === 0) {\n      console.log(' No pending migrations - database is up to date');\n      console.log('='.repeat(60));\n      return;\n    }\n    \n    for (const migration of pending) {\n      console.log(` Executing: ${migration}`);\n      const filePath = path.join(migrationsDir, migration);\n      const sql = await fs.readFile(filePath, 'utf8');\n      \n      await pool.query('BEGIN');\n      try {\n        await pool.query(sql);\n        await recordMigration(migration);\n        await pool.query('COMMIT');\n        console.log(`    Success: ${migration}\\n`);\n      } catch (error) {\n        await pool.query('ROLLBACK');\n        console.error(`    Failed: ${migration}`);\n        console.error(`   Error: ${error.message}\\n`);\n        throw error;\n      }\n    }\n    \n    console.log('='.repeat(60));\n    console.log(` Migration complete! Executed ${pending.length} migrations`);\n    console.log('='.repeat(60));\n    \n  } catch (error) {\n    console.error('\\n Migration failed:', error.message);\n    console.error('='.repeat(60));\n    throw error;\n  }\n};\n\nconst main = async () => {\n  const command = process.argv[2] || 'up';\n  \n  try {\n    if (command === 'up') {\n      await migrateUp();\n    } else {\n      console.log(` Unknown command: ${command}`);\n      console.log('Available commands: up');\n      process.exit(1);\n    }\n  } catch (error) {\n    console.error('\\n Fatal error:', error.message);\n    process.exit(1);\n  } finally {\n    await pool.end();\n    console.log('\\n Database connection closed');\n  }\n};\n\nif (require.main === module) {\n  main();\n}\n\nmodule.exports = { migrateUp, getExecutedMigrations };",
          "description": "Migration utility with SSL auto-detection and consistent DB name"
        }
      ],
      "instructions": "# Build Multitenant B2b - Setup Instructions\n\n##  Generation Summary\n\n **Modules Generated:** 13/14 validated (92.9%)\n **Total Files:** 101\n **Total Functions:** 276\n **Total Exports:** 235\n **Factory Functions:** 63\n **Handler Functions:** 65\n  **Import Issues:** 1 files need review\n\n**Architecture:** Functional MVC (NO classes)\n**Export Standard:** Named exports only (NO default exports)\n**Naming Convention:** camelCase filenames\n**Database:** build_multitenant_b2b\n**SSL:** Auto-detected (disabled for local, enabled for production)\n\n##  Function Registry by Module\n\n- **root**: 10 files\n- **utils**: 5 files\n- **database**: 5 files\n- **migrations**: 1 files\n- **models**: 11 files\n- **middleware**: 4 files\n- **services**: 18 files\n- **handlers**: 18 files\n- **routes**: 18 files\n- **tests**: 1 files\n- **unit**: 1 files\n- **integration**: 1 files\n- **terraform**: 5 files\n- **vpc**: 1 files\n- **security**: 1 files\n- **rds**: 1 files\n- **ecr**: 1 files\n- **ecs**: 1 files\n- **src**: 1 files\n\n##  Quick Start (Docker - Recommended)\n\n```bash\n# 1. Configure environment\ncp .env.example .env\n# Edit .env with your settings (DB_HOST, DB_PASSWORD, etc.)\n\n# 2. Build and start all services\ndocker-compose up -d\n\n# 3. Check application logs\ndocker-compose logs -f app\n\n# 4. Check database logs\ndocker-compose logs -f db\n\n# 5. Test the API\ncurl http://localhost:3000/health\n```\n\n##  Local Development Setup (Without Docker)\n\n```bash\n# 1. Install dependencies\nnpm install\n\n# 2. Configure environment for local PostgreSQL\ncp .env.example .env\n\n# Edit .env:\n# DB_HOST=localhost\n# DB_PORT=5432\n# DB_USER=postgres\n# DB_PASSWORD=your_password\n# DB_NAME=build_multitenant_b2b\n# NODE_ENV=development\n\n# 3. Ensure PostgreSQL is running locally\n# macOS: brew services start postgresql\n# Linux: sudo systemctl start postgresql\n# Windows: Start PostgreSQL service\n\n# 4. Run migrations\nnpm run migrate:up\n\n# 5. (Optional) Seed database\nnpm run db:seed\n\n# 6. Start development server\nnpm run dev\n```\n\n##   Database Configuration\n\n### SSL Settings (Auto-Detected)\n\nThe application automatically detects the environment:\n\n**Local Development:**\n- `NODE_ENV=development` OR `DB_HOST=localhost`\n- SSL: **Disabled**\n- Perfect for local PostgreSQL\n\n**Production/AWS RDS:**\n- `NODE_ENV=production` OR remote `DB_HOST`\n- SSL: **Enabled** with `rejectUnauthorized: false`\n- Works with AWS RDS out of the box\n\n### Environment Variables\n\n```bash\n# Database\nDB_HOST=localhost           # Use RDS endpoint for production\nDB_PORT=5432\nDB_USER=postgres\nDB_PASSWORD=your_password\nDB_NAME=build_multitenant_b2b          #  Consistent everywhere\n\n# Connection Pool\nDB_POOL_MIN=2\nDB_POOL_MAX=10\nDB_POOL_IDLE=10000\n\n# Application\nNODE_ENV=development        # Change to 'production' for prod\nPORT=3000\n```\n\n##  API Endpoints\n\n###  Health Check\n\n```bash\nGET /health\n```\n\n\n###  Organizations API\n\n**Base URL:** `/api/organizations`\n\n- `GET /` - List all organizations (supports filtering, pagination, sorting)\n- `GET /:id` - Get organizations by ID\n- `POST /` - Create new organizations\n- `PUT /:id` - Update organizations\n- `DELETE /:id` - Delete organizations\n\n**Fields:**\n- `id`: uuid\n- `name`: varchar\n- `email`: varchar\n- `created_at`: timestamptz\n- `updated_at`: timestamptz\n- `deleted_at`: timestamptz\n\n\n###  OrganizationUsers API\n\n**Base URL:** `/api/organizationUsers`\n\n- `GET /` - List all organization_users (supports filtering, pagination, sorting)\n- `GET /:id` - Get organization_users by ID\n- `POST /` - Create new organization_users\n- `PUT /:id` - Update organization_users\n- `DELETE /:id` - Delete organization_users\n\n**Fields:**\n- `id`: uuid\n- `organization_id`: uuid\n- `user_id`: uuid\n- `role`: varchar\n- `created_at`: timestamptz\n- `updated_at`: timestamptz\n- `deleted_at`: timestamptz\n\n\n###  Users API\n\n**Base URL:** `/api/users`\n\n- `GET /` - List all users (supports filtering, pagination, sorting)\n- `GET /:id` - Get users by ID\n- `POST /` - Create new users\n- `PUT /:id` - Update users\n- `DELETE /:id` - Delete users\n\n**Fields:**\n- `id`: uuid\n- `email`: varchar\n- `password`: varchar\n- `created_at`: timestamptz\n- `updated_at`: timestamptz\n- `deleted_at`: timestamptz\n\n\n###  Shipments API\n\n**Base URL:** `/api/shipments`\n\n- `GET /` - List all shipments (supports filtering, pagination, sorting)\n- `GET /:id` - Get shipments by ID\n- `POST /` - Create new shipments\n- `PUT /:id` - Update shipments\n- `DELETE /:id` - Delete shipments\n\n**Fields:**\n- `id`: uuid\n- `organization_id`: uuid\n- `carrier_id`: uuid\n- `tracking_number`: varchar\n- `created_at`: timestamptz\n- `updated_at`: timestamptz\n- `deleted_at`: timestamptz\n\n\n###  Carriers API\n\n**Base URL:** `/api/carriers`\n\n- `GET /` - List all carriers (supports filtering, pagination, sorting)\n- `GET /:id` - Get carriers by ID\n- `POST /` - Create new carriers\n- `PUT /:id` - Update carriers\n- `DELETE /:id` - Delete carriers\n\n**Fields:**\n- `id`: uuid\n- `name`: varchar\n- `api_key`: varchar\n- `created_at`: timestamptz\n- `updated_at`: timestamptz\n- `deleted_at`: timestamptz\n\n\n###  ShipmentStatus API\n\n**Base URL:** `/api/shipmentStatus`\n\n- `GET /` - List all shipment_status (supports filtering, pagination, sorting)\n- `GET /:id` - Get shipment_status by ID\n- `POST /` - Create new shipment_status\n- `PUT /:id` - Update shipment_status\n- `DELETE /:id` - Delete shipment_status\n\n**Fields:**\n- `id`: uuid\n- `shipment_id`: uuid\n- `status`: varchar\n- `created_at`: timestamptz\n- `updated_at`: timestamptz\n- `deleted_at`: timestamptz\n\n\n###  ShipmentLocations API\n\n**Base URL:** `/api/shipmentLocations`\n\n- `GET /` - List all shipment_locations (supports filtering, pagination, sorting)\n- `GET /:id` - Get shipment_locations by ID\n- `POST /` - Create new shipment_locations\n- `PUT /:id` - Update shipment_locations\n- `DELETE /:id` - Delete shipment_locations\n\n**Fields:**\n- `id`: uuid\n- `shipment_id`: uuid\n- `latitude`: decimal\n- `longitude`: decimal\n- `created_at`: timestamptz\n- `updated_at`: timestamptz\n- `deleted_at`: timestamptz\n\n\n###  ShipmentAlerts API\n\n**Base URL:** `/api/shipmentAlerts`\n\n- `GET /` - List all shipment_alerts (supports filtering, pagination, sorting)\n- `GET /:id` - Get shipment_alerts by ID\n- `POST /` - Create new shipment_alerts\n- `PUT /:id` - Update shipment_alerts\n- `DELETE /:id` - Delete shipment_alerts\n\n**Fields:**\n- `id`: uuid\n- `shipment_id`: uuid\n- `alert_type`: varchar\n- `created_at`: timestamptz\n- `updated_at`: timestamptz\n- `deleted_at`: timestamptz\n\n\n###  Settings API\n\n**Base URL:** `/api/settings`\n\n- `GET /` - List all settings (supports filtering, pagination, sorting)\n- `GET /:id` - Get settings by ID\n- `POST /` - Create new settings\n- `PUT /:id` - Update settings\n- `DELETE /:id` - Delete settings\n\n**Fields:**\n- `id`: uuid\n- `organization_id`: uuid\n- `setting_key`: varchar\n- `setting_value`: varchar\n- `created_at`: timestamptz\n- `updated_at`: timestamptz\n- `deleted_at`: timestamptz\n\n\n###  AuditLogs API\n\n**Base URL:** `/api/auditLogs`\n\n- `GET /` - List all audit_logs (supports filtering, pagination, sorting)\n- `GET /:id` - Get audit_logs by ID\n- `POST /` - Create new audit_logs\n- `PUT /:id` - Update audit_logs\n- `DELETE /:id` - Delete audit_logs\n\n**Fields:**\n- `id`: uuid\n- `organization_id`: uuid\n- `log_level`: varchar\n- `log_message`: text\n- `created_at`: timestamptz\n- `updated_at`: timestamptz\n- `deleted_at`: timestamptz\n\n\n\n\n##  Available Scripts\n\n```bash\n# Development\nnpm run dev              # Start with nodemon (auto-reload)\nnpm start                # Start production server\n\n# Database\nnpm run migrate:up       # Run all pending migrations\nnpm run migrate:down     # Rollback last migration\nnpm run db:seed          # Seed database with sample data\nnpm run db:reset         # Reset and reseed database\n\n# Code Quality\nnpm run lint             # Run ESLint\nnpm run lint:fix         # Fix ESLint issues\nnpm run format           # Format code with Prettier\n\n# Testing\nnpm test                 # Run all tests with coverage\nnpm run test:watch       # Run tests in watch mode\nnpm run test:integration # Run integration tests only\n```\n\n##   Architecture Principles\n\n###  Named Exports Only\n\n```javascript\n//  WRONG - Default export\nmodule.exports = createUserModel;\n\n//  CORRECT - Named exports\nmodule.exports = { createUserModel };\n```\n\n###  Functional Factory Pattern\n\n```javascript\n// Factory function that returns an object with methods\nconst createUserService = () => {\n  const userModel = createUserModel();\n  \n  const getAll = async (filters, options) => {\n    return await userModel.findAll(filters, options);\n  };\n  \n  const getById = async (id) => {\n    const user = await userModel.findById(id);\n    if (!user) throw createNotFoundError('User not found');\n    return user;\n  };\n  \n  return { getAll, getById };\n};\n\nmodule.exports = { createUserService };\n```\n\n###  CamelCase Naming Convention\n\n- **Files:** `user.js`, `userService.js`, `userHandler.js`\n- **Factories:** `createUserModel`, `createUserService`\n- **Handlers:** `handleGetUser`, `handleCreateUser`\n- **Routes:** `user.route.js`\n\n###  Import/Export Consistency\n\n```javascript\n// Export in models/user.js\nmodule.exports = { createUserModel };\n\n// Import in services/userService.js\nconst { createUserModel } = require('../models/user');\n\n// Export in services/userService.js\nmodule.exports = { createUserService };\n\n// Import in handlers/userHandler.js\nconst { createUserService } = require('../services/userService');\n```\n\n##  Docker Commands\n\n```bash\n# Start all services\ndocker-compose up -d\n\n# View logs\ndocker-compose logs -f app        # Application logs\ndocker-compose logs -f db         # Database logs\n\n# Stop services\ndocker-compose down\n\n# Rebuild after code changes\ndocker-compose up -d --build\n\n# Access database\ndocker-compose exec db psql -U postgres -d build_multitenant_b2b\n\n# Execute migrations manually\ndocker-compose exec app npm run migrate:up\n\n# Reset everything\ndocker-compose down -v            # Remove volumes\ndocker-compose up -d --build      # Rebuild and start\n```\n\n##  Module Validation Results\n\n\n### CONFIG\n- **Status:**  Success\n- **Validated:**  Yes\n- **Files:** 5\n- **Attempt:** 1\n\n\n\n### DOCKER\n- **Status:**  Success\n- **Validated:**  Yes\n- **Files:** 5\n- **Attempt:** 1\n\n\n\n### UTILS\n- **Status:**  Success\n- **Validated:**  Yes\n- **Files:** 5\n- **Attempt:** 1\n\n\n\n### DATABASE\n- **Status:**  Success\n- **Validated:**  Yes\n- **Files:** 5\n- **Attempt:** 1\n\n\n\n### MODELS\n- **Status:**  Success\n- **Validated:**  Yes\n- **Files:** 11\n- **Attempt:** 1\n\n\n\n### MIDDLEWARE\n- **Status:**  Success\n- **Validated:**  Yes\n- **Files:** 4\n- **Attempt:** 1\n\n\n\n### SERVICES\n- **Status:**  Success\n- **Validated:**  Yes\n- **Files:** 11\n- **Attempt:** 2\n\n\n\n### CUSTOM-SERVICES\n- **Status:**  Success\n- **Validated:**  Yes\n- **Files:** 7\n- **Attempt:** 1\n\n\n\n### HANDLERS\n- **Status:**  Success\n- **Validated:**  Yes\n- **Files:** 11\n- **Attempt:** 1\n\n\n\n### CUSTOM-HANDLERS\n- **Status:**  Success\n- **Validated:**  Yes\n- **Files:** 7\n- **Attempt:** 1\n\n\n\n### ROUTES\n- **Status:**  Success\n- **Validated:**  Yes\n- **Files:** 11\n- **Attempt:** 2\n\n\n\n### CUSTOM-ROUTES\n- **Status:**  Success\n- **Validated:**  Yes\n- **Files:** 7\n- **Attempt:** 1\n\n\n\n### TESTS\n- **Status:**  Failed\n- **Validated:**  Partial\n- **Files:** 0\n- **Attempt:** 4\n- **Error:** Bad control character in string literal in JSON at position 53 (line 4 column 33)\n\n\n### TERRAFORM\n- **Status:**  Success\n- **Validated:**  Yes\n- **Files:** 11\n- **Attempt:** 1\n\n\n\n##  Troubleshooting\n\n### Import/Export Issues\n\nIf you encounter import errors:\n\n1. Check that function names match exactly (case-sensitive)\n2. Verify export syntax: `module.exports = { functionName }`\n3. Check import paths are correct relative paths\n4. Review the function registry in this document\n\n### SSL Connection Issues\n\n**Local PostgreSQL:**\n```bash\n# In .env\nDB_HOST=localhost\nNODE_ENV=development\n```\n\n**AWS RDS:**\n```bash\n# In .env\nDB_HOST=your-rds-endpoint.region.rds.amazonaws.com\nNODE_ENV=production\n```\n\n### Database Connection Issues\n\n```bash\n# Test connection\ndocker-compose exec db psql -U postgres -d build_multitenant_b2b -c \"SELECT 1\"\n\n# Check database exists\ndocker-compose exec db psql -U postgres -l\n\n# Recreate database\ndocker-compose exec db psql -U postgres -c \"DROP DATABASE IF EXISTS build_multitenant_b2b\"\ndocker-compose exec db psql -U postgres -c \"CREATE DATABASE build_multitenant_b2b\"\ndocker-compose exec app npm run migrate:up\n```\n\n##  Additional Resources\n\n- **Express.js:** https://expressjs.com/\n- **PostgreSQL:** https://www.postgresql.org/docs/\n- **Docker:** https://docs.docker.com/\n- **Node.js Best Practices:** https://github.com/goldbergyoni/nodebestpractices\n\n---\n\n**Generated with Enhanced Functional MVC Code Generator**\n-  Context-Aware Generation\n-  Function Registry & Validation\n-  Auto SSL Detection\n-  Consistent Database Naming\n-  Import/Export Tracking\n",
      "dependencies": {
        "dotenv": "^16.3.1",
        "cors": "^2.8.5",
        "helmet": "^7.1.0",
        "compression": "^1.7.4",
        "pg": "^8.11.0",
        "express": "^4.18.2",
        "express-validator": "^7.0.1",
        "bull": "^4.11.5",
        "bullmq": "^5.0.0",
        "uuid": "^9.0.0"
      },
      "devDependencies": {
        "nodemon": "^3.0.1",
        "eslint": "^8.57.0",
        "prettier": "^3.1.1",
        "jest": "^29.7.0",
        "supertest": "^6.3.3",
        "@jest/globals": "^29.7.0",
        "@actions/core": "^1.10.1",
        "@actions/github": "^6.0.0"
      },
      "success": true
    },
    "generatedIaC": {
      "success": true,
      "files": [],
      "instructions": "Infrastructure files generated",
      "dependencies": []
    }
  },
  "framework": "express",
  "language": "typescript",
  "includeAuth": false,
  "includeTests": true,
  "options": {
    "iacTargets": [
      "terraform",
      "docker-compose"
    ],
    "environment": "development",
    "architecture": {
      "id": "arch-1765301322151",
      "name": "Build Multitenant B2b System Architecture",
      "description": "Moderate architecture with 25 components",
      "nodes": [
        {
          "id": "cdn-1",
          "type": "cdn",
          "position": {
            "x": 100,
            "y": 100
          },
          "data": {
            "name": "Content Delivery Network",
            "description": "Distributes frontend assets",
            "color": "#0891B2",
            "metadata": {
              "layer": "Layer 0 (Client)",
              "layerIndex": 0
            },
            "aiExplanation": {
              "whyChosen": "\"Content Delivery Network\" provides essential cdn functionality for Build Multitenant B2b. It distributes frontend assets.",
              "howItFits": "This cdn integrates with other components to handle cdn responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard cdn best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "build-multitenant-b2b-frontend-1",
          "type": "frontend",
          "position": {
            "x": 100,
            "y": 300
          },
          "data": {
            "name": "Build Multitenant B2b Frontend",
            "description": "Handles client-side logic",
            "color": "#3B82F6",
            "metadata": {
              "layer": "Layer 0 (Client)",
              "layerIndex": 0
            },
            "aiExplanation": {
              "whyChosen": "\"Build Multitenant B2b Frontend\" provides essential frontend functionality for Build Multitenant B2b. It handles client-side logic.",
              "howItFits": "This frontend integrates with other components to handle frontend responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard frontend best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "mobile-1",
          "type": "mobile",
          "position": {
            "x": 100,
            "y": 500
          },
          "data": {
            "name": "Mobile Application",
            "description": "Provides mobile access to the application",
            "color": "#06B6D4",
            "metadata": {
              "layer": "Layer 0 (Client)",
              "layerIndex": 0
            },
            "aiExplanation": {
              "whyChosen": "\"Mobile Application\" provides essential mobile functionality for Build Multitenant B2b. It provides mobile access to the application.",
              "howItFits": "This mobile integrates with other components to handle mobile responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard mobile best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "load-balancer-1",
          "type": "load-balancer",
          "position": {
            "x": 500,
            "y": 100
          },
          "data": {
            "name": "Load Balancer",
            "description": "Routes traffic to services",
            "color": "#10B981",
            "metadata": {
              "layer": "Layer 1 (Gateway)",
              "layerIndex": 1
            },
            "aiExplanation": {
              "whyChosen": "\"Load Balancer\" provides essential load-balancer functionality for Build Multitenant B2b. It routes traffic to services.",
              "howItFits": "This load-balancer integrates with other components to handle load-balancer responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard load-balancer best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "api-gateway-1",
          "type": "api-gateway",
          "position": {
            "x": 500,
            "y": 300
          },
          "data": {
            "name": "API Gateway",
            "description": "Handles API requests and routing",
            "color": "#059669",
            "metadata": {
              "layer": "Layer 1 (Gateway)",
              "layerIndex": 1
            },
            "aiExplanation": {
              "whyChosen": "\"API Gateway\" provides essential api-gateway functionality for Build Multitenant B2b. It handles api requests and routing.",
              "howItFits": "This api-gateway integrates with other components to handle api-gateway responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's request routing.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard api-gateway best practices for configuration and deployment: configure rate limiting, implement authentication, enable logging."
            }
          }
        },
        {
          "id": "authentication-1",
          "type": "authentication",
          "position": {
            "x": 500,
            "y": 500
          },
          "data": {
            "name": "Authentication",
            "description": "Handles authentication operations",
            "color": "#F59E0B",
            "metadata": {
              "layer": "Layer 1 (Gateway)",
              "layerIndex": 1
            },
            "aiExplanation": {
              "whyChosen": "\"Authentication\" provides essential authentication functionality for Build Multitenant B2b. It handles authentication operations.",
              "howItFits": "This authentication integrates with other components to handle authentication responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard authentication best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "authentication-service-1",
          "type": "api-service",
          "position": {
            "x": 900,
            "y": 100
          },
          "data": {
            "name": "Authentication Service",
            "description": "Handles 2 POST endpoints for authentication management",
            "color": "#8B5CF6",
            "metadata": {
              "layer": "Layer 2 (Application)",
              "layerIndex": 2
            },
            "aiExplanation": {
              "whyChosen": "\"Authentication Service\" provides essential api-service functionality for Build Multitenant B2b. It handles 2 post endpoints for authentication management.",
              "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
              "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
            }
          }
        },
        {
          "id": "organizations-service-1",
          "type": "api-service",
          "position": {
            "x": 900,
            "y": 300
          },
          "data": {
            "name": "Organizations Service",
            "description": "Manages organizations table via 5 endpoints (GET, POST, PUT, DELETE)",
            "color": "#8B5CF6",
            "metadata": {
              "layer": "Layer 2 (Application)",
              "layerIndex": 2
            },
            "aiExplanation": {
              "whyChosen": "\"Organizations Service\" provides essential api-service functionality for Build Multitenant B2b. It manages organizations table via 5 endpoints (get, post, put, delete).",
              "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
              "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
            }
          }
        },
        {
          "id": "shipments-service-1",
          "type": "api-service",
          "position": {
            "x": 900,
            "y": 500
          },
          "data": {
            "name": "Shipments Service",
            "description": "Manages shipments table via 5 endpoints (GET, POST, PUT, DELETE)",
            "color": "#8B5CF6",
            "metadata": {
              "layer": "Layer 2 (Application)",
              "layerIndex": 2
            },
            "aiExplanation": {
              "whyChosen": "\"Shipments Service\" provides essential api-service functionality for Build Multitenant B2b. It manages shipments table via 5 endpoints (get, post, put, delete).",
              "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
              "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
            }
          }
        },
        {
          "id": "carriers-service-1",
          "type": "api-service",
          "position": {
            "x": 900,
            "y": 700
          },
          "data": {
            "name": "Carriers Service",
            "description": "Manages carriers table via 5 endpoints (GET, POST, PUT, DELETE)",
            "color": "#8B5CF6",
            "metadata": {
              "layer": "Layer 2 (Application)",
              "layerIndex": 2
            },
            "aiExplanation": {
              "whyChosen": "\"Carriers Service\" provides essential api-service functionality for Build Multitenant B2b. It manages carriers table via 5 endpoints (get, post, put, delete).",
              "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
              "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
            }
          }
        },
        {
          "id": "settings-service-1",
          "type": "api-service",
          "position": {
            "x": 900,
            "y": 900
          },
          "data": {
            "name": "Settings Service",
            "description": "Manages settings table via 5 endpoints (GET, POST, PUT, DELETE)",
            "color": "#8B5CF6",
            "metadata": {
              "layer": "Layer 2 (Application)",
              "layerIndex": 2
            },
            "aiExplanation": {
              "whyChosen": "\"Settings Service\" provides essential api-service functionality for Build Multitenant B2b. It manages settings table via 5 endpoints (get, post, put, delete).",
              "howItFits": "This api-service integrates with other components to handle api-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
              "bestPractices": "Follow standard api-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
            }
          }
        },
        {
          "id": "cache-1",
          "type": "cache",
          "position": {
            "x": 900,
            "y": 1100
          },
          "data": {
            "name": "Cache",
            "description": "Improves performance by caching frequently accessed data",
            "color": "#DC2626",
            "metadata": {
              "layer": "Layer 2 (Application)",
              "layerIndex": 2
            },
            "aiExplanation": {
              "whyChosen": "\"Cache\" provides essential cache functionality for Build Multitenant B2b. It improves performance by caching frequently accessed data.",
              "howItFits": "This cache integrates with other components to handle cache responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's performance optimization.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Caching improves speed but requires cache invalidation strategy.",
              "bestPractices": "Follow standard cache best practices for configuration and deployment: set appropriate TTLs, implement cache warming, monitor hit rates."
            }
          }
        },
        {
          "id": "queue-1",
          "type": "queue",
          "position": {
            "x": 900,
            "y": 1300
          },
          "data": {
            "name": "Message Queue",
            "description": "Handles asynchronous tasks and messaging",
            "color": "#F97316",
            "metadata": {
              "layer": "Layer 2 (Application)",
              "layerIndex": 2
            },
            "aiExplanation": {
              "whyChosen": "\"Message Queue\" provides essential queue functionality for Build Multitenant B2b. It handles asynchronous tasks and messaging.",
              "howItFits": "This queue integrates with other components to handle queue responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard queue best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "database-1",
          "type": "database",
          "position": {
            "x": 1300,
            "y": 100
          },
          "data": {
            "name": "PostgreSQL Database",
            "description": "Stores data in the following tables: organizations, organization_users, users, shipments, carriers, shipment_status, shipment_locations, shipment_alerts, settings, audit_logs",
            "color": "#EF4444",
            "metadata": {
              "layer": "Layer 3 (Data)",
              "layerIndex": 3
            },
            "aiExplanation": {
              "whyChosen": "\"PostgreSQL Database\" provides essential database functionality for Build Multitenant B2b. It stores data in the following tables: organizations, organization_users, users, shipments, carriers, shipment_status, shipment_locations, shipment_alerts, settings, audit_logs.",
              "howItFits": "This database integrates with other components to handle database responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's data persistence.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Centralized data storage ensures consistency but may become a bottleneck.",
              "bestPractices": "Follow standard database best practices for configuration and deployment: optimize queries, implement backup strategies, use connection pooling."
            }
          }
        },
        {
          "id": "search-engine-1",
          "type": "search-engine",
          "position": {
            "x": 1300,
            "y": 300
          },
          "data": {
            "name": "Search Engine",
            "description": "Provides full-text search capabilities",
            "color": "#B45309",
            "metadata": {
              "layer": "Layer 3 (Data)",
              "layerIndex": 3
            },
            "aiExplanation": {
              "whyChosen": "\"Search Engine\" provides essential search-engine functionality for Build Multitenant B2b. It provides full-text search capabilities.",
              "howItFits": "This search-engine integrates with other components to handle search-engine responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard search-engine best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "storage-1",
          "type": "backup-storage",
          "position": {
            "x": 1300,
            "y": 500
          },
          "data": {
            "name": "Storage",
            "description": "Stores and retrieves files and assets",
            "color": "#4B5563",
            "metadata": {
              "layer": "Layer 3 (Data)",
              "layerIndex": 3
            },
            "aiExplanation": {
              "whyChosen": "\"Storage\" provides essential backup-storage functionality for Build Multitenant B2b. It stores and retrieves files and assets.",
              "howItFits": "This backup-storage integrates with other components to handle backup-storage responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard backup-storage best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "replica-1",
          "type": "database",
          "position": {
            "x": 1300,
            "y": 700
          },
          "data": {
            "name": "Database Replica",
            "description": "Provides a read-only replica of the primary database",
            "color": "#EF4444",
            "metadata": {
              "layer": "Layer 3 (Data)",
              "layerIndex": 3
            },
            "aiExplanation": {
              "whyChosen": "\"Database Replica\" provides essential database functionality for Build Multitenant B2b. It provides a read-only replica of the primary database.",
              "howItFits": "This database integrates with other components to handle database responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's data persistence.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Centralized data storage ensures consistency but may become a bottleneck.",
              "bestPractices": "Follow standard database best practices for configuration and deployment: optimize queries, implement backup strategies, use connection pooling."
            }
          }
        },
        {
          "id": "monitoring-1",
          "type": "monitoring",
          "position": {
            "x": 1700,
            "y": 100
          },
          "data": {
            "name": "Monitoring",
            "description": "Tracks system performance and health",
            "color": "#EA580C",
            "metadata": {
              "layer": "Layer 4 (Infrastructure)",
              "layerIndex": 4
            },
            "aiExplanation": {
              "whyChosen": "\"Monitoring\" provides essential monitoring functionality for Build Multitenant B2b. It tracks system performance and health.",
              "howItFits": "This monitoring integrates with other components to handle monitoring responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard monitoring best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "logging-1",
          "type": "logging",
          "position": {
            "x": 1700,
            "y": 300
          },
          "data": {
            "name": "Logging",
            "description": "Handles log collection and analysis",
            "color": "#CA8A04",
            "metadata": {
              "layer": "Layer 4 (Infrastructure)",
              "layerIndex": 4
            },
            "aiExplanation": {
              "whyChosen": "\"Logging\" provides essential logging functionality for Build Multitenant B2b. It handles log collection and analysis.",
              "howItFits": "This logging integrates with other components to handle logging responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard logging best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "notifications-1",
          "type": "notification-service",
          "position": {
            "x": 1700,
            "y": 500
          },
          "data": {
            "name": "Notifications",
            "description": "Sends notifications to users and administrators",
            "color": "#8B5CF6",
            "metadata": {
              "layer": "Layer 4 (Infrastructure)",
              "layerIndex": 4
            },
            "aiExplanation": {
              "whyChosen": "\"Notifications\" provides essential notification-service functionality for Build Multitenant B2b. It sends notifications to users and administrators.",
              "howItFits": "This notification-service integrates with other components to handle notification-service responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's business logic.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Microservice isolation provides flexibility but adds network overhead.",
              "bestPractices": "Follow standard notification-service best practices for configuration and deployment: implement health checks, use circuit breakers, ensure proper error handling."
            }
          }
        },
        {
          "id": "analytics-1",
          "type": "analytics",
          "position": {
            "x": 1700,
            "y": 700
          },
          "data": {
            "name": "Analytics",
            "description": "Provides insights into system usage and performance",
            "color": "#7C3AED",
            "metadata": {
              "layer": "Layer 4 (Infrastructure)",
              "layerIndex": 4
            },
            "aiExplanation": {
              "whyChosen": "\"Analytics\" provides essential analytics functionality for Build Multitenant B2b. It provides insights into system usage and performance.",
              "howItFits": "This analytics integrates with other components to handle analytics responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard analytics best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "ci-cd-1",
          "type": "ci-cd",
          "position": {
            "x": 2100,
            "y": 100
          },
          "data": {
            "name": "CI/CD Pipeline",
            "description": "Automates build, test, and deployment processes",
            "color": "#059669",
            "metadata": {
              "layer": "Layer 5 (DevOps)",
              "layerIndex": 5
            },
            "aiExplanation": {
              "whyChosen": "\"CI/CD Pipeline\" provides essential ci-cd functionality for Build Multitenant B2b. It automates build, test, and deployment processes.",
              "howItFits": "This ci-cd integrates with other components to handle ci-cd responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard ci-cd best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "secrets-manager-1",
          "type": "secrets-manager",
          "position": {
            "x": 2100,
            "y": 300
          },
          "data": {
            "name": "Secrets Manager",
            "description": "Stores and manages sensitive data",
            "color": "#374151",
            "metadata": {
              "layer": "Layer 5 (DevOps)",
              "layerIndex": 5
            },
            "aiExplanation": {
              "whyChosen": "\"Secrets Manager\" provides essential secrets-manager functionality for Build Multitenant B2b. It stores and manages sensitive data.",
              "howItFits": "This secrets-manager integrates with other components to handle secrets-manager responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard secrets-manager best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "backup-1",
          "type": "backup-storage",
          "position": {
            "x": 2100,
            "y": 500
          },
          "data": {
            "name": "Backup",
            "description": "Stores and retrieves backups of the system",
            "color": "#4B5563",
            "metadata": {
              "layer": "Layer 5 (DevOps)",
              "layerIndex": 5
            },
            "aiExplanation": {
              "whyChosen": "\"Backup\" provides essential backup-storage functionality for Build Multitenant B2b. It stores and retrieves backups of the system.",
              "howItFits": "This backup-storage integrates with other components to handle backup-storage responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard backup-storage best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        },
        {
          "id": "container-registry-1",
          "type": "container-registry",
          "position": {
            "x": 2100,
            "y": 700
          },
          "data": {
            "name": "Container Registry",
            "description": "Stores and manages container images",
            "color": "#6B7280",
            "metadata": {
              "layer": "Layer 5 (DevOps)",
              "layerIndex": 5
            },
            "aiExplanation": {
              "whyChosen": "\"Container Registry\" provides essential container-registry functionality for Build Multitenant B2b. It stores and manages container images.",
              "howItFits": "This container-registry integrates with other components to handle container-registry responsibilities in the Build Multitenant B2b architecture. It serves as a key part of the system's overall functionality.",
              "tradeoffs": "Selected for its balance of performance, scalability, and ease of integration. Consider monitoring and scaling strategies as load increases.",
              "bestPractices": "Follow standard container-registry best practices for configuration and deployment: ensure proper monitoring, logging, and alerting."
            }
          }
        }
      ],
      "edges": [
        {
          "id": "edge-cdn-1-build-multitenant-b2b-frontend-1-0",
          "source": "cdn-1",
          "target": "build-multitenant-b2b-frontend-1",
          "label": "GET Frontend Assets"
        },
        {
          "id": "edge-build-multitenant-b2b-frontend-1-load-balancer-1-1",
          "source": "build-multitenant-b2b-frontend-1",
          "target": "load-balancer-1",
          "label": "GET/POST/PATCH Frontend Requests"
        },
        {
          "id": "edge-load-balancer-1-api-gateway-1-2",
          "source": "load-balancer-1",
          "target": "api-gateway-1",
          "label": "POST/GET API Requests"
        },
        {
          "id": "edge-api-gateway-1-authentication-1-3",
          "source": "api-gateway-1",
          "target": "authentication-1",
          "label": "POST Authentication Data"
        },
        {
          "id": "edge-api-gateway-1-authentication-service-1-4",
          "source": "api-gateway-1",
          "target": "authentication-service-1",
          "label": "POST Authentication Data"
        },
        {
          "id": "edge-api-gateway-1-organizations-service-1-5",
          "source": "api-gateway-1",
          "target": "organizations-service-1",
          "label": "GET/POST Organizations Data"
        },
        {
          "id": "edge-api-gateway-1-shipments-service-1-6",
          "source": "api-gateway-1",
          "target": "shipments-service-1",
          "label": "GET/POST Shipments Data"
        },
        {
          "id": "edge-api-gateway-1-carriers-service-1-7",
          "source": "api-gateway-1",
          "target": "carriers-service-1",
          "label": "GET/POST Carriers Data"
        },
        {
          "id": "edge-api-gateway-1-settings-service-1-8",
          "source": "api-gateway-1",
          "target": "settings-service-1",
          "label": "GET/POST Settings Data"
        },
        {
          "id": "edge-organizations-service-1-database-1-9",
          "source": "organizations-service-1",
          "target": "database-1",
          "label": "GET/POST Organizations Table"
        },
        {
          "id": "edge-shipments-service-1-database-1-10",
          "source": "shipments-service-1",
          "target": "database-1",
          "label": "GET/POST Shipments Table"
        },
        {
          "id": "edge-carriers-service-1-database-1-11",
          "source": "carriers-service-1",
          "target": "database-1",
          "label": "GET/POST Carriers Table"
        },
        {
          "id": "edge-settings-service-1-database-1-12",
          "source": "settings-service-1",
          "target": "database-1",
          "label": "GET/POST Settings Table"
        },
        {
          "id": "edge-database-1-replica-1-13",
          "source": "database-1",
          "target": "replica-1",
          "label": "Replication Data"
        },
        {
          "id": "edge-database-1-search-engine-1-14",
          "source": "database-1",
          "target": "search-engine-1",
          "label": "Search Indexing"
        },
        {
          "id": "edge-ci-cd-1-container-registry-1-15",
          "source": "ci-cd-1",
          "target": "container-registry-1",
          "label": "Image Deployment"
        },
        {
          "id": "edge-ci-cd-1-load-balancer-1-16",
          "source": "ci-cd-1",
          "target": "load-balancer-1",
          "label": "Deployment"
        },
        {
          "id": "edge-secrets-manager-1-ci-cd-1-17",
          "source": "secrets-manager-1",
          "target": "ci-cd-1",
          "label": "Secrets Injection"
        }
      ],
      "metadata": {
        "createdAt": "2025-12-09T17:28:42.151Z",
        "updatedAt": "2025-12-09T17:28:42.151Z",
        "version": "2.0.0",
        "aiGenerated": true,
        "complexity": "Moderate",
        "scalingStrategy": "Horizontal",
        "securityLevel": "Standard"
      }
    },
    "technologies": {
      "database": "postgresql"
    }
  }
}